---

episode: 7
guests:
- micheallanham
ids:
  anchor: datatalksclub/episodes/Lessons-from-Two-Decades-of-AI---Micheal-Lanham-e38oarc
  youtube: DSxqUlumM3A
image: images/podcast/s21e07-lessons-from-two-decades-of-ai.jpg

description: "Learn lessons from 20 years of AI. Discover evolution of AI, enduring principles, and wisdom from decades of machine learning experience."
links:
  anchor: https://creators.spotify.com/pod/profile/datatalksclub/episodes/Lessons-from-Two-Decades-of-AI---Micheal-Lanham-e38oarc
  apple: https://podcasts.apple.com/us/podcast/lessons-from-two-decades-of-ai-micheal-lanham/id1541710331?i=1000728604349
  spotify: https://open.spotify.com/episode/7uhe5ZysRi07S6mb14nnox
  youtube: https://www.youtube.com/watch?v=DSxqUlumM3A
season: 21
short: Lessons from Two Decades of AI
title: Lessons from Two Decades of AI
transcript:
- header: Micheal Lanham’s career journey and AI agent books
- line: Hi everyone, welcome to our event. This event is brought to you by DataTalks.Club,
    a community of people who love data. We have weekly events. If you want to find
    out more about the events we plan, there is a link in the description. Click on
    that link and check it out. You'll see all the events we have coming up.
  sec: 0
  time: 0:00
  who: Alexey
- line: Do not forget to subscribe to our YouTube channel. This way, you'll stay up
    to date with all our streams and future events like today’s. If you haven't joined
    our community yet, join now. There you can hang out with other data enthusiasts.
  sec: 19
  time: 0:19
  who: Alexey
- line: During today's interview, you can ask any question you want. There is a pinned
    link in the live chat. Click on it, ask your questions, and we will cover them
    during the interview.
  sec: 32
  time: 0:32
  who: Alexey
- line: That’s the usual intro. Now I am opening the questions we prepared. If you're
    ready, Michael, we can start.
  sec: 44
  time: 0:44
  who: Alexey
- line: Yeah, sure. Hi everyone.
  sec: 60
  time: '1:00'
  who: Michael
- line: Today we are joined by Michael. His career spans two decades, from building
    game AI with neural networks and evolutionary algorithms to writing more than
    10 books on augmented reality, virtual reality, reinforcement learning, and AI
    agents.
  sec: 67
  time: '1:07'
  who: Alexey
- line: Today he focuses on advanced deep learning, evolutionary methods, and building
    intelligent systems that go beyond large language models. We will talk about what
    makes AI agents different from simple chatbots, how games and simulations continue
    to shape AI research, and what has changed in the field over the last two decades.
  sec: 87
  time: '1:27'
  who: Alexey
- line: Welcome, Michael.
  sec: 106
  time: '1:46'
  who: Alexey
- line: Thank you for having me.
  sec: 106
  time: '1:46'
  who: Michael
- line: Evolutionary methods  that’s been a while since I last heard about those.
    I remember studying them at university in 2006 or 2007. I haven’t seen much practical
    use of them since. My view is limited to what I was personally exposed to, mostly
    software engineering.
  sec: 113
  time: '1:53'
  who: Alexey
- line: I’m really curious to know more because I remember doing those simulations
    and they were very fun. But first, can you tell us about your career journey so
    far?
  sec: 125
  time: '2:05'
  who: Alexey
- line: Over the last few decades, I’ve worked in various data science and machine
    learning roles. I started in academia, working with a group of Harvard scientists.
    We built a game to test children for executive functions like ADHD and behavioral
    problems.
  sec: 156
  time: '2:36'
  who: Michael
- line: We used simple neural networks and evolutionary algorithms to create tests
    and patterns for players to go through, then analyzed the data. Since Calgary
    is an oil and gas town, I joined a small consulting company in that industry.
  sec: 175
  time: '2:55'
  who: Michael
- line: I worked with them for several years on academic projects involving geomechanics
    and data science. We developed two products called Stab and Roxbank for oil and
    gas.
  sec: 195
  time: '3:15'
  who: Michael
- line: That company was later purchased by a larger oil and gas provider, where I
    moved up from managing a small group to leading 80 people across 11 cities in
    seven countries including Scotland.
  sec: 235
  time: '3:55'
  who: Michael
- line: You called that a small group?
  sec: 252
  time: '4:12'
  who: Alexey
- line: There was a lot of travel involved. I gained exposure to many data science
    and engineering techniques while building various applications. I left that position
    because of the travel and returned to consulting, working on evolutionary algorithms
    for optimizing numerical analysis related to pipeline corrosion.
  sec: 259
  time: '4:19'
  who: Michael
- line: Evolutionary algorithms were able to adapt faster and process data more efficiently
    back then. But they are very computationally intensive and haven’t been designed
    to benefit from frameworks that improved deep learning.
  sec: 290
  time: '4:50'
  who: Michael
- line: That’s why they’ve been pushed aside, though I believe they could come back.
    Along the way, I worked with oil and gas providers, then in cannabis business
    intelligence, and financial tech.
  sec: 301
  time: '5:01'
  who: Michael
- line: Currently, I work in a company building AI support assistants powered by multiple
    agents. We are developing deep research operator agents and other advanced tools.
  sec: 328
  time: '5:28'
  who: Michael
- header: 'Publishing journey: AR, Pokémon Go, sound design, and reinforcement learning'
- line: 'Around 2015 or 2016, I started writing books. I contacted a publisher and
    proposed three ideas: geospatial analysis and data, data analysis, and reverse
    engineering Pokémon Go.'
  sec: 345
  time: '5:45'
  who: Michael
- line: I had kids interested in the game and a background in GIS and Unity game development,
    so I was able to reverse engineer Pokémon Go. The publisher agreed, and that book
    became very popular, translated into 14 languages.
  sec: 370
  time: '6:10'
  who: Michael
- line: I remember when Pokémon Go came out. People were crazy about it, taking out
    their phones and seeing Pokémon on the screen like it was real augmented reality.
  sec: 387
  time: '6:27'
  who: Alexey
- line: It lasted maybe a month from my view as a casual observer, then interest dropped.
  sec: 407
  time: '6:47'
  who: Alexey
- line: One of my kids still plays it. It’s still around and was a big deal as augmented
    reality was the next big thing then. I wrote another AR book focused more on AI
    because I saw many benefits from AI even then.
  sec: 433
  time: '7:13'
  who: Michael
- line: Then I wrote a book about sound that became popular and used in colleges to
    teach sound design for games. My experience with waveform analysis from the oil
    and gas industry helped with that book.
  sec: 456
  time: '7:36'
  who: Michael
- line: Underground, waveforms are used to analyze rock composition, which translated
    well to sound design. After that, I moved into reinforcement learning. Alberta
    was the capital of reinforcement learning, with Richard Sutton who introduced
    me to it, along with David Silver, his student.
  sec: 481
  time: '8:01'
  who: Michael
- line: Why was Alberta the capital of reinforcement learning?
  sec: 518
  time: '8:38'
  who: Alexey
- line: The roots are definitely at the University of Alberta. David Silver has since
    moved to California and carried the work forward, so the center of research has
    shifted. I continued working on various projects and books.
  sec: 525
  time: '8:45'
  who: Michael
- line: I wrote several reinforcement learning and deep learning books. Then I returned
    to evolutionary algorithms with a book called Evolutionary Deep Learning, combining
    deep learning and evolutionary algorithms.
  sec: 549
  time: '9:09'
  who: Michael
- line: The idea covers hyperparameter search and modifying network architectures.
    These methods are computationally intensive but work well for optimizing convolutional
    neural networks.
  sec: 569
  time: '9:29'
  who: Michael
- header: 'Evolution of AI: evolutionary algorithms, deep learning, and agents'
- line: I started looking at large language models early on, but they weren’t big
    then. After LLMs exploded, I focused on NLP work. AI agents became popular around
    2023, five months after ChatGPT launched, and I embraced the concept.
  sec: 600
  time: '10:00'
  who: Michael
- line: We built agent pipelines to generate code using AI agents. I also wrote a
    book on using AI for learning game development, called vibe coding for games,
    published around 2023-24.
  sec: 635
  time: '10:35'
  who: Michael
- line: I finished most of the AI agents book in 2024. Initially, no one was excited
    about agents, but interest surged when it was published. The concepts were based
    on 2023 principles rather than the cutting edge by release. I'm now working on
    the second edition.
  sec: 660
  time: '11:00'
  who: Michael
- line: You've been productive over the last decades. Speaking of evolutionary algorithms,
    I think they're also called genetic algorithms, a type of evolutionary algorithm.
  sec: 690
  time: '11:30'
  who: Alexey
- line: The main idea is to start with a population of individuals that vary in fitness.
    The unfit die, and the fit reproduce, creating offspring with random mutations.
  sec: 707
  time: '11:47'
  who: Alexey
- line: 'Those offspring can be either fit or unfit, and the cycle repeats. You need
    two functions: a fitness function and a mutation function.'
  sec: 747
  time: '12:27'
  who: Alexey
- line: Sometimes there is also a pairing function to determine how parents combine
    genetics to produce offspring.
  sec: 767
  time: '12:47'
  who: Michael
- line: You repeat the process until resources run out or convergence is reached based
    on fitness.
  sec: 779
  time: '12:59'
  who: Alexey
- line: Exactly. Evolutionary algorithms are popular for many applications but computationally
    intensive. They explore many solutions without many constraints. Around 2006,
    they were seen as a promising path to intelligence.
  sec: 801
  time: '13:21'
  who: Michael
- header: Evolutionary algorithms in prompt engineering and LLMs
- line: That was what I studied in my AI class. We used Prolog and other rule-based
    systems. Genetic algorithms were interesting but I never used them outside class.
  sec: 824
  time: '13:44'
  who: Alexey
- line: Some recent uses include evolutionary algorithms in prompt engineering for
    LLMs and agents. They optimize prompts by evolving them to find better results.
  sec: 849
  time: '14:09'
  who: Michael
- line: This is popular but computationally expensive. You can discover prompt variations
    producing unexpected outputs due to LLM complexity. It has exciting applications
    if we solve computational challenges.
  sec: 868
  time: '14:28'
  who: Michael
- line: I found a GitHub repo called Genetic Prompt Lab with 28 stars.
  sec: 899
  time: '14:59'
  who: Alexey
- line: Yes, it may take about a week of computation to get results.
  sec: 923
  time: '15:23'
  who: Michael
- line: The idea is interesting. I do AI and prompt engineering too. With older models
    like GPT-3.5, tuning prompts made a big difference. Now, with newer models, the
    impact is less but still present.
  sec: 935
  time: '15:35'
  who: Alexey
- line: A precise prompt usually leads to a better answer. Writing good prompts feels
    more like art than science. I experiment a lot, hoping something sticks.
  sec: 960
  time: '16:00'
  who: Alexey
- line: That's how many of these things began. It's not only LLMs. All generative
    AI using text can benefit. Finding the right prompt can feel like art, where one
    day you find the perfect phrase that works perfectly.
  sec: 1045
  time: '17:25'
  who: Michael
- line: Generative AI extends to video and image prompts with many applications. I've
    thought about writing a book on this topic next.
  sec: 1078
  time: '17:58'
  who: Michael
- header: AI agent books second edition and practical applications
- line: How many books have you written?
  sec: 1093
  time: '18:13'
  who: Alexey
- line: I’ve written 11 books so far. I’m working on the 12th, the second edition
    of the AI agents book, and possibly a 13th on evolutionary algorithms.
  sec: 1099
  time: '18:19'
  who: Michael
- line: Is the AI agents book about game development?
  sec: 1105
  time: '18:25'
  who: Alexey
- line: No, it covers AI agents in general, for development and any application.
  sec: 1110
  time: '18:30'
  who: Michael
- line: You mentioned a book using agents for vibe coding for games in 2023, but now
    agents are big in 2025, which explains the second edition of the AI agents book.
  sec: 1116
  time: '18:36'
  who: Alexey
- line: Yes. I was working in fintech on NLP tasks like customer sentiment classification.
    We found LLMs and LLM-powered agents perform better than traditional deep learning.
  sec: 1139
  time: '18:59'
  who: Michael
- line: Because of my games background, I used agents with ChatGPT in a book teaching
    Python game development using Pygame.
  sec: 1182
  time: '19:42'
  who: Michael
- line: That’s a different book then?
  sec: 1204
  time: '20:04'
  who: Alexey
- line: Yes, a different book about teaching people to code games using AI. I was
    using GPT-3.5 and starting with GPT-4, with much prompt iteration.
  sec: 1211
  time: '20:11'
  who: Michael
- line: Now with GPT-5, fewer prompts would likely be needed to produce the game.
  sec: 1223
  time: '20:23'
  who: Michael
- line: So we’re discussing the AI Agents in Action book, correct?
  sec: 1228
  time: '20:28'
  who: Alexey
- line: Yes.
  sec: 1235
  time: '20:35'
  who: Michael
- line: I looked it up. It’s by Ming, published in March, and you’re working on the
    second edition because the field moves fast. Last year we did a course about LLMs,
    but this year I had to redo many parts.
  sec: 1242
  time: '20:42'
  who: Alexey
- line: AI agents have come up really fast, but we've used them differently over time.
    The way I teach AI agents now embraces minimalism, keeping agents as lean as possible.
  sec: 1249
  time: '20:49'
  who: Michael
- header: 'AI agent workflows: minimalism, task breakdown, and collaboration'
- line: I’ve seen people bulk their agents with many tools and instructions, but I
    recommend breaking up the workflow into tasks assigned to individual agents. These
    agents can run in a flow like an assembly line or through orchestration where
    one agent calls the others as needed.
  sec: 1257
  time: '20:57'
  who: Michael
- line: I have a pet project — a single agent that writes code to create websites.
    It reads and writes files, lists files, executes bash commands, and grabs data.
    It plans and executes the plan well.
  sec: 1312
  time: '21:52'
  who: Alexey
- line: 'I’m thinking to split it into multiple agents: a requirements agent to clarify
    what the user wants, a planning agent to create the execution plan, and an execution
    agent that carries out the plan. Does this approach make sense?'
  sec: 1319
  time: '21:59'
  who: Alexey
- line: Yes, that’s a good way to break it down into tasks. You could have a flow
    or an orchestration agent that reviews output, compares it to requirements, and
    decides whether to rerun or continue.
  sec: 1398
  time: '23:18'
  who: Michael
- line: Could you explain the difference between a flow and orchestration?
  sec: 1422
  time: '23:42'
  who: Alexey
- line: A flow is like an assembly line of agents where each does a task and passes
    output to the next. For example, requirements, planning, and execution agents.
  sec: 1428
  time: '23:48'
  who: Michael
- line: 'So the flow is sequential: requirements, plan, execution. But usually there’s
    back and forth, especially in the requirements stage to clarify details. This
    is like a conversation until agreement before passing to the next agent. For users,
    it looks like one chat, but under the hood multiple agents handle parts of the
    process.'
  sec: 1448
  time: '24:08'
  who: Alexey
- line: Yes, communication patterns vary, but flow is sequential agents. In orchestration,
    a front-facing agent manages interaction and calls planning and builder agents.
    It inspects outputs, providing feedback loops to meet requirements.
  sec: 1520
  time: '25:20'
  who: Michael
- header: Collaboration and orchestration among AI agents
- line: Orchestration is more complex since it must understand other agents’ actions.
    Some platforms like AutoGPT use collaboration, where agents communicate directly
    with each other in feedback loops. This is powerful but expensive and not good
    for real-time responses.
  sec: 1585
  time: '26:25'
  who: Michael
- line: When is collaboration a good pattern? What are the use cases?
  sec: 1660
  time: '27:40'
  who: Alexey
- line: For very complex problems where you know input and output but the process
    is intricate. Collaboration agents can work together, iterating and refining solutions
    like evolutionary algorithms.
  sec: 1665
  time: '27:45'
  who: Michael
- line: 'To make it concrete: in coding agents, one could be a designer, another front-end
    developer, another back-end developer, collaborating by sharing output and feedback.'
  sec: 1726
  time: '28:46'
  who: Alexey
- line: Yes, collaboration means agents talk to each other by sharing outputs that
    become inputs for others. They use a shared message channel to exchange context
    continuously.
  sec: 1745
  time: '29:05'
  who: Michael
- line: So collaboration allows parallel work, unlike the sequential flow where tasks
    happen one after another. For example, front-end and back-end development can
    run in parallel, sharing completion messages.
  sec: 1775
  time: '29:35'
  who: Alexey
- line: That could be either collaboration or orchestration. You may have a manager
    agent orchestrating parallel development tasks, switching between workflows, ensuring
    requirements are met.
  sec: 1809
  time: '30:09'
  who: Michael
- line: Do you describe all these patterns in your book?
  sec: 1870
  time: '31:10'
  who: Alexey
- line: Yes, the second edition covers architectural and communication patterns, with
    chapters detailing management and control of agent workflows.
  sec: 1877
  time: '31:17'
  who: Michael
- header: Tools and reasoning servers for agent communication
- line: Do you use a library for this or show how to build from scratch using APIs?
  sec: 1884
  time: '31:24'
  who: Alexey
- line: I like using the OpenAI Agent SDK it’s simple and includes features like guardrails
    and handoffs, making it good for demos and teaching.
  sec: 1891
  time: '31:31'
  who: Michael
- line: It also integrates with MCP servers for reasoning tasks. For example, each
    agent can talk to a sequential thinking server that acts like a workspace to plan
    and reason through tasks.
  sec: 1911
  time: '31:51'
  who: Michael
- line: The sequential thinking server stores plans and thoughts. Reasoning agents
    use it to write out their thought processes, which can be seen by users as the
    agents work, even though they interact primarily with one agent interface.
  sec: 1925
  time: '32:05'
  who: Michael
- line: Can this be done with just the Agent SDK?
  sec: 1979
  time: '32:59'
  who: Alexey
- line: Yes, alongside an MCP server. The sequential thinking server is a scratchpad
    for reasoning and planning.
  sec: 1988
  time: '33:08'
  who: Michael
- line: So it’s not for inter-agent communication but for helping agents think through
    problems?
  sec: 2000
  time: '33:20'
  who: Alexey
- line: Exactly. It’s like prompting agents to think step-by-step, improving answers
    by allowing them to give feedback to themselves as they generate output.
  sec: 2005
  time: '33:25'
  who: Michael
- line: This reasoning is separate from the output passed between agents. Usually,
    agents don’t share their reasoning steps with each other, just the results.
  sec: 2043
  time: '34:03'
  who: Michael
- line: Which chapter covers this topic?
  sec: 2069
  time: '34:29'
  who: Alexey
- line: Chapter four in the second edition. Earlier books mention reasoning and evaluation
    patterns, but this is a deeper treatment of reasoning and planning tools like
    sequential thinking servers.
  sec: 2074
  time: '34:34'
  who: Michael
- line: Is it available in Meep already?
  sec: 2104
  time: '35:04'
  who: Alexey
- line: I think it was added recently or will be soon. We’re watching for updates.
  sec: 2109
  time: '35:09'
  who: Michael
- header: AI agents in game development and generative AI impact
- line: Thanks for sharing. I’m also interested in game development. It seems closer
    to hardware and more complex because it involves languages like C++ prone to errors
    and segmentation faults.
  sec: 2117
  time: '35:17'
  who: Alexey
- line: How do coding agents deal with this complexity? Are games created with them
    easy to maintain and play?
  sec: 2142
  time: '35:42'
  who: Alexey
- line: Agent patterns can do powerful things in game development. I like playing
    Spider Solitaire but was annoyed by ads. I asked various LLMs to create a Spider
    Solitaire game.
  sec: 2189
  time: '36:29'
  who: Michael
- line: Recently, GPT-5 Pro built a complete Spider Solitaire game with card images
    from GitHub. It required some bug-fixing but the game is fully functional from
    end to end.
  sec: 2218
  time: '36:58'
  who: Michael
- line: Was it a React app?
  sec: 2261
  time: '37:41'
  who: Alexey
- line: Yes, just a HTML/JavaScript React app.
  sec: 2266
  time: '37:46'
  who: Michael
- line: Did you do this in the web interface or a coding agent?
  sec: 2271
  time: '37:51'
  who: Alexey
- line: GPT-5 Mini works well in VS Code and Cursor, but I prefer GPT-5 Pro despite
    its slower pace because it generates high-quality code.
  sec: 2276
  time: '37:56'
  who: Michael
- line: I’ve asked GPT-5 Pro to build microservice agents an interface orchestrator,
    backend image creation agent, web search agent all deployed with Docker Compose.
    It delivered a zipped package that runs with a single command.
  sec: 2287
  time: '38:07'
  who: Michael
- line: And it just worked?
  sec: 2318
  time: '38:38'
  who: Alexey
- line: Yes, after a couple bug-fix iterations.
  sec: 2325
  time: '38:45'
  who: Michael
- line: That’s impressive.
  sec: 2331
  time: '38:51'
  who: Alexey
- header: Future of generative AI in gaming and immersive content
- line: You can do a lot now. Returning to game development, a few years ago I wrote
    a book called Generating Reality about the impact of generative AI on gaming.
  sec: 2337
  time: '38:57'
  who: Michael
- line: Generative AI will change gaming by creating real-world models. The next platform
    may not be code but generative AI producing whole games without traditional artists
    or designers.
  sec: 2357
  time: '39:17'
  who: Michael
- line: The games could be infinitely playable and embed discovery, far beyond simple
    current games. They might look like watching high-quality video, the best graphics
    ever.
  sec: 2388
  time: '39:48'
  who: Michael
- line: I spent a lot of time playing Diablo I when I was younger. It’s an RPG where
    you have a character and fight monsters. I imagine if all the levels, quests,
    and challenges were automatically generated every time, it would be really cool.
  sec: 2413
  time: '40:13'
  who: Alexey
- line: Every time you play, it would be different, so you could play forever.
  sec: 2451
  time: '40:51'
  who: Alexey
- line: You could prompt level one and get a version of level one, or prompt level
    99 for that level. It might not happen next year, but that’s definitely the direction
    we’re heading.
  sec: 2457
  time: '40:57'
  who: Michael
- line: Not just fully generative AI applications, but generative AI producing both
    front and back end work. Eventually, we might have competent AI opponents in games,
    something gamers have wanted for a long time.
  sec: 2474
  time: '41:14'
  who: Michael
- header: Coding agents, new LLMs, and local deployment
- line: I was given a test to implement Space Invaders. It’s not very complex, but
    you need to model bullet physics, collisions, and manage things moving at the
    same time, which needs some multithreading. GPT-4 couldn’t solve it fully, but
    with 10-15 prompts, I got it to work. The same with Claude One, though it needed
    many iterations.
  sec: 2502
  time: '41:42'
  who: Alexey
- line: Hearing your story about Spider Solitaire made me want to try it again. Maybe
    I’ll see how far it can go with Space Invaders.
  sec: 2566
  time: '42:46'
  who: Alexey
- line: You might be surprised. These models have become quite capable.
  sec: 2586
  time: '43:06'
  who: Michael
- line: So GPT-4 Pro is required? I need to upgrade?
  sec: 2591
  time: '43:11'
  who: Alexey
- line: I’m not trying to sell Pro, but yes.
  sec: 2598
  time: '43:18'
  who: Michael
- line: I have a paid version but guess it’s not enough.
  sec: 2604
  time: '43:24'
  who: Alexey
- line: I spend a lot on AI service subscriptions every month.
  sec: 2609
  time: '43:29'
  who: Michael
- line: Is this available through API?
  sec: 2617
  time: '43:37'
  who: Alexey
- line: Yes, with high reasoning settings.
  sec: 2623
  time: '43:43'
  who: Michael
- line: So it’s paid separately from the subscription?
  sec: 2630
  time: '43:50'
  who: Alexey
- line: Yes, and you have to verify your identity with OpenAI.
  sec: 2635
  time: '43:55'
  who: Michael
- line: I tried to access reasoning tokens and got a message about security checks—like
    being a suspected spy.
  sec: 2641
  time: '44:01'
  who: Alexey
- line: They hide reasoning outputs so others don’t train on them. It’s likely they
    scraped outputs and trained on them, but no one knows for sure.
  sec: 2663
  time: '44:23'
  who: Michael
- line: We tested some new Chinese models.
  sec: 2677
  time: '44:37'
  who: Alexey
- line: I’ve tried some vision and image models from China, but not many language
    models because we need to be careful with corporate usage and Azure.
  sec: 2682
  time: '44:42'
  who: Michael
- line: For professional use, it’s better to avoid those for now.
  sec: 2707
  time: '45:07'
  who: Alexey
- line: Yes, but smaller, task-focused models are coming. Most current models are
    huge and general-purpose, but future models will be more efficient and specialized.
  sec: 2714
  time: '45:14'
  who: Michael
- header: AI model trends and data scientist career advice
- line: People will want models running locally because paying for hosted models and
    bandwidth gets expensive. GPUs are becoming affordable enough to run these models
    themselves.
  sec: 2740
  time: '45:40'
  who: Michael
- line: We’ve worked with the OpenAI 120 billion parameter open-source model, which
    is very capable.
  sec: 2774
  time: '46:14'
  who: Michael
- line: That’s open source?
  sec: 2781
  time: '46:21'
  who: Alexey
- line: Yes, we use it with Brock Labs’ GR OQ, a great provider offering many models.
    It has low latency 1 to 2 seconds compared to 4 or 5 seconds of GPT-4 or slower
    experience with GPT-5. Latency is a big issue.
  sec: 2788
  time: '46:28'
  who: Michael
- line: We’re still streaming, but recording stopped due to disk space. Ignore the
    glitch, we’re still live.
  sec: 2825
  time: '47:05'
  who: Alexey
- line: I tried a new Chinese LLM from Z AI. It outperformed previous agents I used.
  sec: 2850
  time: '47:30'
  who: Alexey
- line: A simple one-agent system completed complex steps from requirements gathering
    to execution.
  sec: 2905
  time: '48:25'
  who: Alexey
- line: More focused models will emerge. OpenAI’s big models are general purpose,
    but smaller, task-specific efficient models will do the same or better work.
  sec: 2920
  time: '48:40'
  who: Michael
- line: I see more questions. One asks about your career before AI. You mentioned
    development work with oil and gas companies.
  sec: 2953
  time: '49:13'
  who: Alexey
- line: Even back then, I was doing machine learning, data science what some call
    AI now. Before that, I did game development courses involving 2D and 3D graphics.
    This gave me an edge in understanding the math behind AI and deep learning.
  sec: 2971
  time: '49:31'
  who: Michael
- line: It’s common for game developers to move into deep learning because under the
    hood it’s matrix math and tensor operations, similar to graphics calculations.
  sec: 3001
  time: '50:01'
  who: Alexey
- line: Exactly.
  sec: 3018
  time: '50:18'
  who: Michael
- line: You mentioned earlier work diagnosing ADHD with games. Did you continue research
    in that area?
  sec: 3025
  time: '50:25'
  who: Alexey
- line: I worked with Harvard professors in the early 2000s on the application but
    moved on later. I believe they continued with it. Using technology to diagnose
    children is very capable, and some games help in this. But gaming is fun, and
    not all kids engage with the same themes or types of games.
  sec: 3043
  time: '50:43'
  who: Michael
- line: I also worked on cognitive tests at Boston University as a bachelor student.
    They weren’t entertaining though more like routine tests, unlike games like Mario
    Kart or Minecraft that kids enjoy.
  sec: 3104
  time: '51:44'
  who: Alexey
- line: Yes, the theme matters because if kids don’t like the game theme, they’re
    not interested, which can skew experiments. The idea was good for the time, but
    maybe now we could do better with open source or new tools.
  sec: 3144
  time: '52:24'
  who: Michael
- line: In our tests, students took tests for educational credits, not real money.
    Maybe kids would prefer rewards like cookies to make it less boring.
  sec: 3169
  time: '52:49'
  who: Alexey
- line: If there was a formula to make a game everyone wants to play, it would be
    overused because the game industry is highly competitive even more than AI, though
    AI is rising fast.
  sec: 3198
  time: '53:18'
  who: Michael
- header: Cognitive testing, evaluation, and monitoring in AI
- line: For Albin’s question, could you recommend keywords to research this field?
  sec: 3216
  time: '53:36'
  who: Alexey
- line: Look into cognitive testing and executive function, which covers brain functions
    like planning and reasoning and relates to ADHD and other conditions where focus
    and planning are challenging. It aligns well with reasoning and planning in AI.
  sec: 3227
  time: '53:47'
  who: Michael
- line: A fresher with a master's in data science asked whether they should focus
    on machine learning, AI, or LLMs to secure a job. Some data scientists struggle
    to find work compared to ML engineers. What would you advise?
  sec: 3260
  time: '54:20'
  who: Alexey
- line: I suggest focusing on AI engineering. LLMs embed a lot of knowledge and can
    perform many data science tasks, like merging spreadsheets and creating graphs.
  sec: 3316
  time: '55:16'
  who: Michael
- line: Data science itself might not be the best continued path, but data science
    skills evaluating experiments, working with data are useful in AI engineering.
  sec: 3357
  time: '55:57'
  who: Michael
- line: When AI emerged, I was confused by RAG (retrieval-augmented generation), but
    then realized it’s essentially search and information retrieval plus prompt engineering.
    Past experience with search and recommendations is very helpful now.
  sec: 3384
  time: '56:24'
  who: Alexey
- line: Data scientists have valuable skills that remain relevant with LLMs, just
    requiring some new twists and continuous evaluation and experimentation.
  sec: 3448
  time: '57:28'
  who: Alexey
- line: Exactly. One core concept I teach is building evaluation and feedback mechanisms.
    You want to assess agent performance for consistency and understand variance in
    outputs.
  sec: 3459
  time: '57:39'
  who: Michael
- line: For production applications, controlling variables and explaining agent behavior
    is vital. Build evaluation pipelines and use tools like Arize Phoenix to monitor
    LLM communication and prompts, applying data science techniques for success metrics.
  sec: 3484
  time: '58:04'
  who: Michael
- line: We cover Phoenix in our LLM course. For those interested, check out LLM Zoomcamp.
  sec: 3518
  time: '58:38'
  who: Alexey
- header: Publishing details and closing remarks
- line: Before wrapping up, about your second edition of AI Agents in Action if someone
    buys the first edition now, will they get the second automatically?
  sec: 3530
  time: '58:50'
  who: Alexey
- line: I need to confirm with the publisher, but I think the second edition will
    be provided free or as part of the package since it’s releasing within the same
    year.
  sec: 3547
  time: '59:07'
  who: Michael
- line: Maybe to be safe, we can wait for the Meep announcement, which might come
    soon.
  sec: 3570
  time: '59:30'
  who: Alexey
- line: If viewers already understand agents well, they should wait. The first edition
    covers fundamentals, but the second has more advanced and valuable material.
  sec: 3584
  time: '59:44'
  who: Michael
- line: We’ll follow you on LinkedIn for updates. Is your name common or unique?
  sec: 3604
  time: '1:00:04'
  who: Alexey
- line: My name’s spelling is unique, but some others have it too.
  sec: 3610
  time: '1:00:10'
  who: Michael
- line: You’re recognizable. If someone sees a person with a big beard named Michael,
    it’s probably you. We will include your LinkedIn link in the description so people
    can find you easily.
  sec: 3623
  time: '1:00:23'
  who: Alexey
- line: Thanks so much for sharing your expert knowledge and experience. I enjoyed
    this conversation and I’m sure the listeners did too.
  sec: 3640
  time: '1:00:40'
  who: Alexey
- line: Thank you very much for having me.
  sec: 3648
  time: '1:00:48'
  who: Michael

---

Links:

* [Linkedin](https://www.linkedin.com/in/micheal-lanham-189693123/){:target="_blank"}