---
title: "Ace Non-Technical Data Science Interviews"
short: "Ace Non-Technical Data Science Interviews"
guests: [nicksingh]

image: images/podcast/s06e02-non-technical-interviews.jpg

season: 6
episode: 2

ids:
  youtube: tRdLVUKU7Bo
  anchor: Ace-Non-Technical-Data-Science-Interviews---Nick-Singh-e1a5qtd

links:
  youtube: https://www.youtube.com/watch?v=tRdLVUKU7Bo
  anchor: https://anchor.fm/datatalksclub/episodes/Ace-Non-Technical-Data-Science-Interviews---Nick-Singh-e1a5qtd
  spotify: https://open.spotify.com/episode/7tO8GmqAcFUUk4fLqxEXy1
  apple: https://podcasts.apple.com/us/podcast/ace-non-technical-data-science-interviews-nick-singh/id1541710331?i=1000541631687

transcript:
- line: This week, we'll talk about the non-technical parts of a data science interview.
    We already had an episode where we talked about how to prepare a CV and other
    aspects of the interview process. You can go and check our website for it. We
    didn't talk a lot about the behavioral interviews and other less technical parts
    of a data science interview, which is what we are going to cover today. We have
    a special guest today, Nick. Nick started his career as a software engineer on
    Facebook's growth team. Then he worked with a startup called SafeGraph, which
    is an application analytics company. He graduated from the University of Virginia
    with a degree in Systems Engineering. You also interned at Microsoft and Google,
    right?
  sec: 118
  time: '1:58'
  who: Alexey
- line: Google, yes.
  sec: 168
  time: '2:48'
  who: Nick
- line: "As we already know, Nick is an author of a book about acing data science\
    \ interviews. I think the name is \u201CAcing Data Science Interviews\u201D \u2013\
    \ I also have a copy which just arrived."
  sec: 169
  time: '2:49'
  who: Alexey
- line: Yeah, amazing. Just amazing.
  sec: 186
  time: '3:06'
  who: Nick
- line: "Just in time. [laughs] Okay. Anyways \u2013 welcome, Nick."
  sec: 189
  time: '3:09'
  who: Alexey
- line: Thank you for having me. I'm really excited to be part of your community and
    give a little talk, as well as do the Book of the Week a little bit later on in
    the month.
  sec: 194
  time: '3:14'
  who: Nick
- header: "Nick\u2019s background"
- line: Yeah, thanks. Before we go into our main topic of acing interviews (specifically
    behavioral interviews), let's start with your background. Can you tell us about
    your career journey so far?
  sec: 201
  time: '3:21'
  who: Alexey
- line: "Yeah, absolutely. I've had a pretty interesting background that's all around\
    \ data, but in indirect ways. In school, I studied systems engineering, which\
    \ is a sort of mix of operations, research, business, and math. I was on the data\
    \ infrastructure team as an intern at Google. I was also a growth engineer and\
    \ did data driven experimentation, ran and implemented many A/B tests at Facebook.\
    \ Then I joined a location analytics startup called SafeGraph, which sold alternative\
    \ data to hedge funds and retail analytics companies. Most recently, I wrote the\
    \ book \u201CAce a Data Science Interview\u201D which is sort of like \u201CCracking\
    \ the Coding Interview\u201D, or the \u201CLeetCode\u201D for data scientists,\
    \ machine learning engineers, and data analysts. So that's my background around\
    \ data."
  sec: 212
  time: '3:32'
  who: Nick
- header: Being a career coach
- line: "When I read your bio \u2013 I think your book has your biography \u2013 it\
    \ says that you're a career coach. So what do you do as a career coach?"
  sec: 257
  time: '4:17'
  who: Alexey
- line: "Absolutely. These days, I'm super passionate. When COVID hit, I left my job\
    \ and thought, \u201CHmm. A lot of people got laid off or they had their offers\
    \ rescinded.\u201D I knew that there was a lot of advice given on how to break\
    \ into product management and software engineering, but not that much around data\
    \ science. So these days, what I do is work with different people who are trying\
    \ to improve themselves in their interview, help them, and coach them on positioning\
    \ themselves for success in the job market \u2013 how to build portfolio projects,\
    \ improve their resume, and build up those technical skills to land their dream\
    \ jobs in tech as a data scientist, machine learning engineer, or data analyst."
  sec: 270
  time: '4:30'
  who: Nick
- line: So you help people get a job, right?
  sec: 307
  time: '5:07'
  who: Alexey
- line: Exactly. That's my goal nowadays.
  sec: 310
  time: '5:10'
  who: Nick
- header: Overview of the hiring process
- line: "Okay. Let's say I want to find a job, specifically \u2013 a data science\
    \ job. Usually, I apply, send my CV. Then I talk to the recruiter. It's actually\
    \ a whole process, where there are many, many, many different steps. So, what\
    \ are the typical steps in this process?"
  sec: 311
  time: '5:11'
  who: Alexey
- line: "Totally. Of course, it differs from company to company. But some of these\
    \ larger FAANG-type companies, like Facebook, Google, Amazon \u2013 what they\
    \ do is have a phone screening with a recruiter, maybe even the hiring manager,\
    \ if it\u2019s a smaller company. They assess you \u2013 they might give you an\
    \ online assessment, where they often ask either a coding question or a SQL question.\
    \ After these, they usually bring you on-site, (of course in COVID times, there\u2019\
    s no on-site), where it\u2019s just a panel with three or four more interviews\
    \ that encompass technical aspects, more system design open-ended case-type problems,\
    \ as well as, of course, a behavioral interview with your probably soon-to-be\
    \ hiring manager or director, or someone else like that. So it varies, but usually\
    \ it sticks to this script."
  sec: 333
  time: '5:33'
  who: Nick
- line: So there are like four or five interviews in total, right?
  sec: 380
  time: '6:20'
  who: Alexey
- line: Yeah, these days most companies are running four or five interviews by the
    end of it.
  sec: 383
  time: '6:23'
  who: Nick
- line: "Yeah, I remember like six, seven years ago, when I got my first data science\
    \ job, I actually had just one interview. That interview was a bit long, about\
    \ an hour and a half. I mean, maybe by today's standards, this is probably considered\
    \ a short one. But it was just one interview. Maybe it was two, I don't remember\
    \ exactly. But after that interview, a couple of hours later, I got a call about\
    \ an offer. Now, even smaller companies don't do that anymore. I wonder \u2013\
    \ why is that?"
  sec: 388
  time: '6:28'
  who: Alexey
- line: "Exactly. When I'm talking about this four or five round process, it\u2019\
    s definitely more around these unicorn Silicon Valley startups or FAANG-type companies.\
    \ At smaller companies, you might have a more expedited process, partly because\
    \ they realize talent doesn't put up with something like a week's worth of interviewing.\
    \ That's one thing. Another thing, a very interesting mindset they have in hiring\
    \ is that they don't want false positives. They'd rather turn down people who\
    \ are good than have hired somebody who suddenly turns out to be bad, because\
    \ it's very cumbersome to fire somebody and put them on a performance improvement\
    \ plan and things like that. So to weed out these false positives, one easy way\
    \ is just to make a tougher screening process and screen them multiple times.\
    \ That's kind of where the industry is headed recently. It's a pain for candidates,\
    \ so I have complete empathy there. It's a pain, but it's just what it is these\
    \ days."
  sec: 417
  time: '6:57'
  who: Nick
- line: "But also for companies, it's not very easy to find so many people. You have\
    \ to find at least four or five people who can interview the candidates. It\u2019\
    s very difficult. Even smaller startups do that these days."
  sec: 474
  time: '7:54'
  who: Alexey
- line: "Some days you hear \u201COh, all the companies can't find enough talent.\
    \ People are raising their wages.\u201D On the other hand, you still have a lot\
    \ of folks who study data science, who are like, \u201CDude, how do I break in?\
    \ They're only hiring PhDs. They're only hiring people with years of experience.\
    \ How do I break in as a fresh, new graduate from my Master\u2019s or Bachelor's\
    \ program?\u201D So it's a tough matching problem. Companies are complaining about\
    \ talent and talent is complaining about companies. I hope that with the work\
    \ I do, and with what the book does, that it at least bridges the gap a little\
    \ closer so that companies are better able to ask questions and assess talent,\
    \ and talent \u2013 who\u2019s super-skilled technically \u2013 is able to better\
    \ portray their own skills and experience so that they don't get dinged for some\
    \ arbitrary random reason that could have been prevented."
  sec: 489
  time: '8:09'
  who: Nick
- header: Behavioral interviews for data scientists
- line: "When you described the interview process, you mentioned this behavior interview\
    \ part, which is an interview with a hiring manager or a director who assesses\
    \ how good you are as a person? Or don't know \u2013 how well you fit the company\
    \ or the company culture? I don\u2019t think that there is a lot of material out\
    \ there that can help prepare you for that. The technical part is a bit easier,\
    \ because if you just go to your favorite search engine and type something in\
    \ \u2013 you'll find dozens, maybe hundreds of different resources. But if you\
    \ go and type something about a behavioral interview, then maybe it's tougher.\
    \ Right?"
  sec: 538
  time: '8:58'
  who: Alexey
- line: "Yeah. I think there is enough material about behavioral interviews, but it's\
    \ not really geared towards data scientists and machine learning engineers. There\
    \ are things that list these kinds of arbitrary questions where they ask, \u201C\
    Tell me about your biggest weakness.\u201D This is sort of something that you\
    \ would ask a salesperson or something like that, but it's a bit random to be\
    \ asking really smart technical people that kind of question. Often, a lot of\
    \ your hiring is actually around your strengths, not even your weaknesses. There's\
    \ definitely a lot of BS out there from people who haven't been in the game. But\
    \ behavioral interviews are really important."
  sec: 581
  time: '9:41'
  who: Nick
- line: "Definitely, as technical people, we just think, \u201COh, I\u2019ll grind\
    \ LeetCode. Oh, I\u2019ll just practice data structures or SQL or get really good\
    \ at Kaggle, and then I'll be fine.\u201D But there's this behavioral component\
    \ that is important. Behavioral interviews look for soft skills. Let's be honest,\
    \ Alexey, part of being a data scientist isn't just sitting there and building\
    \ a model, it's working with so many different stakeholders. If you're not able\
    \ to hold yourself, talk confidently, argue for your position, or argue for your\
    \ business recommendation, you're not going to be an effective data scientist.\
    \ So much of it is the soft skills, communication, and the ability to present\
    \ your results."
  who: Nick
- line: "Something else these behavioral interviewers look for is position fit and\
    \ culture fit. Let's be honest, people want to work with you and you want to work\
    \ with other people who like you, and you like them. We're not robots and we're\
    \ not machines. We're humans at the end of the day, so of course, there\u2019\
    s going to be this aspect of \u201CDo they fit in well?\u201D I think it is a\
    \ real component. People think, \u201COh, that's just BS.\u201D Amazon, for example,\
    \ has these \u2018Amazonian principles\u2019 that they really adhere to \u2013\
    \ and they\u2019re not for everybody."
  who: Nick
- line: "Startups have their own set of principles, and often, someone from a company\
    \ like Google \u2013 I'm sure they're very smart \u2013 but they just might not\
    \ be a good fit for this type of place. So of course, these behavioral interviews\
    \ also assess not just your soft skills, but just how good you are for this specific\
    \ role and this specific company. There is an art to it, but we can talk a little\
    \ bit more."
  who: Nick
- line: "Basically, it's not enough just to grind LeetCode, learn SQL, and learn all\
    \ the probability theory stuff or machine learning, and expect that it will be\
    \ enough to get the job, right? Because even though you pass all the other interviews,\
    \ there is this 45-minute interview where they don't ask about theory, they don't\
    \ ask about the technical part. Actually, I remember when I interviewed with a\
    \ company a couple of years ago, the name of which starts with F and ends with\
    \ K. They asked me, (I have a list here, because after interviews, I usually try\
    \ to take notes of what they ask, for reference) \u201CTell me about something\
    \ you're proud of.\u201D The second one was, \u201CTell me about a time you disagreed\
    \ and weren\u2019t right.\u201D Then \u201CTell me about a project that got delayed?\
    \ What was the impact? And what did you learn from that?\u201D And then \u201C\
    Tell me about a time that something changed your career.\u201D And the last one\
    \ was, \u201CWhat are your personal areas for improvement? And why?\u201D This\
    \ wasn't out of the blue for me, because I interviewed with big companies before,\
    \ especially in Amazon \u2013 I think that at Amazon, their interviews are\u2026"
  sec: 706
  time: '11:46'
  who: Alexey
- line: They really hone this in, yeah. Leadership principles are really important
    to them.
  sec: 789
  time: '13:09'
  who: Nick
- header: Preparing for behavioral interviews
- line: "I was expecting that, but it\u2019s still very hard to prepare for, right?\
    \ With LeetCode, it\u2019s clear \u2013 you just go to LeetCode and you solve\
    \ some problem."
  sec: 793
  time: '13:13'
  who: Alexey
- line: "Yeah. But there is a way to prepare. There\u2019s good news and bad news.\
    \ The bad news is, it\u2019s work \u2013 it's gonna take some time. The good news\
    \ is \u2013 there's a process. It's not some arbitrary thing that you can't ever\
    \ predict. In the book, I talk about some of these very common questions, and\
    \ you actually got hit with some of the more common ones like, \u201CTell me about\
    \ your proudest career moment.\u201D They\u2019re looking for you to show off.\
    \ That's kind of a well-known question. Another one is, \u201CTalk about an unpopular\
    \ or hard decision that you had to make and how did you deal with it?\u201D That's\
    \ another one where they're trying to see \u201CCan you go against the grain?\
    \ Can you do it tactfully?\u201D Because, of course, as a data scientist, you're\
    \ going to be making some recommendations that rub other people the wrong way\
    \ or you may get a little bit of a pushback. So I think these are very reasonable\
    \ questions."
  sec: 800
  time: '13:20'
  who: Nick
- line: "My advice for you to prepare is \u2013 first of all, think about your three\
    \ most significant experiences. Maybe these are two jobs and one portfolio project.\
    \ Or, if you're still in school, maybe they're all just projects and internships.\
    \ But think about your three most important experiences that you love to talk\
    \ about. In my book, we talked about some of the common questions that are asked,\
    \ but you can find these on the Internet \u2013 what you should do is simply make\
    \ a grid. For each of these questions, you can answer them in the grid, like \u201C\
    What are you most proud of, in this job, this job, or this project?\u201D The\
    \ same way for, \u201CWhat was the hardest part? What was the biggest bug? What\
    \ was something that went haywire and how did you recover? What was the setback?\u201D\
    \ Because really, they fall into these kinds of patterns of like, \u201CWhat did\
    \ good?\u201D \u201CWhat did bad?\u201D and \u201CHow do you deal with it both\
    \ ways?\u201D That's the first thing \u2013 just systemize it with a grid. Put\
    \ it in an Excel sheet, and suddenly that will help you."
  who: Nick
- line: "Now, I know some people listening might be thinking, \u201COh, why do we\
    \ have to prepare so much? This is my own experience. I already know it well enough.\u201D\
    \ But let's be honest, some of these things you talk about are from a job you\
    \ did a year or two ago. You forgot about it \u2013 it's been a year or two, right?\
    \ Let's be honest, we don't talk about ourselves all the time, like, \u201COh,\
    \ the best thing I ever did was this, this, this.\u201D We're used to being a\
    \ little shyer, a little bit more humble. But this is not the time for that. So\
    \ there is some element of practicing to be a little bit boastful \u2013 to get\
    \ those points across of why you're a kick-ass data scientist. It does require\
    \ practice \u2013 it's not gonna come easy. It requires you to talk to the mirror,\
    \ or talk to a friend, or talk to yourself, and verbalize these things and get\
    \ those talking points down. But you can prepare. So that's my first thing, make\
    \ a grid."
  who: Nick
- line: "Now, what do we put in the grid for these questions? Alexey, are you familiar\
    \ with the STAR format by any chance? Yeah, that's a common one. For people who\
    \ might not have heard of it \u2013 and there are really great resources out there\
    \ about it on the internet and also in my book (yes, out there on the internet,\
    \ I don't want to just keep plugging my book) \u2013 the STAR format is basically\
    \ Situation Task Action Result. It's a way to structure your story. I'll give\
    \ you an example. At Facebook, they asked me \u201CWhat's a time you use data\
    \ to make a decision?\u201D Or, this is another common question for a data-oriented\
    \ person, like, \u201CTell me about a time you used data to make a decision.\u201D\
    \ Because they want to hear that you do data-informed decision making. That's\
    \ a big part of our jobs. My answer in the STAR format would be \u2013 the Situation:\
    \ I was at Facebook and I was on the growth team. I was Tasked with figuring out\
    \ \u201CIs Facebook Stories good for new user retention?\u201D Meaning \u201C\
    Is this product helping people who are new to the app, stay on Facebook longer\
    \ (retention rate)?\u201D So that's the Situation (I was at Facebook), the Tasks\
    \ (I need to figure this out). The Actions I took: I analyzed a whole bunch of\
    \ data and wrote lots of SQL queries to understand \u201CHow do new users interact\
    \ with this feature set?\u201D and looked for gaps that I thought could be good\
    \ opportunities. The Result: I was able to actually find real bugs that affected\
    \ new users. Since I was a software engineer, I fixed these bugs. I also made\
    \ recommendations to the Facebook Stories team \u2013 because they didn't really\
    \ think about new users, they just thought about all the users in general, they\
    \ weren't worried about the people who are new to the platform \u2013 that actually\
    \ impacted their next quarter\u2019s roadmap."
  who: Nick
- line: "Do you see how I kind of really forced myself to say Situation Task Action\
    \ Result? Maybe you don't have to be as hard hitting. But did you see just how\
    \ I kind of narrowed down this success story? Like, \u201CWow, this guy actually\
    \ did something with data and impacted Facebook's roadmap. Great!\u201D And I\
    \ kind of said that in probably 8-10 sentences. Of course, I probably said a little\
    \ bit more, but I think you can get these stories down to a minute and a half.\
    \ Those punchy, exact stories that say, \u201CHey, I improved the user retention\
    \ rate and I changed the whole roadmap.\u201D Those are the things that you want\
    \ to get across and they work really well when you narrow down your story to the\
    \ STAR format."
  who: Nick
- line: "Yeah, I guess even if you don't follow this exact format during the interview,\
    \ but when you prepare for the interview and try to stick to this structure \u2013\
    \ this structure will just pop up when you give examples. Maybe you will not follow\
    \ it exactly (Situation, Task, etc) maybe it will be different. But still, if\
    \ you were using this format when preparing, then it\u2019ll help during the interview."
  sec: 1102
  time: '18:22'
  who: Alexey
- line: "100%. Actually, you touched on a good point. I know some people in the audience\
    \ are thinking, \u201COh, I don't want to sound like a robot. I don't want to\
    \ sound so scripted. I don't want to sound rehearsed.\u201D You wish you were\
    \ that good. You wish you were an actor who can just do two minutes of prep in\
    \ the STAR format, and then hit it verbatim. Right? You're not that good. So,\
    \ practicing beforehand won't make you sound like a robot. It will only get your\
    \ point across better. You're not going to sound robotic. People have this mindset,\
    \ like \u201COh, if I prepare, it will hurt me.\u201D Actually, probably not.\
    \ Now, if you're the world's best salesman, maybe you might sound too salesy.\
    \ But let's be honest, most of the data scientists and machine learning engineers\
    \ that are reading this stuff and listening to our podcasts right now \u2013 you're\
    \ not in that position that you just [snaps fingers] and spit out things. So,\
    \ preparation is possible and it takes some work. But if you go systemized, it'll\
    \ work out and you'll present yourself much, much better."
  sec: 1127
  time: '18:47'
  who: Nick
- header: Handling "tricky" questions
- line: "What about tricky questions? For me, a tricky one that I wasn't able to answer\
    \ during the interview I mentioned was \u201CTell me about a time you disagreed\
    \ with someone and weren't right.\u201D For me, I was like, \u201CUm\u2026 I don't\
    \ remember.\u201D So how do you go about these tricky ones? The other one was\
    \ about \u201Ca project that got delayed.\u201D It's a very specific question,\
    \ so in my head I was like \u201COkay, which project did I have in my career that\
    \ actually got delayed? Well\u2026 all of them?\u201D Right? [laughs]"
  sec: 1185
  time: '19:45'
  who: Alexey
- line: "[laughs] All of them, right? Actually, I wish I had a better answer, but\
    \ \u2013 just don't get tricked. You're calling these tricky, but I think I have\
    \ some of these in my book. They're not that tricky \u2013 a delay is a very common\
    \ thing and so a disagreement with somebody else. A common question that I wrote\
    \ in the book is, \u201CTell me about a time you disagreed with a product manager\
    \ or business stakeholder.\u201D That's what your job is. You're going to be working\
    \ with these people. So, they're actually not that tricky."
  sec: 1215
  time: '20:15'
  who: Nick
- line: "I think tricky, in this sense, would be something like, \u201CTell me about\
    \ your three biggest weaknesses.\u201D But these days, honestly, that kind of\
    \ question is a little taboo. People think it's dumb, because the typical answers\
    \ are like, \u201COh, I work too hard. That's my biggest weakness. I care too\
    \ much.\u201D So people have shied away from that question. Of course, at some\
    \ level, they're looking for you to be you. It's okay if you get stumped. But\
    \ preparation definitely makes perfect and then these questions are not actually\
    \ that tricky. They're tricky in the moment, but stepping back \u2013 every project\
    \ gets delayed and every project has their disagreements. It's up to you to think\
    \ about these things before you even step into the interview room."
  who: Nick
- line: Yeah. I think you mentioned Amazon leadership principles. Amazon uses interviews
    to actually find out if people fit this principle. I think these principles kinda
    make sense. I mean, they make sense for many companies. Maybe like, frugality.
    I don't know about every company. But in general, they make sense. What I personally
    found useful when preparing is taking these leadership principles into account.
    I think I selected like two or three projects and put them in a grid. Then I took
    the leadership principles from Amazon and put them in this grid, like how I showed
    these leadership principles in a particular project. That was very helpful, not
    just for Amazon interviews, but for a bunch of other companies as well.
  sec: 1283
  time: '21:23'
  who: Alexey
- line: "Absolutely. Make a grid. As you hinted on, every company thinks that they're\
    \ really unique, but a lot of these questions that are asked are repetitive. A\
    \ lot of the principles of \u201Ccustomer first\u201D \u2013 you know, half the\
    \ companies in Silicon Valley say, \u201COh, we're customer first, profit second.\u201D\
    \ I think Amazon does live by that a little bit better. But I'm just trying to\
    \ say, you're right, putting your work into the grid and really spelling it out\
    \ in the STAR format beforehand, won't just help you at Amazon, it will help you\
    \ with any company. This is the type of work you should be doing before you interview.\
    \ This is why I always say that this whole interview thing is an art. Some people\
    \ just want to show up and think they'll ace the interview. But there's an art\
    \ to preparing and it's not rocket science. But it is work and it is sometimes\
    \ unintuitive."
  sec: 1337
  time: '22:17'
  who: Nick
- line: Another good thing about these Amazon leadership principles is that they are
    available publicly. Not many other similar values of companies are also publicly
    available.
  sec: 1389
  time: '23:09'
  who: Alexey
- line: "Yeah. I say that that's because a lot of companies might not even have those\
    \ values or be as value driven. But I would say if there's a company that is value\
    \ driven, they will publicize it, usually on their \u2018careers\u2019 page or\
    \ their \u2018about\u2019 page. For example, the company I worked at last, SafeGraph,\
    \ was super careers-driven to the point that we had our mission and values put\
    \ on posters in every single room \u2013 every single conference room and in the\
    \ bathroom. So while you're peeing at the urinal, it's right in front of you \u2013\
    \ one foot in front. You can't help but look at it every day and read it and kind\
    \ of live by it. I mean, of course, it goes company to company \u2013 but at my\
    \ company, if you're a pooping, you'd be reading the principles. I think it'll\
    \ be easy. Most companies try their best to publicize it. The ones that do, you\
    \ better expect that they're going to ask you those same kinds of questions. This\
    \ is the kind of prep work you can do beforehand so you don't get stumped. Because\
    \ you know if they publicize it that much, they're going to be asking you about\
    \ it in pretty much every interview. That's another thing I wanted to bring up,\
    \ Alexey \u2013 often at an on-site, for 45 minutes, you might have a strictly\
    \ behavioral interview with a hiring manager. But let's be honest, most interviews\
    \ will start with a kind of, \u201CHey, tell me about yourself. Tell me about\
    \ your project. Tell me about a failure.\u201D These kinds of things seep in not\
    \ just with your last round with the hiring manager, they seep into almost every\
    \ interview. Even at the beginning with the recruiter that says \u201COh, we're\
    \ data driven. Tell me about how you used data to make decisions.\u201D You might\
    \ be hit with that right from the beginning."
  sec: 1405
  time: '23:25'
  who: Nick
- header: Project deep dive
- line: Right. But that's not the only non-technical part of the interview, right?
    There are other parts. So what are they?
  sec: 1504
  time: '25:04'
  who: Alexey
- line: "Yeah. Another really popular one, especially in data science, are these project\
    \ walkthrough questions where they ask you lots of details about work you've done\
    \ in the past. You might be thinking, \u201CBut doesn't every industry have that\
    \ kind of question?\u201D I think in coding, you'll definitely see more of an\
    \ emphasis on things like, \u201CHey, listen. It\u2019s nice that you did this\
    \ project, but\u2026 reverse this link list.\u201D Or like, \u201CHey, that's\
    \ cool. But\u2026 do this graph theory problem. DFS.\u201D Data science is such\
    \ a broad field \u2013 especially in things like machine learning \u2013 that\
    \ they can't really just hit you with like, \u201COkay, let's do linear regression\
    \ now.\u201D So what they often do is, they ask you about your project and then\
    \ if you happen to use, let's say, logistic regression, then they'll ask you lots\
    \ more follow-on questions like, \u201COh, you used logistic regression? Why?\
    \ Why not other techniques? How did you validate assumptions? What performance\
    \ metrics did you use? Did your model overfit? Why or why not? How do you deal\
    \ with overfitting?\u201D"
  sec: 1513
  time: '25:13'
  who: Nick
- line: "This starts getting into the technical realm. But again, it usually starts\
    \ out as more like \u201CTell me about your project and what actually happened?\u201D\
    \ And Alexey, the biggest thing I've noticed, amongst data scientists and data-driven\
    \ people is that they don't talk about the results nearly enough. They talk too\
    \ much about the technical details of a project and not enough about \u201CI did\
    \ this work and it saved the company a million dollars.\u201D or, \u201COh, I\
    \ helped do this and it became the world's best selling this.\u201D You know?"
  who: Nick
- line: "Usually, you see that even in the STAR format, the Result is at the end.\
    \ Often, though, when you're talking about a project, that's called \u2018burying\
    \ the lead\u2019. If you talk about the impact of it at the end, that's not interesting.\
    \ I'd rather that you first tell me \u201CYeah, so this project made a million\
    \ dollars, let me tell you about what I actually did.\u201D Then it\u2019s like,\
    \ \u201COh, wow! That's super cool.\u201D Because at the end of the day, Alexey,\
    \ you're being hired to a business and they just want to see business impact."
  who: Nick
- line: "Sometimes, I hate to tell data scientists this, but how you did it might\
    \ not even matter sometimes. It's more about \u201CWhat actually happened?\u201D\
    \ So, preparing your answers for these project walkthrough questions, and really\
    \ understanding \u201CWhat is the quantifiable business impact? What actually\
    \ happened?\u201D and trying to make that at the start of your story is a real\
    \ skill and a real art. This has nothing to do with your technical abilities.\
    \ It has to do with your preparation and your ability to convey yourself. It's\
    \ a behavioral thing."
  who: Nick
- line: "There\u2019s this pyramid principle from the folks at McKinsey. Basically,\
    \ when they do a presentation to executives \u2013 executives don't have time\
    \ for a lot of stuff. So they just start with the end, like, \u201COkay, this\
    \ is what we want to do at the end.\u201D Or \u201CThis is what the project will\
    \ achieve at the end.\u201D They start with that and then build a pyramid from\
    \ that and then go into details. So you start with the most important thing and\
    \ then build on it. \u201CThis is how we did it. These are the three things that\
    \ actually helped. And for these three things, this is what we did.\u201D So you\
    \ start with the most important thing."
  sec: 1670
  time: '27:50'
  who: Alexey
- line: "Yeah. Exactly. These project walkthrough questions are oftentimes just \u201C\
    Let's hear about your project.\u201D But they can also be good jumping points\
    \ into technical things. It's something you'll see at most companies \u2013 a\
    \ sort of a blend. For example, they'll ask you one time about logistic regression\
    \ in your project, but then they'll also ask about, \u201CHow did you make sure\
    \ the model got productionized?\u201D Or like, \u201CHow did you prevent disagreements?\u201D\
    \ So they\u2019ll mix it in. But it's another one that, if you put the grid out,\
    \ and you really anticipate some of these questions, like, \u201CHey, how did\
    \ you know it was successful? What was the hardest part about the project?\u201D\
    \ There are some very standard questions that I talk about in the book that people\
    \ ask about your projects. As long as you make a grid, STAR it out, and anticipate\
    \ these things, you'll not only do well on behavioral, you'll also do well on\
    \ these sort of semi-technical questions. You can anticipate that they're going\
    \ to ask you something like, \u201CIf you used this type of model, why not that?\u201D"
  sec: 1708
  time: '28:28'
  who: Nick
- line: "Yeah. I also take part in interviews quite often \u2013 I interview people.\
    \ Usually these are the kinds of questions that I ask in the screening interview.\
    \ The very first interview, I ask, \u201CHey, let's talk about your background.\
    \ What kind of things have you worked on?\u201D and then \u201COkay, now let's\
    \ select one of the projects and do a deep dive into that project.\u201D Then\
    \ we will do what you call the project walkthrough. \u201CWell, this is the project\
    \ you took part in. Let's talk about that.\u201D Actually, I usually ask, \u201C\
    What kind of project do you want to talk about? Pick one and let's talk about\
    \ that.\u201D This is how it usually happens at other interviews?"
  sec: 1765
  time: '29:25'
  who: Alexey
- line: "Yep. That's exactly it. You're falling into what most companies do. At the\
    \ end of the day, they're not really trying to do a \u201Cgotcha\u201D. They'll\
    \ let you talk about what you want to talk about. But then, if that's the trade\
    \ off \u2013 if they're gonna let you pick \u2013 then you better come damn prepared\
    \ to talk about your favorite project. Usually, pick two things, like your most\
    \ important work experience and if you\u2019re a junior in your career, maybe\
    \ also a portfolio project or side project that's really interesting. So come\
    \ damn prepared, because if they're gonna let you pick your project, you better\
    \ know every detail. Often they are trying to just see if you are BSing on your\
    \ project. It's so easy to be like, \u201COh, yeah, I did all this.\u201D And\
    \ then it turns out, \u201CNo, you and a team of seven people did this.\u201D\
    \ Back in the day, in school projects, you'd be a group of four and usually, two\
    \ of the four people even did the work, right? That's why they do these project\
    \ walkthrough questions just to see, \u201CDid you actually do what you said you\
    \ did? Do you actually understand things?\u201D"
  sec: 1804
  time: '30:04'
  who: Nick
- header: Business context
- line: "When we talk about projects, what I often notice is that candidates don't\
    \ give enough business context. They immediately jump into technical things like,\
    \ \u201CI used logistic regression and it had 70% accuracy. It wasn't good enough,\
    \ so I used XGBoost and it hit 80% of accuracy.\u201D \u201COh, cool. But tell\
    \ me why. Why did you do this? What was the business problem you were solving?\
    \ What were you trying to achieve with this? At the end, what did you actually\
    \ achieve? Did it help solve the problem?\u201D"
  sec: 1866
  time: '31:06'
  who: Alexey
- line: "See, if they started with the result, they wouldn't even just say, \u201C\
    I achieved this percent accuracy.\u201D Right? Because then I would have pushed\
    \ and said \u2013 the business doesn't get paid in accuracy. They get paid in,\
    \ \u201CIt drove this many dollars,\u201D or like, \u201CIt reduced false negatives\
    \ here by X percentage, which reduced costs of this manual review process.\u201D\
    \ Once you bring in, as you said, the pyramid principle \u2013 bring up that result\
    \ higher and then make that result, a business result, a product result, not a\
    \ technical result. You'll find yourself coming across as a much more mature data\
    \ person. At the end of the day, you're there to drive business results, not to\
    \ improve the accuracy of some small thing by X percentage without the product\
    \ or business context."
  sec: 1900
  time: '31:40'
  who: Nick
- line: How much time do you think people should spend on giving the business context
    when they answer these kinds of questions?
  sec: 1949
  time: '32:29'
  who: Alexey
- line: "Nobody loves people who ramble. So just try to keep your whole answer to\
    \ like two minutes. One interesting thing I've noticed, Alexey, when coaching\
    \ different people is \u2013 in some cultures, people try to be exhaustive and\
    \ give every single detail, because they think that if they don't hit every point,\
    \ they're going to get points dinged. But I think what you\u2019ve got to think\
    \ about is that this is a conversation. You're having a conversation with your\
    \ future boss or future coworker. So don't just shoot off rapid fire \u201COh,\
    \ here's everything I did here, all the technical details, blah, blah, blah.\u201D\
    \ If you're talking to a normal person, it's just like, \u201CDude, I don't even\
    \ need to hit all these technical details. Let's first talk about \u2018this is\
    \ what I did was really cool because of this\u2019\u201D I think if people frame\
    \ it as a conversation with their future coworker and less like, \u201COh, they're\
    \ trying to quiz me and get me.\u201D That mindset change will itself lend you\
    \ to have better answers. Then your specific question \u2013 sorry, what was your\
    \ specific question again?"
  sec: 1956
  time: '32:36'
  who: Nick
- line: How much time we should spend on business context.
  sec: 2016
  time: '33:36'
  who: Alexey
- line: "So yeah \u2013 don't ramble. Keep it to two minutes. First of all, keep it\
    \ to two minutes \u2013 in a business context, I don't know, it could be a good\
    \ 45 seconds. Of course, if they're curious about one thing or another, they're\
    \ gonna ask questions because it\u2019s a conversation. So keep things on the\
    \ shorter end. Again, preparing beforehand will stop you from rambling."
  sec: 2018
  time: '33:38'
  who: Nick
- header: Pacing, rambling, and honesty
- line: "You actually brought up a good point \u2013 when somebody is trying to cover\
    \ every single detail. When I interview, I don't feel very good saying, \u201C\
    Hey, stop. Let's not go into details,\u201D because then I would have to interrupt.\
    \ But I often have to do this because, you know, we have a limited amount of time\
    \ and we want to cover many things. But definitely don't feel good about, you\
    \ know\u2026 shutting a person up by asking them to stop."
  sec: 2039
  time: '33:59'
  who: Alexey
- line: "Alexey, you're not unique in feeling bad. So you know what happens? You just\
    \ let them ramble. And then you walk away and you say, \u201COh, I didn't really\
    \ like this person,\u201D and they got rejected. Then they're like, \u201COh,\
    \ well\u2026 I hit every point and said everything amazingly. F that company\u2026\
    \ I did amazing.\u201D People feel awkward to shut somebody down, but they are\
    \ also not self-aware of the fact that they've been talking for seven-eight minutes\
    \ and didn\u2019t even make sense. People use so much jargon and this and that.\
    \ I have some crazy stories of that where it's just like \u2013 I'll give you\
    \ an example. Hopefully she's not listening."
  sec: 2070
  time: '34:30'
  who: Nick
- line: "This person worked on a male contraceptive device, so that's already an interesting\
    \ topic. But they didn't even talk about that. They said, \u201COh, I'm doing\
    \ some testing around a medical device, blah, blah, blah, survival analysis.\u201D\
    \ I couldn't keep track of what they were saying. I'm like, \u201CYo, I'm in data.\
    \ I have no idea what you're saying.\u201D I happen to know this person personally.\
    \ I'm like, \u201CDude, why don't you just start from the top?\u201D Like \u201C\
    Oh, I work at a company that's making a male contraceptive. And one of the biggest\
    \ things is \u2013 how long will it work? Will it work for a year or two? So I\
    \ did survival analysis.\u201D If they just said that, then I'd be like, \u201C\
    Oh yeah, survival analysis. Great. Let's talk about the results.\u201D"
  who: Nick
- line: "But they buried the lead and just said, \u201COh, obscure medical device.\
    \ This, this, this\u2026\u201D and ranted on and I could not understand it. It\
    \ is so easy to fall into that trap. Everyone thinks, \u201COh, yeah. That's other\
    \ people making that mistake. I will never make that mistake.\u201D But my goodness,\
    \ it is so easy \u2013 especially for people who don't talk for a living. If you're\
    \ not a salesperson or marketing expert, you're gonna fall into these traps. So\
    \ all you can do is prepare."
  who: Nick
- line: "Yeah, exactly. Because if I don't prepare, the behavioral questions like\
    \ the ones I mentioned will have me puzzled, like \u201COkay, what do I answer?\
    \ I don't know.\u201D Then I answer. \u201CYeah, sorry.\u201D Even worse, I can\
    \ start rambling and lose 10 minutes of time without really answering the thing.\
    \ Yeah. You mentioned that people can sometimes start sprinkling buzzwords in\
    \ their rant. There is a comment that says \u201CI once interviewed somebody who\
    \ said they used SVM in a project, but they couldn't really walk through what\
    \ the model is or what the reason for choosing this model was.\u201D I think this\
    \ is the reason we have these kinds of interview questions \u2013 to understand\
    \ how much the person actually knows. I guess this is getting on the technical\
    \ side, but the non-technical part of this would be \u2013 maybe if you don't\
    \ know much about these things, maybe don't talk about them, right?"
  sec: 2174
  time: '36:14'
  who: Alexey
- line: "Right! Write real bullets on your thing, because you're going to be asked\
    \ about them. Let's be honest and let's say you did do SVM and you just don't\
    \ know everything about it. Well, go prepare that before your interview, because\
    \ you better believe they're going to ask about it. That's why some people who\
    \ know linear regression \u2013 or do a linear regression project \u2013 but they\
    \ really understand that, they might do better than someone who made some crazy\
    \ RNN or CNN using TensorFlow and Keras, but literally doesn't know what the foundations\
    \ of this field are. But, that's what they get assessed on. So, it goes both ways\
    \ \u2013 technical and behavioral. In our field, we just can't ask a LeetCode-type\
    \ question that's like, \u201COh, Tell me everything you know about SVM? Let's\
    \ test you.\u201D That's why they come through with these conversations. If you're\
    \ having a conversation, there's no right or wrong answer. Suddenly, it\u2019\
    s just behavioral stuff around pacing, not rambling, preparing STAR format \u2013\
    \ that stuff starts to matter."
  sec: 2238
  time: '37:18'
  who: Nick
- header: "\u201CWhat\u2019s your favorite model?\u201D"
- line: "I remember in one interview, the interviewer asked me, \u201CHey, what's\
    \ your favorite model?\u201D And then I thought, \u201COkay, the next question\
    \ will be \u2018tell me how this model actually works.\u2019\u201D So I answered\
    \ \u201Clinear regression.\u201D And then he was like \u201COh, what's your second\
    \ favorite one?\u201D He wanted me to pick something more complex. [laughs]"
  sec: 2297
  time: '38:17'
  who: Alexey
- line: "Ah, okay. Usually what I've seen \u2013 and I talk about it in the book,\
    \ \u201CAce a Data Science Interview\u201D \u2013 I've seen \u201CWhat's your\
    \ favorite model?\u201D Then they say something really crazy and then the follow\
    \ up question is like, \u201COkay, so what do you know about it?\u201D And they're\
    \ like, \u201COh\u2026 I read a research paper like seven months ago \u2013 I\
    \ never used it.\u201D You're better off answering with something that you've\
    \ actually used in a project. Because think about this, \u201COh, yeah. I love\
    \ linear regression. I made a million dollars with it in the stock market.\u201D\
    \ Suddenly, even if they want something more complex \u2013 do you see how I just\
    \ twisted so that they're like, \u201Coh, wait\u2026 what? Tell me more.\u201D\
    \ \u201COh, okay. Yeah. It turns out that predicting the oil prices is just like\
    \ a linear regression based on these four variables. Then I did PCA to find that\
    \ these four variables are the best predicatively. And I made a million dollars.\u201D\
    \ Wow. Suddenly, your project was amazing, even though it's linear regression.\
    \ Maybe sometimes people will push you to talk about something more complex, but\
    \ I think linear regression, honestly, is a great answer for \u201Cwhat's your\
    \ favorite model?\u201D Or decision trees, random forest \u2013 great."
  sec: 2316
  time: '38:36'
  who: Nick
- header: "What if I haven\u2019t worked on a project that brought $1 mln?"
- line: What if I haven't worked on a project that brought $1 million? What do I pick?
  sec: 2375
  time: '39:35'
  who: Alexey
- line: "Perfect. Yeah, that's a real question. Because let's say you're a student\
    \ and all you've done is internships or not even any internships. I feel like\
    \ there's an art to being able to quantify your impact. In my book, I talk a ton\
    \ about the value of making kick-ass portfolio projects. You can always quantify\
    \ your impact like, \u201C7000 people use my little web app.\u201D or \u201C\u2026\
    downloaded my Chrome extension\u201D, or something like that. You can always find\
    \ some clever way to quantify it. It doesn't even have to be a million dollars.\
    \ Maybe it's something like, \u201CI reduced the latency by 5%.\u201D Or like,\
    \ \u201CI increased AUC by 7%.\u201D"
  sec: 2382
  time: '39:42'
  who: Nick
- line: "I mean, those are a little bit more technical and yes, you may not have a\
    \ real business impact because it's a pet project. But go with the technical impact,\
    \ because at least some impact is better than \u201CI just did something,\u201D\
    \ and there's no impact. But you're right, there's a benefit to doing real business\
    \ things. Wherever you can, try to work on more real things \u2013 scrape your\
    \ favorite websites, look at their data, so that at least it's somewhat more realistic\
    \ than doing a very pet project and saying there was no business impact."
  who: Nick
- header: Different questions for different levels
- line: How do you think these questions vary? How are they different for different
    levels? I imagine that if somebody is interviewing for a junior position, the
    questions they get are a bit different from somebody who's interviewing for a
    senior position, or even above that.
  sec: 2455
  time: '40:55'
  who: Alexey
- line: "Like staff or at principal \u2013 yeah. I think behavioral questions about\
    \ \u2018your biggest failure in this and that\u2019 are going to be asked at every\
    \ level, because everyone should have some kind of failure. I think just at the\
    \ higher levels, you have to give more mature answers. Often, there, you might\
    \ be asked more people-type questions, because often, a lot of being a principal\
    \ or director of data science, is maybe less about being the world's best expert\
    \ at one specific technique and more about, \u201CHey, how do you work with others\
    \ to drive an initiative or business impact?\u201D This is exactly why questions\
    \ about your project delay or dealing with tough personalities are so popular.\
    \ There might be more of an emphasis on the human aspect for the senior roles\
    \ compared to junior roles. You just want to know more about their technical details\
    \ on a project or how they dealt with failure, but not necessarily like, \u201C\
    Oh, tell me what the 11 personalities that are responsible in a seven year project\
    \ you did.\u201D So I think that's one thing."
  sec: 2471
  time: '41:11'
  who: Nick
- line: "Then, going technical for a second, another thing you might be asked is some\
    \ simple SQL questions at all kinds of levels. But I think more open-ended case\
    \ studies are expected for senior talent. If you want, we can talk about that.\
    \ These open-ended case studies often incorporate business or product sense. I'll\
    \ give you an example. One question might be \u201CWhat metrics would you use\
    \ to quantify the success of Facebook dating?\u201D That's an example of a question.\
    \ Here's another open-ended question. That one is more like a product-sensy question\
    \ around product metrics. Here's an open-ended one that's more like system designing,\
    \ which is \u201CHow would you go about building Uber's surge-pricing algorithm?\u201D\
    \ For both of these kinds of open-ended questions, for more senior roles, you'll\
    \ be asked to give more mature answers and have more interesting thoughts and\
    \ perspectives."
  who: Nick
- line: "Whereas a junior person might just jump into the answer and be like, \u201C\
    Oh, Uber surge-pricing, I'd use this algorithm.\u201D But a more senior person\
    \ would be like, \u201CWhy are we even building the surge-pricing algorithm? Is\
    \ it to balance supply and demand? Is it that drivers are complaining that they're\
    \ leaving money on the table? Or is it that riders are complaining that they can't\
    \ get a cab because it's New Year's Eve, and there's just not enough drivers,\
    \ and they wish there were more cabs on the market?\u201D Who is motivating this\
    \ problem? Or is it Uber who's like, \u201CDude, I think I could make more money.\
    \ Things are working right now, but if I just doubled my pricing, I could probably\
    \ make 50% more money without much drop-off. Who is motivating this problem? I\
    \ mean, all parts of it are probably real for surge pricing. But these are the\
    \ kind of maturity things you get for questions aimed at more senior people and\
    \ what kind of answer that they give."
  who: Nick
- line: "Okay, so for case studies, basically \u2013 if you're interviewing for a\
    \ senior position, when they ask questions, you do not jump into a solution immediately.\
    \ You first ask \u201CWhy?\u201D \u2013 \u201CWhy are we even talking about this\
    \ problem?\u201D As well as \u201CWho is motivating this problem? Where is it\
    \ coming from?\u201D Right?"
  sec: 2648
  time: '44:08'
  who: Alexey
- line: "Yeah, exactly. I want to caveat one thing, though. This kind of framework\
    \ of clarifying, I think it's true for all levels. I'm just saying the way the\
    \ senior management might clarify would be more interesting than a junior person.\
    \ A junior person would be like, \u201CWhat are the technical requirements?\u201D\
    \ And a senior person might be like, \u201CIs this a one-year initiative or are\
    \ we just trying to MVP it?\u201D Because they\u2019re used to some projects being\
    \ a two-month MVP and some might be a year long. But a junior person is not even\
    \ thinking like, \u201COh, I didn't know there's a multi-year Uber surge pricing\
    \ thing.\u201D I mean, at Uber, there's going to be a whole team around it. It's\
    \ probably a multi-year project where they\u2019re going to keep improving it.\
    \ So I don't want to make it seem like \u201COh, if you're Junior, just jump in.\u201D\
    \ I think at all levels, we should clarify. I think it's one of the biggest tips\
    \ I give in chapters 10 and 11, which are about product sense and case interviews.\
    \ It's the framework on how to approach these open-ended questions. The first\
    \ step, as you said \u2013 clarify, clarify, clarify. That's exactly the first\
    \ step."
  sec: 2667
  time: '44:27'
  who: Nick
- header: Product-sense interviews
- line: Maybe you can tell us a bit more about what these product-sense interviews
    are? What are they about?
  sec: 2725
  time: '45:25'
  who: Alexey
- line: "Sure. So product-sense interviews are not asked by every company, but they\
    \ are asked by more product-driven companies like Facebook, as well as for roles\
    \ like product data science, business analytics, marketing analytics. Most analytic\
    \ shops will have this, but also for more product-oriented roles, where you're\
    \ actually supporting a PM and engineers. So companies like Facebook, Uber, Snapchat,\
    \ Airbnb will ask these more product-oriented questions. They're kind of similar\
    \ to what PMs (product managers) will be asked in interviews, but often have a\
    \ more data spin to them. The reason these questions are asked is because in these\
    \ kinds of companies, product data scientists work hand-in-hand with PMs to develop\
    \ the roadmap. So if you don't have a good product sense, how are you going to\
    \ help develop the product roadmap with the PM? That's why these products-sense\
    \ questions like, \u201CWhat would be the success metrics you'd use for Facebook\
    \ dating?\u201D Or, \u201CHey, do you have any product improvement ideas on how\
    \ to improve retention or engagement of this feature?\u201D are asked to even\
    \ data scientists, not just product managers, at these types of companies."
  sec: 2730
  time: '45:30'
  who: Nick
- line: "If I get a question, like, \u201CWe have this feature \u2013 how do you think\
    \ we should go about improving it? What should we do?\u201D What kind of answer\
    \ is expected? Should I go \u201COh, let's change this button from red to blue,\
    \ maybe more people will like it.\u201D What kind of answer is expected there?"
  sec: 2813
  time: '46:53'
  who: Alexey
- line: "So let's say your question was, \u201CHow do we improve engagement for Facebook\
    \ Live?\u201D The first thing is actually \u2013 again, you're going to notice\
    \ a theme here \u2013 you have to do your homework, you have to do your prep work,\
    \ get to know the company and know their products. Because you're allowed to clarify\
    \ like, \u201COh, can you tell me more about Facebook Live?\u201D Or like, \u201C\
    Hey, I don't really use Facebook much, but I'm guessing it's a lot like YouTube\
    \ Live.\u201D It's a conversation, so the interviewer will be like, \u201CYeah,\
    \ it is. Think of it as YouTube Live, honestly.\u201D That's the first thing.\
    \ You have to prepare and know your products, because otherwise, how the hell\
    \ are you gonna answer your question? Let's be honest, these companies are not\
    \ going to ask \u2013 Uber is not going to ask about Facebook Live. Facebook's\
    \ gonna ask about Facebook Live. Uber is going to ask about surge pricing, or\
    \ something to do with \u201CHow would you improve the rider/driver app?\u201D\
    \ Right?"
  sec: 2833
  time: '47:13'
  who: Nick
- line: "Usually, the first thing you try to do is, again, clarify. I talk about that\
    \ framework in our book. You first have to say, \u201CHey! When you say \u2018\
    improve,\u2019 what are we trying to improve? What's the key metric we're trying\
    \ to improve?\u201D Because \u2018improve\u2019 is a very nebulous term and at\
    \ these large product-driven companies, there are metrics like \u2018engagement\u2019\
    \ or \u2018revenue\u2019 or \u2018time spent\u2019 that they want to improve.\
    \ I think for an improvement thing, that's a little bit less popularly asked.\
    \ But there, you just start brainstorming like, \u201CI know for engagement, this\
    \ has worked well at my past company, so I could try this.\u201D or like, \u201C\
    I know that pop-ups or notifications are always great for engagement. So I'd look\
    \ at Facebook Live and look at their notifications and see if we can do more real-time\
    \ notifications on the product.\u201D"
  who: Nick
- line: "There the interviewer will usually help navigate you to something that they\
    \ want to talk about. I know that that\u2019s such an open-ended question, \u201C\
    How do you improve Facebook Live engagement?\u201D That's too hard of a question.\
    \ Usually, it's a conversation \u2013 they'll narrow it down for you. It's not\
    \ as daunting as it seems. But definitely a mistake would be to just jump in and\
    \ say something like, \u201COh, I would add this feature.\u201D You know \u2013\
    \ without even clarifying \u201CWhat are we trying to do?\u201D and \u201CWhat's\
    \ the product and business goal that we need to align our answer with?\u201D"
  who: Nick
- header: Identifying key metrics in unfamiliar domains
- line: "One of the things you mentioned is that we need to say \u201CWhat is the\
    \ key metric?\u201D I think this is a tricky one, especially if you don't have\
    \ a lot of experience in this particular domain. Maybe you're even a senior already.\
    \ I work in online classifieds, so I can understand what kinds of things are important\
    \ in this domain. But if I go to a different website, outside of my typical expertise,\
    \ let's say Uber \u2013 I don't know much about Uber. I don't know much about\
    \ this domain. How do I come up with good metrics? Not just a set of metrics,\
    \ but the key metrics?"
  sec: 2974
  time: '49:34'
  who: Alexey
- line: "I'll tell you the politically correct answer and then I'll tell you the real\
    \ answer. I talk about this in my book as well. The politically correct answer\
    \ is \u201CAlexey, you don't need to know about Uber\u2019s business. We're judging\
    \ all candidates fairly, and it's okay that you have a different background. We'll\
    \ give you the context needed to answer the question.\u201D That's the politically\
    \ correct answer. Now here's the real answer. I'm an interviewer, I work at Uber.\
    \ All day, I'm thinking about this damn problem around surge pricing. All day,\
    \ the management's beating my ass saying, \u201CHey, we're dropping. Our driver\
    \ numbers are not good. Riders are happy to pay money, but we can't recruit drivers\
    \ fast enough in peak times. We can't bring them online.\u201D So they're worried\
    \ about that all the time."
  sec: 3011
  time: '50:11'
  who: Nick
- line: "Then, guess who they're interviewing you against, Alexey? An internal candidate,\
    \ an intern who's now looking for a return offer, two people who worked at Lyft,\
    \ someone who worked at Facebook and had a similar problem, and then you \u2013\
    \ who might not have contacts? So they tell you, \u201COh, we're all looking at\
    \ you equally.\u201D But let's be honest, the internal Uber candidate has a leg\
    \ up, right? So how do you fix yourself? Again, for people watching at home, this\
    \ is not to discourage you so that you\u2019re like, \u201COh, crap, I'm never\
    \ gonna get a job at Uber, because there are Uber internal candidates.\u201D It's\
    \ not like that. But there is an art to preparing. Again, I talk about that in\
    \ the book \u2013 that are some tactical ways to prepare for these product interviews."
  who: Nick
- line: "One way to prepare is \u2013 Uber\u2019s a public company. You can read their\
    \ reports. You can see what financial metrics they're reporting against. You can\
    \ see their CEO, Dara, saying, \u201CHey, listen. We're trying to focus on profit\
    \ because we have great revenues, but not good profits. So we're working on that.\u201D\
    \ That's one way that you can actually see these things broken down. Secondly,\
    \ go look on Reddit. Go look on Quora. Go read news stories around Uber. You'll\
    \ start seeing actual business analysts and stock reporters and things like that,\
    \ talk about the metrics you need. Even if you don't have perfect context, if\
    \ you're a reasonably smart data scientist, and you do your homework \u2013 you\
    \ look at their public reports, you look at the news, you look at what people\
    \ are saying \u2013 you can get yourself a leg up."
  who: Nick
- line: "Or let's pretend that we\u2019re talking about a private company. There's\
    \ usually a public comparable that you can look at. You know what I mean? For\
    \ a while, DoorDash was private, but you could have always looked at UberEats\
    \ data or GrubHub data and find these answers. So that's probably my first answer,\
    \ which is \u201CDo your damn homework.\u201D Because it'll give you an unfair\
    \ leg up. Someone might be thinking, \u201CHey, that's not fair. That doesn't\
    \ mean we're smart. That just means you did your homework.\u201D But let's face\
    \ it, doing your homework is going to give you a leg up. If you're trying to get\
    \ a job at Uber, knowing the ins and outs of the Uber product is gonna help you\
    \ for sure."
  who: Nick
- line: "What if you're interviewed for Google or Microsoft \u2013 or some giant tech\
    \ company that is doing everything?"
  sec: 3183
  time: '53:03'
  who: Alexey
- line: "Yeah. Then I think you'd still want to know what their product set was. Oftentimes,\
    \ you might know what team you're interviewing with. Honestly, these days, if\
    \ it's data scientists at GCP (Google Cloud Platform), there might be 100 teams\
    \ there, but it's still GCP. It's not something else. Go read the earnings reports\
    \ or go see what Azure and AWS are doing. Then that will give you a leg up. Of\
    \ course, they can still hit you with something that surprises you, or they might\
    \ ask about something really weird. But then, of course, they will usually be\
    \ smart enough to give you a little bit more context. It's not like you have to\
    \ know every product and every product line, but I'm just trying to tell you \u201C\
    Hey, if you know, overall, what GCP is struggling with, you will have a better\
    \ sense of how to answer them.\u201D Or \u201CIf you know something more about\
    \ cloud computing, or how enterprises use the cloud and what metrics they look\
    \ at like \u2018total cost of ownership\u2019, you will have a leg up\u201D"
  sec: 3191
  time: '53:11'
  who: Nick
- line: "Even just knowing the term \u2018Total Cost of Ownership\u2019 is not something\
    \ that a junior data scientist might know, but a senior business leader thinks\
    \ about it all the time. I think there's always a way. I also think that there's\
    \ no foolproof method for any of this. You can always get stumped. You can always\
    \ be asked about a product in a weird way or an interviewer might not like your\
    \ answer \u2013 but all we can do is improve your odds. It's a process, but if\
    \ you improve your odds significantly and you play the numbers game that is hiring\
    \ \u2013 you're not just ever interviewing for one company or not even interviewing\
    \ with 10. If you can go from getting one offer out of 10 to 2 out of ten, we're\
    \ in business. You're making money. This is great. So there's no foolproof plan.\
    \ All we can do is have better chances."
  who: Nick
- header: Tech blogs
- line: "Each company usually has a tech blog. In the blog, they talk about use cases.\
    \ Not always, but sometimes, in our tech blog at OLX, we say \u201CThis is the\
    \ metric we care about and this is what we want to optimize.\u201D So the end\
    \ goal for this project was to impact this metric."
  sec: 3295
  time: '54:55'
  who: Alexey
- line: "100%. That's one of the best ways to prepare. I can't believe I forgot to\
    \ mention this. But I talk about it in the book and on LinkedIn all the time.\
    \ Case studies are one of the best ways to level up, because it's more than just,\
    \ \u201COh, we use linear regression.\u201D It's you explaining \u201CWhat was\
    \ the business problem? What was the product problem? What were the technical\
    \ techniques used? How did we productionize our system? And in this era, where\
    \ ML Ops is important and people are talking about productionization and deployment\
    \ \u2013 it's not just enough to build the models. Reading these technical blogs\
    \ gives you this in-depth understanding around a business and around this problem\
    \ that simply reading about it in a textbook \u201COh, here's how you do linear\
    \ regression\u201D just doesn't give you. So, you're 100% right. Go read their\
    \ tech blog before you interview with a company."
  sec: 3322
  time: '55:22'
  who: Nick
- line: "I have a funny story about that. A friend of mine was interviewing with SoundCloud.\
    \ Do you know SoundCloud? It\u2019s like Spotify. So, he was being interviewed\
    \ there and he read their blog. They were doing the system design interview and\
    \ then they asked, \u201CHey, let's design the search for SoundCloud.\u201D Then\
    \ he did the design and then they said, \u201COh, really cool. It's almost like\
    \ the search system that we already have.\u201D And he said, \u201CYes, I read\
    \ your blog and basically just followed whatever you wrote and designed the system\
    \ like you did in your blog post.\u201D OOPS! [laughs] It was funny."
  sec: 3372
  time: '56:12'
  who: Alexey
- line: "Yeah. It can happen. You might be thinking, like, \u201COh, did that guy\
    \ fail?\u201D But actually no, the guy 1) showed that he knew their architecture\
    \ and cared enough to read their tech blog. Remember, right at the beginning,\
    \ we talked about position and culture fit? Alexey, let's be honest, some of being\
    \ a good employee is just giving a damn. So if you read their technical blog before\
    \ your interview, they realize, \u201COh, this guy actually cared enough to read\
    \ the blog.\u201D You're already scoring high marks. They're like, \u201COh, this\
    \ guy didn't just shotgun applications or just sprayed and prayed. They actually\
    \ care about SoundCloud and they care about engineering enough to read our tech\
    \ blog.\u201D"
  sec: 3410
  time: '56:50'
  who: Nick
- line: "That's the first thing and the second thing is \u2013 dude, he gave a correct\
    \ answer because that's all these engineering guys know \u2013 their own architecture.\
    \ Someone who just regurgitates that? It's just like, \u201COh, wow! That's pretty\
    \ good.\u201D Now, of course, they should have asked a better question, not something\
    \ from their own blog. But you'd be surprised how often this happens. Listen,\
    \ I'm going to look for any advantage. The politically correct answer would be\
    \ like, \u201COh, they should have nullified that and said he read the blog. So\
    \ they should have not given him any marks.\u201D But let's be honest, he crushed\
    \ it. I hate to say that, but yeah. It's on SoundCloud to ask better questions\
    \ \u2013 but as a candidate, go do that and you will crush it. But just don't\
    \ lie about it. Don't be like, \u201COh, I had no idea you had a blog about this.\u201D\
    \ As long as you're upfront, they're gonna be like, \u201COh, dope. That's pretty\
    \ cool.\u201D"
  who: Nick
- header: Cold emailing
- line: "Yeah, thanks. There was something I wanted to ask you about the book. When\
    \ I was ordering this on Amazon, I looked at reviews just because I was curious.\
    \ In the reviews, many people actually mentioned the \u2018cold emailing\u2019\
    \ tip. They said that this was the most useful thing from the book. I wanted to\
    \ ask you \u2013 what is this thing?"
  sec: 3506
  time: '58:26'
  who: Alexey
- line: "Alright. So, I'm a little biased. I think, out of this book, the most interesting\
    \ part is the 201 Real Questions. But I feel like questions are just questions,\
    \ right? It's great practice, but no one's like, \u201COh, my God. That changed\
    \ my life.\u201D I think the thing that gave most people a \u2018light bulb\u2019\
    \ moment, or something that really changed their outlook was my chapter on sending\
    \ cold emails. A cold email is an email sent to a stranger \u2013 someone you\
    \ don't know. Someone you did know would be a warm introduction, or if it was\
    \ a friend of a friend, that's warm. Cold emails are emails to a complete stranger.\
    \ It's not just even about email, you could send it on LinkedIn, you could send\
    \ it as a cold Twitter DM \u2013 but the point is, people are willing to help\
    \ you."
  sec: 3530
  time: '58:50'
  who: Nick
- line: If you reach out to people you don't know, you will be surprised by the results.
    I got my last job at SafeGraph by writing a cold email to the CEO and I put it
    up on my LinkedIn, what that email looked like. I talk about this all the time.
    I think people just love this chapter because they thought that they had to apply
    online with 300 other people, waiting to get their resume screened. Often, they
    never hear back. They don't even get an interview.
  who: Nick
- line: "So this kind of changes it up, because you're actually doing the reach-outs.\
    \ When you write a good reach-out to somebody and say, \u201CHey, listen. I see\
    \ you work at Uber. I analyzed the free data around New York City taxis. And I\
    \ analyze this. I made a public Tableau dashboard here. And I did some analysis\
    \ with SciKit Learn here. It's on my GitHub.\u201D And you will link those two\
    \ things to a hiring manager who was working on surge pricing. They're going to\
    \ be like, \u201COh, that's awesome. Cool. We would love to talk to you.\u201D\
    \ Or like, \u201COh, yeah. I just forwarded you to the recruiter.\u201D People\
    \ just don't know that they can build portfolio projects and then email people\
    \ \u2013 the right people \u2013 to get ahead of this game of just applying online\
    \ and never hearing back. I think that's why people love it."
  who: Nick
- line: That's cool. So this is basically the cover letter. But you don't send this
    cover letter to the recruiter, right? You send this cover letter directly to the
    hiring manager.
  sec: 3648
  time: '1:00:48'
  who: Alexey
- line: "You could even send it to a recruiter too. I've had great luck with sending\
    \ it to recruiters as well. CEOs work too, for smaller companies, because they\
    \ just want to hear from smart, talented people. I think the biggest thing is\
    \ \u2013 a cover letter is very formal and it's often generic for 99% of people.\
    \ So that's why so many jobs these days don't even ask for a cover letter. If\
    \ they do, nobody reads it. No one has time for that. Plus, cover letters are\
    \ like formatting \u2013 just a clean page. A crisp email with a hyperlink, like,\
    \ \u201CHey, here's my GitHub link.\u201D or like, \u201CHere's the project.\u201D"
  sec: 3659
  time: '1:00:59'
  who: Nick
- line: "Or you just embed the image. You could embed a GIF or an image, like \u201C\
    Hey, look at this visualization of all the taxis in New York City over 24 hours.\
    \ I love transportation and I want to help build a future of mobility at Uber.\u201D\
    \ That's like a two sentence thing. It's one GIF. That's way more alive and shows\
    \ that this person actually knows how to deal with something like 8 million taxi\
    \ trip record data and did something with it, than any cover letter that just\
    \ says \u201CI'm a hard working data scientist who's passionate about making a\
    \ difference.\u201D You know, that's bullshit. So that's why this cold email stuff\
    \ works."
  who: Nick
- header: Wrapping up
- line: "Yeah, thanks. We should be wrapping up. Just before we finish \u2013 anything\
    \ else you want to mention? Any tips you want to share?"
  sec: 3729
  time: '1:02:09'
  who: Alexey
- line: "No. I would just say \u2013 people who are about to interview or just want\
    \ to know about how to ace their data science, data analyst, or machine learning\
    \ interviews \u2013 go check out the book on Amazon. It's basically the \u201C\
    Cracking the Coding Interview\u201D of our field. It didn't exist, so we made\
    \ it happen. It's only a few months old, but it's already getting some great reviews.\
    \ So I just tell any person who wants to break into these FAANG-type companies\
    \ or just level up in their career to go check it out."
  sec: 3736
  time: '1:02:16'
  who: Nick
- line: How can people find you?
  sec: 3763
  time: '1:02:43'
  who: Alexey
- line: "You can check out the book on Amazon, of course. It\u2019s just \u201CAced\
    \ the Data Science Interview\u201D. You can find me and my blogs on NickSingh.com.\
    \ I also talk a ton on LinkedIn. I have about 65,000 followers on LinkedIn. I\
    \ post tips daily, around career, job hunting, and data science. You can always\
    \ find me there at Nick Singh. LinkedIn, my website, and buying the book are the\
    \ best ways to go \u2013 to learn more about me and my tips."
  sec: 3767
  time: '1:02:47'
  who: Nick
- line: "Yeah. Thanks a lot. Thanks for joining us today. Thanks for sharing your\
    \ story. Thanks for sharing tips with us. And thanks, everyone, for joining us\
    \ today \u2013 for watching us. There was one question I didn't cover. Sorry about\
    \ that. But yeah, thanks a lot, everyone. And thanks, Nick."
  sec: 3797
  time: '1:03:17'
  who: Alexey
- line: Yeah, thanks for having me. It was great to be on. Alright. Talk to you later.
    Bye.
  sec: 3816
  time: '1:03:36'
  who: Nick

---
