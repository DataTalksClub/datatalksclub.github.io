---
title: "Becoming a Data-led Professional"
short: "Becoming a Data-led Professional"
guests: [arpitchoudhury]

image: images/podcast/s03e08-data-led-professional.jpg

season: 3
episode: 8

ids:
  youtube: 8v5KpHWgyYw
  anchor: Becoming-a-Data-led-Professional---Arpit-Choudhury-e11mkgq

links:
  youtube: https://www.youtube.com/watch?v=8v5KpHWgyYw
  anchor: https://anchor.fm/datatalksclub/episodes/Becoming-a-Data-led-Professional---Arpit-Choudhury-e11mkgq
  spotify: https://open.spotify.com/episode/2hg3Gi3h5OfdedXENwZwnU
  apple: https://podcasts.apple.com/us/podcast/becoming-a-data-led-professional-arpit-choudhury/id1541710331?i=1000523422699

transcript:
- line: "This week we will talk about becoming a data-led professional. We have a\
    \ special guest today \u2014 Arpit. Arpit actually is one of the first people\
    \ who joined DataTalks.Club. I think you were one of the first 10 or 20. I remember\
    \ asking you for some tips. I checked your LinkedIn and it was something about\
    \ growth and community. I immediately became interested and started to ask you\
    \ different questions about growing the community. Arpit is also the founder of\
    \ the data led academy, which is the go place for anybody interested in data,\
    \ who wants to learn how to work with data. If you want to ask any data related\
    \ question, this is the place to look for answers. Welcome, Arpit."
  sec: 141
  time: '2:21'
  who: Alexey
- header: Data-led academy
- line: "Thanks Alexey for the intro. I\u2019m excited to be here, thanks for having\
    \ me. DataTalks is a really great community, I\u2019m excited to be part of it.\
    \ Just to let people know that data academy is not exactly a community, it\u2019\
    s not a slack community. Essentially it\u2019s a place to learn how to work with\
    \ data. We have a lot of free learning content. We're also creating a repository\
    \ of common questions about tools, technologies, people and processes related\
    \ to data. You can go and find answers to those questions there. I\u2019m excited\
    \ to be here, thanks again."
  sec: 208
  time: '3:28'
  who: Arpit
- line: And you also have a podcast.
  sec: 246
  time: '4:06'
  who: Alexey
- line: "We have a podcast called \u201Cthe data led professional\u201D. You can check\
    \ out the podcast on our website at dataled.academy/podcast. We talk about different\
    \ data related topics that mostly are relevant for less technical people \u2014\
    \ people who are not exactly data engineers or data analysts. Of course, they\
    \ can also benefit from the content but our core audience is people working in\
    \ product growth and operations roles or marketing. They want to learn about data\
    \ and different data related topics. Typically our goal is to answer common questions\
    \ that people have about data."
  sec: 249
  time: '4:09'
  who: Arpit
- header: "Arpit\u2019s background"
- line: Before we go into our main topic of becoming data-led, maybe we can start
    with your background. Can you tell us about your career journey so far?
  sec: 294
  time: '4:54'
  who: Alexey
- line: "I\u2019ve been working in the technology industry for pretty much my whole\
    \ career. I\u2019ve  worked in different types of companies. I got into the data\
    \ space when I was working as a consultant. I was building a lot of integrations\
    \ for SMBs and that led me to Integromat. I was a user of Integromat. It's a work\
    \ automation solution like Zapier. I was one of the earliest people who joined\
    \ the Integromat team. I built the integrometric community and then eventually\
    \ I led growth at Integromat. I moved on from Integromat soon after it got acquired\
    \ last year. Since then I worked with a few other companies in the data space,\
    \ solving different problems in the customer data infrastructure space."
  sec: 306
  time: '5:06'
  who: Arpit
- line: "Now I am building dataled.academy. I\u2019m also helping a few data companies\
    \ with their content and community strategy. For me, content communities is all\
    \ I\u2019ve been doing. At Integromat, the content community is what helped us\
    \ grow really fast. It\u2019s really important for data companies to build their\
    \ presence across different communities where their prospects, customers and partners\
    \ hang out \u2014 communities like DataTalks.Club. A lot of people are building\
    \ new communities. But I believe that there are already a lot of great communities.\
    \ That\u2019s why I like to be active in existing communities. That\u2019s the\
    \ idea behind dataled.academy \u2014 not to build another community, but to create\
    \ a place where people can get concrete, actionable and unbiased answers to their\
    \ questions. A lot of these answers are answered by experts who are from these\
    \ communities."
  who: Arpit
- header: Growth marketing
- line: "Growth \u2014 this is something you did within Integromat. I was curious\
    \ what growth managers actually do. When I checked, I found out that it\u2019\
    s very data driven. They use a lot of data. When I look at \u201Cgrowth marketing\u201D\
    , it doesn\u2019t sound too data related to me. But when I actually read about\
    \ it \u2014 they run a lot of A/B tests, they need to make a lot of decisions.\
    \ All these decisions are based on data. I guess this is how you ended up creating\
    \ this dataled.academy. You saw how it is useful."
  sec: 441
  time: '7:21'
  who: Alexey
- line: "Yeah. Without data, there is only so much you can do. If you don\u2019t have\
    \ data when you are building growth experiences \u2014 whether it\u2019s for acquisition,\
    \ activation or retention \u2014 without data you\u2019d be forced to build linear\
    \ experiences. Every customer, irrespective of their behavior, will go through\
    \ the same path. But when you have data, you can create personalized experiences.\
    \ The customers are prospects, they\u2019ll see content or interact with your\
    \ product based on where they come from, what their industry is and how they interact\
    \ with your product."
  sec: 489
  time: '8:09'
  who: Arpit
- line: "That\u2019s the main difference. It\u2019s very hard for growth professionals\
    \ or product managers to build personalized customer experiences across different\
    \ touch points and channels without having access to data in the tools that they\
    \ use. It\u2019s not enough just to have access to data in a data warehouse or\
    \ a BI tool. It\u2019s more important to have access data in the tools that they\
    \ use \u2014 to build and craft these customer experiences."
  who: Arpit
- line: Tools that marketers use to make different decisions? Most of them cannot
    just go and run a SQL query in a database.
  sec: 568
  time: '9:28'
  who: Alexey
- line: "Yeah. Marketers, growth professionals, product people, operations people.\
    \ They don\u2019t need to know how to write SQL. Of course, if they know it, it\u2019\
    s an advantage. But there are a lot of great tools out there that allow you to\
    \ visually query the data. If the data is made available, they can easily use\
    \ the data for whatever they are doing. Whether it\u2019s creating in-app experiences\
    \ or creating lifecycle email campaigns or doing A/B tests like you mentioned,\
    \ or doing an SMS campaign. Irrespective of the channel that they are using to\
    \ engage with customers, they can use this data, if the data is available in the\
    \ tools that they use."
  sec: 586
  time: '9:46'
  who: Arpit
- header: Being data-led
- line: What is data-led? I think you have a definition. What is that?
  sec: 638
  time: '10:38'
  who: Alexey
- line: "A data-led professional is someone who understands where data comes from\
    \ and what it looks like. They are able to question its accuracy, not just blindly\
    \ believe the data that they see. If they understand where data comes from and\
    \ what it looks like, they will be able to question its accuracy. They are comfortable\
    \ working with data and they have the skills to build their experiences powered\
    \ by data. It sounds like a lot, but you don\u2019t really need a technical background\
    \ to know this \u2014 to understand where data comes from, what it looks like,\
    \ to question its accuracy and to work with data to build data experiences."
  sec: 645
  time: '10:45'
  who: Arpit
- header: Data-led vs data-driven
- line: Is there any difference between being data-driven and data-led? Data-driven
    is something I hear quite often. To be honest, I still have no idea what it actually
    means. What is it and what are the differences between data-driven and data-led?
    If there are any differences.
  sec: 693
  time: '11:33'
  who: Alexey
- line: "It\u2019s a buzzword, but I like to think that being data-driven means to\
    \ base decisions exclusively on available data. Every company wants to be data-driven.\
    \ They are investing heavily in their infrastructure. Once data is available,\
    \ they want to be data-driven. They don\u2019t always question the accuracy of\
    \ the data and use intuition and experience before making decisions. Data is all\
    \ about making decisions. Good data helps you make good decisions. But you cannot\
    \ always blindly follow what data tells you. There are so many ways the data that\
    \ you see can be inaccurate. There are so many data quality issues. It\u2019s\
    \ important to combine your intuition, your experience along with the data that\
    \ you see."
  sec: 720
  time: '12:00'
  who: Arpit
- line: "So when you\u2019re data-led, data is leading you or guiding you rather than\
    \ just telling you what to do \u2014 rather than just blindly following what data\
    \ tells you."
  who: Arpit
- line: So, a data-led profession is somebody who knows and understands where the
    data comes from, can question its accuracy and is comfortable working with data.
    The second point about questioning is the main differentiating factor between
    these two.
  sec: 789
  time: '13:09'
  who: Alexey
- header: 'Documenting your data: creating a tracking plan'
- line: "Yeah. You can only question this accuracy if you understand where data has\
    \ been collected or how it is being collected. If nothing is documented, you cannot\
    \ really understand anything, and you cannot really question it. It\u2019s important\
    \ to have proper documentation on your data sources."
  sec: 814
  time: '13:34'
  who: Arpit
- line: "In the context of product and growth, we need to have a data tracking plan.\
    \ It could be a simple Google doc or a Google sheet. Or there are purpose-built\
    \ tools to create your tracking plans. In these tools, you can define every event\
    \ that has been captured, related properties that are being captured and even\
    \ the data types of each property. When these things are well defined, any product\
    \ or growth professional can look at that information and understand that \u201C\
    okay this event is captured when someone performed this particular action\u201D\
    . \u201CThe sign up event is captured when someone not just submits the sign up\
    \ form \u2014 but when the sign up is completed rather than just being a client-side\
    \ event versus being a service side event.\u201D"
  who: Arpit
- line: "When you specify these things, you have enabled people to understand where\
    \ data comes from. It's important to document everything to be able to pass on\
    \ that knowledge to others. The person who would implement it cannot be around\
    \ forever to explain where the data is coming from. But once you have that understanding,\
    \ then you are able to question the accuracy. When you see an anomaly, when you\
    \ see that the data doesn\u2019t look right, you can go and drill down and figure\
    \ out what the issue is \u2014 instead of flying blind or blindly trusting what\
    \ you see."
  who: Arpit
- line: "This data tracking plan is the document which describes all these events.\
    \ When do you need to do this? Let\u2019s say we work for a startup or for a mature\
    \ organization. We already have some data sources. Then we hire a growth marketer.\
    \ Now that person needs to make decisions based on data."
  sec: 925
  time: '15:25'
  who: Alexey
- line: It depends on the stage of the company. I have seen some big companies not
    having a tracking plan at all, which is a problem. Every company that has a tech
    product or a tech-enabled product or even an e-commerce business needs to have
    this documented. It could be a tracking plan. Some companies use tools like Miro
    for that.
  sec: 961
  time: '16:01'
  who: Arpit
- line: "It\u2019s usually done even before you set up instrumentation of data \u2014\
    \ before you set up a product analytics tool, or any tool that depends on event\
    \ data. You instrument your product events. The process of tracking product data\
    \ is often referred to as \u201Cinstrumentation\u201D."
  who: Arpit
- line: "There is no rule when it\u2019s done. Typically it\u2019s done when companies\
    \ are ready to invest in product analytics tools or other event based engagement\
    \ tools, like Customer.IO, Braze, etc. There are many tools where you can use events\
    \ to personalize customer experiences. This is relevant to both startups as well\
    \ as big companies."
  who: Arpit
- line: "At a big company if you do not have this stuff documented, new people will\
    \ come in and they will have no idea what to do. They see a bunch of events. They\
    \ are supposed to create some in-app experiences or some email campaigns. But\
    \ they wouldn\u2019t know what an event means. Or they might see conflicting events.\
    \ They might see an event called \u201Csigned_up\u201D and another event called\
    \ \u201CSignedUp\u201D with a different casing. All of those issues come up if\
    \ you do not have things documented and well instrumented."
  who: Arpit
- line: "I\u2019d recommend every company to do this sooner rather than later. Of\
    \ course you need to have customers first, you need to have users to be able to\
    \ make sense of this data."
  who: Arpit
- header: Understanding your data
- line: "You mentioned growth marketers. But there are a lot of different users of\
    \ data. We have data analysts, product managers... Many people need to make decisions\
    \ based on data. They need to analyze the data and they need to understand each\
    \ event \u2014 what\u2019s the origin of this event? If they see something strange\
    \ in the data, they need to be able to question it. \u201CThere\u2019s a spike\
    \ in registrations. What does it mean?\u201D And then they would be able to go\
    \ and drill in and understand what\u2019s happening. Right?"
  sec: 1107
  time: '18:27'
  who: Alexey
- line: "Absolutely. An example would be \u2014 you see a ridiculous spike in your\
    \ signups. You know that it doesn\u2019t look right. If you have the event instrumented\
    \ properly and you are also capturing relevant properties with that event, you\
    \ can figure out where the signups are coming from. Oftentimes you might realize\
    \ that these are fake signups."
  sec: 1152
  time: '19:12'
  who: Arpit
- line: "We talked about product, growth and product marketing, but these events are\
    \ extremely useful for sales people as well. Sales people look at a CRM. They\
    \ look at data about a company or a prospect. They can have more context about\
    \ customers in the trial period if they see what they are doing inside the product.\
    \ They can go after the right accounts rather than going after everybody. They\
    \ see that this particular account has five users. They have already performed\
    \ a bunch of actions. If it\u2019s a project management tool, they have already\
    \ created a project and a bunch of tasks. Now would be a good time to reach out\
    \ to them versus just reaching out to everybody who shows up in your CRM. It\u2019\
    s extremely useful for sales."
  who: Arpit
- header: Tools for creating a tracking plan
- line: "It\u2019s very important to document your data. You mentioned that you can\
    \ do this with Miro. Or things like an Excel spreadsheet or Google spreadsheet.\
    \ Are there any special tools for that? Or people use whatever they are comfortable\
    \ with?"
  sec: 1247
  time: '20:47'
  who: Alexey
- line: 'There are purpose-built tools for that: AVO, Iteratively, TrackPlan. These
    are tools that are built for companies to create their tracking plan in a collaborative
    manner rather than relying on a spreadsheet. They have useful features to maintain
    data quality, maintain taxonomy and collaborate on each event. You describe an
    event and the developer who is supposed to instrument it might have questions
    about that event. You can discuss it and these tools are really useful.'
  sec: 1276
  time: '21:16'
  who: Arpit
- line: "You said \u201Ca developer is supposed to instrument this event\u201D. The\
    \ way I understand it, first you create this tracking plan: you write down all\
    \ the events you want to capture. It doesn\u2019t mean you capture them yet. But\
    \ you want to start tracking them. Then an engineer needs to implement this to\
    \ start tracking this data. The data doesn\u2019t just appear magically on your\
    \ dashboard. You actually need to capture this data."
  sec: 1324
  time: '22:04'
  who: Alexey
- header: Data flow stages
- line: "Now we have a tracking plan. We tell the developer, \u201Ccan you please\
    \ instrument this event?\u201D We start collecting them. Then we have the other\
    \ end of this \u2014 an analyst or somebody is looking at the dashboard. Then\
    \ make a decision like this variant of the campaign is better than this variant\
    \ of campaign. There are a lot of things that happen between these two things."
  sec: 1370
  time: '22:50'
  who: Alexey
- line: "Data collection is the first step. Even before, let\u2019s talk about a startup\
    \ that doesn\u2019t have any data infrastructure in place. Let\u2019s think of\
    \ a SaaS product \u2014 could be a project management tool or an invoicing tool.\
    \ Before you implement any product analytics tools or any tools that rely on data,\
    \ you need to first create a tracking plan. You need to describe all the events\
    \ that you want to capture and then describe all the properties of these events.\
    \ You also need to describe user properties and organization or account properties\
    \ \u2014 all the different pieces of data that you ideally want to collect."
  sec: 1407
  time: '23:27'
  who: Arpit
- line: "When you start doing this, you feel like you want to collect everything.\
    \ You might end up with 50 events. This is great. The next step is to remove all\
    \ the events that you don\u2019t need in the near future. Having too much data\
    \ at the beginning is one of the biggest issues. It takes more time to implement,\
    \ it takes more time to test. So, bring it down to seven or ten events that you\
    \ really need to understand the customer journey from acquisition to activation."
  who: Arpit
- header: "Tracking events \u2014 examples"
- line: Maybe you can think of some examples? So you said, a SaaS product which could
    be a project management tool or account or invoicing.
  sec: 1483
  time: '24:43'
  who: Alexey
- line: "You start by tracking your sign up event. I recommend people to track the\
    \ \u201Cemail verified\u201D event \u2014 depending on your sign up flow, you\
    \ might have people who sign up but don\u2019t verify their email. It\u2019s useful\
    \ because you might want to create some emails based on that event."
  sec: 1504
  time: '25:04'
  who: Arpit
- line: "If it\u2019s a project management tool, one of the first things is to create\
    \ a project. Then \u201Cinvite a user\u201D, because a project management tool\
    \ is no good if you don\u2019t invite another user to work with. So, \u201Cproject\
    \ created\u201D, \u201Cuser invited\u201D \u2014 those would be the core events\
    \ that you track. Then, of course, you want to see whether they create a task,\
    \ so \u201Ctask created\u201D."
  who: Arpit
- line: "If it\u2019s an invoicing tool, it could be \u201Cinvoice created\u201D.\
    \ With an invoicing tool, you probably add a client. So, it could be \u201Cclient\
    \ added\u201D or \u201Cclient created\u201D and then \u201Cinvoice created\u201D\
    . Then you invite your colleagues, so \u201Cuser invited\u201D. These are the\
    \ most common events. You start with these."
  who: Arpit
- line: "For each event, you would describe relevant properties. For the \u201Csign\
    \ up\u201D event you describe the user's name and email. If in the signup form\
    \ you ask which industry they belong to and what their roles are, you want to\
    \ capture that information alongside that event."
  who: Arpit
- line: Once you are happy with your events, then you bring in an engineer. You discuss
    it with them, get their feedback. Engineers will have a lot of good feedback.
    You get their feedback, polish your tracking plan.
  who: Arpit
- header: Collecting the data
- line: "I recommend that for every event you describe if it\u2019s a client-side\
    \ event or a server-side event. That is really important. It\u2019s better to\
    \ track server-side but you might want to track some client-side events."
  sec: 1620
  time: '27:00'
  who: Arpit
- line: "What\u2019s the difference? For a sign up with client side or server side."
  sec: 1638
  time: '27:18'
  who: Alexey
- line: "It depends how you end up implementing it. If you are tracking a client side,\
    \ the event will be fired as soon as someone clicks the \u201Csign up\u201D button\
    \ and submits the form. But if you are tracking the server side, it\u2019ll only\
    \ be fired once the signup process is actually completed, once that user is added\
    \ in your database. A lot of times a user will click that sign up button and there\
    \ will be a validation error that your password is not right or email is not right.\
    \ But the event will be fired. So, you might see a sign up, but an actual signup\
    \ has not taken place."
  sec: 1643
  time: '27:23'
  who: Arpit
- line: "Ideally you would track it server side, but for some use cases, tracking\
    \ client-side events is better if you want to track if someone clicked a button.\
    \ This is useful, if you want to see if someone tried clicking on a button to\
    \ use the feature. Even if they don\u2019t use the feature, you want to know that\
    \ someone actually tried using it. That\u2019s very useful information for you,\
    \ so that could be a client-side event."
  who: Arpit
- line: Once you have that, you start working with your engineers. Multiple engineers
    might be involved. You should even specify which engineer is going to implement
    which events. You can specify who owns which event. Once you have everything done
    and once you actually have data flowing in, you are actually done with the collection
    stage.
  who: Arpit
- header: Storing and analyzing the data
- line: "The next step is to make sure that this data is stored in a warehouse. For\
    \ early stage startups it might not always be possible to set up a warehouse.\
    \ But it\u2019s not hard to set up a warehouse today, it\u2019s very affordable."
  sec: 1732
  time: '28:52'
  who: Arpit
- line: "But you need to store event data or product data somewhere. If you don\u2019\
    t, you would obviously be sending it to some product analytics tool, like clicky,\
    \ mixpanel or amplitude. But you wouldn\u2019t really have access to this raw\
    \ event data to be used in the future. So, you should store it."
  who: Arpit
- line: "Then you want to analyze this data. Typically event data is analyzed in a\
    \ product analytics tool. Some people end up doing this in a BI tool. BI tools\
    \ are not purpose-built to analyze event data. You\u2019d need an analyst to write\
    \ a whole bunch of SQL queries to create a simple funnel report in a BI tool.\
    \ But you could do it in a product analytics tool with a few clicks."
  who: Arpit
- header: Data activation
- line: "Irrespective of the tools you are using to analyze the data, you derive some\
    \ insights from the data, and then you want to activate that data \u2014  act\
    \ upon that data. That\u2019s the most important thing. You cannot just look at\
    \ data and be happy with it. You need to do something about it. That\u2019s when\
    \ data activation comes into place. Once this data is available in your activation\
    \ tools, your email tools, your support tools."
  sec: 1803
  time: '30:03'
  who: Arpit
- line: "Support is a really good use case \u2014 it\u2019s something that a lot of\
    \ people don\u2019t think about. If you make this event data available in your\
    \ support tools, you enable your support teams to see what users have done in\
    \ the product. When somebody opens a ticket, they don\u2019t have to ask people\
    \ \u201Cdid you try doing this?\u201D or \u201Cdid you try doing that?\u201D or\
    \ \u201Ccan you try doing this?\u201D. They can see what users have performed.\
    \ So, they don\u2019t have to ask you and can provide better support."
  who: Arpit
- line: Are there companies who actually have this? All my experience with customer
    support was...
  sec: 1862
  time: '31:02'
  who: Alexey
- line: "More and more companies realize the importance of this. It\u2019s not a priority\
    \ for most companies, but there are companies that provide great support. They\
    \ have this and it\u2019s really not that hard. Once you have the data, you send\
    \ it to ZenDesk or whatever support tool you are using. That\u2019s the thing\
    \ with data. Companies have access to this data, but only 5 out of 100 actually\
    \ use this data across different channels and make this data available to different\
    \ teams."
  sec: 1872
  time: '31:12'
  who: Arpit
- line: "It\u2019s also useful in sales. People don\u2019t generally have access to\
    \ product data in the tools that they use. But now more and more companies realize\
    \ the importance of this. Now there is a new breed of companies, they are building\
    \ new tools dubbed as \u201CCRM 2.0\u201D.  With these tools, sales people can\
    \ access product data and be more responsive. They don\u2019t have to create these\
    \ linear experiences."
  who: Arpit
- line: "So once you have the data and the right tools, you can activate the data.\
    \ You can build a personalized customer experience. Then you send this data back\
    \ to your product and personalize the product experience. HubSpot is a good example\
    \ and there are a bunch of other companies that do this really well \u2014 the\
    \ way people experience the product is personalized based on what they have done\
    \ earlier in the product."
  who: Arpit
- line: "That\u2019s the ultimate destination. You are not just analyzing data. You\u2019\
    re using it to create experience outside and inside your product. Amplitude, which\
    \ is one of the most popular product analytics tools, has launched a new feature\
    \ called \u201Camplitude recommend\u201D where you can do this using Amplitude.\
    \ You can send the data from Amplitude back to your product and to other tools\
    \ to create a unified customer experience."
  who: Arpit
- header: Tools for data collection
- line: "There was a lot of information and I have so many questions. Maybe we can\
    \ take a step back and start from the beginning. You said for creating this tracking\
    \ plan, we can use a specialized tool like TrackPlan. We create this tracking\
    \ plan. Then an engineer would go and implement this for data collection. What\
    \ are the tools we\u2019d use for that?"
  sec: 2021
  time: '33:41'
  who: Alexey
- line: "There are CDI tools \u2014 customer infrastructure tools. The ones I mentioned\
    \ \u2014 track plan, AVO and Iteratively. They allow you to also collect your\
    \ data, not just create the plan. Other popular tools will be Segment Connections.\
    \ Segment Connection is one of the most popular tools for tracking product data.\
    \ There are also RudderStack and MetaRouter, which is relatively new. Freshpaint\
    \ enables implicit tracking \u2014 you don\u2019t even have to define tracking.\
    \ Once you install it, it starts tracking all the events automatically. Some companies\
    \ do this using code and some companies build microservices just for tracking\
    \ purposes. But, then of course there are all these great tools that I mentioned.\
    \ In fact I have written about this and I am happy to share content."
  sec: 2056
  time: '34:16'
  who: Arpit
- line: Please. Send the link and I will include it in the description.
  sec: 2121
  time: '35:21'
  who: Alexey
- line: Yeah, for sure.
  sec: 2125
  time: '35:25'
  who: Arpit
- header: Data warehouses
- line: "We mentioned that we collect the data and then we can send it immediately\
    \ to a product analytics tool, but it is better to store it in a warehouse. So\
    \ what is a warehouse? It\u2019s a database that you own, right? Can you tell\
    \ us what it is?"
  sec: 2127
  time: '35:27'
  who: Alexey
- line: "A data warehouse is a database that is purpose-built for analytics. It\u2019\
    s not a typical database. Companies use it to store large amounts of structured\
    \ data. They create data models in the data warehouse, they transform the data,\
    \ they clean the data there. There are tools for transformation like DBT or Trifacta.\
    \ Once you have this clean structured data in the warehouse, you can analyze it\
    \ in a BI tool."
  sec: 2156
  time: '35:56'
  who: Arpit
- line: "Also, there are product analytics companies that are now warehouse-centric.\
    \ You have a warehouse and you are already sending data there. If you want to\
    \ implement a product analytics tool, you don\u2019t have to use their SDKs to\
    \ send data to them directly. You can send data from your warehouse to these products.\
    \ There is a tool called Rakam. You don\u2019t even need to send data there.\
    \ It just sits on top of your warehouse like a BI tool and offers data analytics\
    \ features."
  who: Arpit
- line: "So, it\u2019s really important to set up a warehouse. Popular warehouses\
    \ worth mentioning are Snowflake, BigQuery, AWS Redshift. There is a new one called\
    \ FireBolt. In fact we have someone from FireBolt in our community."
  who: Arpit
- line: I think I saw somebody recently in DataTalks.Club.
  sec: 2241
  time: '37:21'
  who: Alexey
- header: Reverse ETL tools
- line: "Exactly. That's what I meant. Next, there\u2019s Panoply. Once you have\
    \ the data in the warehouse, you can do a lot of things with it. You can send\
    \ it back to your BI and analytics tools. You can even send it to your engagement\
    \ tools. There are again a new bunch of companies that have come up that are solving\
    \ this problem. They are referred to as \u201Creverse ETL\u201D tools or \u201C\
    operational analytics tools\u201D. Companies like Census, HighTouch, Grouparoo are\
    \ solving this problem. You have the data in the warehouse and you want to send\
    \ data to a lot of different tools \u2014 your sales, marketing, advertising,\
    \ support tools or whatever product analytics tools. You can do that using these\
    \ tools."
  sec: 2245
  time: '37:25'
  who: Arpit
- header: Customer data platforms
- line: "There\u2019s a lot of different tools for solving different pieces of the\
    \ puzzle. To implement all of these tools, you\u2019d need a lot of resources.\
    \ You\u2019d need a data team, or at least one dedicated data engineer. It\u2019\
    s not possible for early stage startups to do everything. It\u2019s worth mentioning\
    \ CDPs \u2014 customer data platforms. They are an all-in-one bundled solution,\
    \ where you can track data and send it to different tools. You can create audiences\
    \ and create your models and segments inside a CDP. Of course, it has limited\
    \ capabilities. You cannot do everything there that you can do in a warehouse,\
    \ but it gives a lot of flexibility to marketers and growth professionals to work\
    \ with data without relying on data teams."
  sec: 2300
  time: '38:20'
  who: Arpit
- header: Modern data stack for growth
- line: "I was trying to take a note of all the tools you mentioned. But there are\
    \ simply so many of them. Let\u2019s say my co-founder and I just started a startup.\
    \ We understand that data is important. We want to use it. We look at all these\
    \ tools and there are just too many. How do we make a decision which tool to choose?"
  sec: 2356
  time: '39:16'
  who: Alexey
- line: "Yeah. It\u2019s first important to define what your goals are. A good way\
    \ to think about this is to just list down 10 questions that you want to answer\
    \ with data. Then work backwards and figure out the tools. There are ready-made\
    \ tools, but a lot of companies end up fixing these problems or implementing these\
    \ solutions without buying ready-made tools, by building them in-house. So, it\
    \ depends on what your resources are \u2014 these tools can also get expensive."
  sec: 2394
  time: '39:54'
  who: Arpit
- line: "At the very least, you need to collect data. You need a tool like a CDI \u2014\
    \ Segment Connections, Rudderstack, MetaRouter. I will share a list. I\u2019\
    ve written a lot about this stuff. A lot of these tools have free tiers, free\
    \ plans. You can explore different tools and see what works for you."
  who: Arpit
- line: "Once you have the data, you want to analyze it in a product analytics tool\
    \ or even like a simple BI tool \u2014 or both. It makes sense to have both. They\
    \ both serve different purposes. Of course, you want to have an email tool where\
    \ you send this data to create personalized emails, to have a great onboarding\
    \ experience \u2014 if you have a SaaS product, you want to do some in-app onboarding.\
    \ There are tools for that and you can send this data to those tools."
  who: Arpit
- line: "There are 4-5 different tools. I like to think of this data stack as the\
    \ \u201Cmodern data stack for growth\u201D. If you hear the term \u201Cmodern\
    \ data stack\u201D, you hear it in the context of analytics \u2014 \u201Cmodern\
    \ data stack for analytics\u201D is how I would describe it. You have an ELT tool,\
    \ like Fivetran, Stitch, Xplenty, etc. You\u2019re ingesting data from all third\
    \ party tools into a warehouse. Then you have a BI tool and you have a transformation\
    \ tool. DBT is worth mentioning here \u2014  it\u2019s growing so fast, so many\
    \ companies are adopting this library for their transformation needs and modeling\
    \ needs. Then BI tools \u2014 like Liquid, Looker, Mode, etc. That\u2019s the\
    \ modern data stack for analytics."
  sec: 2490
  time: '41:30'
  who: Arpit
- line: "In terms of modern data stack for growth \u2014 you need a data collection\
    \ tool, a product analytics tool and a warehouse. Every company should have a\
    \ warehouse."
  who: Arpit
- line: "Then you have tools that make data available in your downstream SasS tools\
    \ \u2014 sales, marketing, support tools. That could be a customer data platform\
    \ \u2014 if you are using tools like Segment Connections and Rudderstack, they\
    \ can do that. If you are storing the data in the warehouse then you can use a\
    \ reverse ETL tool. Each of these categories obviously has multiple tools. A lot\
    \ of them are very similar. Some have different capabilities. It\u2019s time consuming\
    \ to evaluate all of these different tools and understand the differences. That\u2019\
    s actually one of the things I am trying to solve with dataled.academy."
  who: Arpit
- line: "I am launching \u201Ccompany profiles\u201D. You can go and learn about a\
    \ product in a very simple manner, understand what the product does, what the\
    \ core benefits are, who the product caters to and then get answers to questions\
    \ about the product. I agree, companies spend a lot of time figuring out the right\
    \ tools. That\u2019s a problem that needs to be solved."
  who: Arpit
- header: Buy vs build
- line: "I have engineering background. I look at these tools and I think \u201Cwhy\
    \ are they so expensive?\u201D I could implement something like this. But I know\
    \ that once I implement it, there will be bugs. It\u2019s difficult to maintain\
    \ later. You probably had this experience: you go to a company, you say \u201C\
    this is a great tool\u201D and an engineer says \u201CNo. I am going to implement\
    \ it myself\u201D."
  sec: 2630
  time: '43:50'
  who: Alexey
- line: "I have experienced that a lot. Very few people actually like using these\
    \ tools. For most people it\u2019s a headache. It\u2019s an additional task whether\
    \ for engineers to implement the tool, or for business teams to use these tools.\
    \ Everyone just wants answers to questions. Especially when it comes to data.\
    \ They just want data to be available in the right format so that they can use\
    \ it and derive insights from it or act upon it. Implementing new tools is not\
    \ easy at all, especially when it comes to data tools. There are a lot of security\
    \ challenges, a lot of compliance issues. It\u2019s difficult. That\u2019s why\
    \ it\u2019s important to understand the problem that the tool solves."
  sec: 2664
  time: '44:24'
  who: Arpit
- line: If you have the resources then you can do the buy-vs-build analysis. If you
    build this in-house, how much will it cost us? Do we have the resources to maintain
    that? Versus buying a ready-made solution.
  who: Arpit
- line: "A lot of these tools are open source. So, Rudderstack is open source, Grouparoo\
    \ with a reverse ETL tool is open source. There\u2019s a bunch of open source\
    \ BI tools. There\u2019s an open source product analytics tool now called \u201C\
    Posthog\u201D. In every category you will find open source tools. If you have\
    \ the resources \u2014 it takes a lot of effort to implement an open source tool.\
    \ Just because it\u2019s open-source, it doesn't mean it\u2019s easy to implement.\
    \ But if you have the resources you can go that route."
  who: Arpit
- header: People we need to in the data flow
- line: "We talked about tools. We discussed the flow from the moment we start capturing\
    \ events to the moment when data is activated. I\u2019ve heard that we need to\
    \ have at least a data engineer \u2014 somebody who implements this. Who else\
    \ do we need to have in a team to implement the whole flow from the beginning\
    \ to the end?"
  sec: 2773
  time: '46:13'
  who: Alexey
- line: "For early startups, you may not have a dedicated data engineer. Any engineer\
    \ \u2014 a backend engineer or frontend engineer could help you. But eventually\
    \ you\u2019d need a data engineer to manage all of these different data pipelines.\
    \ It\u2019s not just about implementing the tool once. You have to maintain it.\
    \ You have to make sure that everything is working properly. Then teams have continuous\
    \ requests for new events to track, you want to add more data, and you want to\
    \ collect more data. So, at the very least, you need a data engineer."
  sec: 2808
  time: '46:48'
  who: Arpit
- line: "If you are using a BI tool and you have a warehouse, then it makes sense\
    \ to have a data analyst. The analyst will be analyzing the data and making the\
    \ data available in the BI tools. So, you need those two. I have seen companies\
    \ hire one data person who does pretty much all of this stuff. Now there\u2019\
    s an analytics engineer \u2014 a more specialized role which fits in between data\
    \ engineering and data analysis. They work with tools like DBT. They build data\
    \ models."
  who: Arpit
- line: "We also have DataOps people who make sure that all tools are working, all\
    \ teams have access to the tools that they need and to the resources that they\
    \ need. There are companies that are creating product ops teams. Companies that\
    \ don\u2019t have dedicated data teams, they are calling this \u201Cproduct ops\u201D\
    . They work on prototypes and often do a lot of the work that data teams do. They\
    \ take care of all the tools. They take care of your ETL pipelines, they take\
    \ care of your warehouse."
  who: Arpit
- line: "You have an analyst, an engineer and someone who understands the product\
    \ really well. it doesn\u2019t matter what you call it, but depending on your\
    \ resources, you decide how many people you would want in a team like that. It\
    \ definitely makes sense to empower product teams and growth teams to understand\
    \ all of the stuff. Then they can support these teams by taking up their work\
    \ instead of adding more work for data people."
  who: Arpit
- line: "One of the typical challenges is that data people are overwhelmed with requests\
    \ from different teams \u2014 teams have requests to track new data or create\
    \ dashboards. If you enable them to do that work themselves, then you can make\
    \ your data people more efficient. That\u2019s data democratization \u2014 you\
    \ aren\u2019t just making data accessible for people, but you are enabling them\
    \ to work with data. You\u2019re implementing self-service analytics tools. People\
    \ can go in and derive insights from data themselves. You are investing in upskilling\
    \ people. Have people learn basic SQL, so they can run simple queries and won\u2019\
    t have to rely on data people. They will be able to take a SQL query, put it in\
    \ the right place, run it and then understand the result."
  who: Arpit
- line: "These things are becoming more and more common. It makes sense for every\
    \ team to learn these skills and become data literate. I strongly believe that\
    \ one doesn\u2019t need to have an engineering or technical background to work\
    \ with data."
  who: Arpit
- line: We need to have quite a few roles. But not every company needs all these people.
    For early-stage startups, they just need somebody like an analytics engineer,
    who can do both analytics and data engineering. Then as a team grows, they can
    have a data engineer and a data ops team to support all these tools.
  sec: 3066
  time: '51:06'
  who: Alexey
- header: Data democratization
- line: We also talked about data democratization. As I understood, this is about
    enabling people to access the data, go and analyze the data themselves, go and
    implement some things on top of data themselves. Is there any more to that like
    what is it?
  sec: 3100
  time: '51:40'
  who: Alexey
- line: "Data literacy is a big part of it. You cannot democratize data just by making\
    \ data available or just by giving people access to different tools. Invest in\
    \ data literacy. Have people from less technical teams or business teams know\
    \ how data works. Invest in documentation, invest in data cataloging tools or\
    \ data documentation tools \u2014 tools like Atlan, Secoda."
  sec: 3127
  time: '52:07'
  who: Arpit
- line: "So, invest in data literacy within an organization and then make data available\
    \ in the right tools \u2014 tools where people can actually use their data, not\
    \ just look at dashboards. Then, of course, up-skill them, so they can efficiently\
    \ use product analytics tools to self-serve their analytics needs. Teach them\
    \ some SQL to go and use a BI tool."
  who: Arpit
- line: To sum it up, data democratization is about investing in data literacy, making
    clean accurate data available in the different tools across an organization.
  who: Arpit
- header: Motivating people to document data
- line: Also documented. Available and documented.
  sec: 3210
  time: '53:30'
  who: Alexey
- line: Yes. Especially in a remote world, documenting data is one of the most important
    things.
  sec: 3213
  time: '53:33'
  who: Arpit
- line: "How to motivate people to write data documentation? I know it is difficult.\
    \ As a data scientist, I am the one who\u2019s constantly producing new data for\
    \ others to consume. But this step of documenting the data is annoying. How do\
    \ you convince people like me and others to go and document this data?"
  sec: 3228
  time: '53:48'
  who: Alexey
- line: "It works when you start small and you start early. The earlier that you start,\
    \ the easier it is going to be. If you keep delaying it, it becomes difficult.\
    \ And if there is a tool that can solve your problem, you should explore that\
    \ tool and adopt it. Tools like Atlan \u2014  these new age data documentation\
    \ and data discovery tools \u2014 they integrate with all your data sources and\
    \ they automate documentation and data exploration. If you have a lot of different\
    \ data sources and you have a lot of data in different places and you don\u2019\
    t have a way to efficiently document it, then that is worth exploring these tools."
  sec: 3255
  time: '54:15'
  who: Arpit
- line: But before you invest in a data documentation cataloguing tool, you need to
    have the right data infrastructure in place. It comes after you have data collection,
    warehousing, analysis, activation. All of that should be in place when you invest
    in these tools.
  who: Arpit
- line: "If you are starting today, then it should be table stakes that everything\
    \ that is being tracked should be documented. That\u2019s how you go about it.\
    \ If you don\u2019t start early, then and it\u2019s going to be a mess later on."
  who: Arpit
- line: "So, it \u2018s more about the culture and mindset? You just say, \u201CWe\
    \ need it. We start early. For all the data we produce, we must have documentation.\
    \ Because if we don\u2019t, then it becomes a mess\u201D. Right?"
  sec: 3345
  time: '55:45'
  who: Alexey
- line: "Yeah. It\u2019s important to start early and it\u2019s definitely a culture\
    \ thing. Thanks for mentioning that."
  sec: 3359
  time: '55:59'
  who: Arpit
- header: Product-led vs data-led
- line: "One thing I wanted to ask you at the very beginning, but we didn\u2019t cover\
    \ this yes. There\u2019s a thing called \u201Cproduct-led\u201D. What is product-led?\
    \ What is the difference between being product-led and being data-led?"
  sec: 3368
  time: '56:08'
  who: Alexey
- line: Being product-led requires you to be data-led. The whole idea of being product-led
    is using your product to drive growth rather than investing in sales. Although
    product-led and sales can coexist, one of the principles of product-led is that
    users or prospects or customers should be able to try your product before they
    buy the product. You want to have a free trial or a free plan. People should be
    able to use the product and derive value from it before they are asked to buy
    it.
  sec: 3387
  time: '56:27'
  who: Arpit
- line: "This takes us back to the earlier conversation. I mentioned that the salesperson\
    \ can see that the prospect has actually used the product and derived some value.\
    \ Or, reached the \u201Caha moment\u201D of the product. I often refer to it as\
    \ the \u201Cactivation\u201D event. In a project management tool, it could be\
    \ creating a project, adding one user and creating three tasks. That\u2019s when\
    \ you feel that the user has derived some value from the product."
  who: Arpit
- line: "Typically it applies to organizations, not individuals. In a product-led\
    \ company you invest in these product-led efforts, for example a self-serve onboarding\
    \ experience. For that, you need data. If you don\u2019t have data, then you can\u2019\
    t enable prospects to have that personalized experience when they are starting\
    \ to use your product. A common example is in in-app walk-throughs or onboarding\
    \ walk-throughs that you see when you start using a new product. You can personalize\
    \ it based on the role of the user or the industry of the user. Then you keep\
    \ personalizing it based on the features they are using in the product. You can\
    \ do it only if you are data-led, if you have the data. Using the data to build\
    \ onboarding experiences or triggering emails is a great example."
  who: Arpit
- line: "You might have received an email from a company saying \u201Cyou should try\
    \ using this feature\u201D after you have already used that feature. That\u2019\
    s very common. That\u2019s a bad experience. You have actually opened that email.\
    \ Someone who created that campaign will be happy because they see a good open\
    \ rate. But it actually annoyed you. Their emails are useless. Next day, I am\
    \ not going to open their emails because they are telling me to do things I have\
    \ already done."
  who: Arpit
- line: "If you\u2019re data-led, you don\u2019t do that. You make sure that if someone\
    \ has used a feature, they will not be asked to use that feature again."
  who: Arpit
- line: "I can attempt to summarize what you said. Being product-led applies to a\
    \ company not to an individual. It\u2019s about taking feedback from users, being\
    \ led by this feedback, being led by what users want. To be able to do this, you\
    \ cannot call every user. You need to track the data, you need to have this data\
    \ to make, if I can say that, data driven decisions."
  sec: 3566
  time: '59:26'
  who: Alexey
- line: "Data-informed decisions. Feedback is an important part of it. Gathering feedback\
    \ while people are using the product, running micro surveys in the product or\
    \ even gathering data by looking at heatmaps and session recordings\u2026 All\
    \ of that stuff drives towards a product-led approach."
  sec: 3605
  time: '1:00:05'
  who: Arpit
- header: Wrapping up
- line: Thank you. We should be wrapping up. I wanted to ask you if you want to say
    any last comments? Anything you want to mention.
  sec: 3629
  time: '1:00:29'
  who: Alexey
- line: "Reach out to me in the DataTalk\u2019s slack community if you have any questions.\
    \ I\u2019d love to answer your questions. You can check out dataled.academy and\
    \ you can sign up to my newsletter. It\u2019s not a weekly newsletter, I send\
    \ out almost every two weeks where I share different lessons. You can check out\
    \ the past issues on the website, where a lot of the stuff that I talked about\
    \ is already written, that will be helpful for you. Thanks again for joining and\
    \ listening to us."
  sec: 3640
  time: '1:00:40'
  who: Arpit
- line: Thank you. I will add to what you just said that you should also go and check
    the podcast. How many episodes do you have already?
  sec: 3673
  time: '1:01:13'
  who: Alexey
- line: "We have seven episodes published already. If you are from a data company,\
    \ I\u2019d love to chat with you. If you want to be on the podcast, feel free\
    \ to reach out to me. Seven episodes are live here."
  sec: 3684
  time: '1:01:24'
  who: Arpit
- line: It means that you recorded some which are not published yet?
  sec: 3705
  time: '1:01:45'
  who: Alexey
- line: Yes.
  sec: 3709
  time: '1:01:49'
  who: Arpit
- line: Can you tell how many there are already?
  sec: 3710
  time: '1:01:50'
  who: Alexey
- line: We have three more already in the tube which are ready to go.
  sec: 3713
  time: '1:01:53'
  who: Arpit
- line: Okay, stay tuned.
  sec: 3718
  time: '1:01:58'
  who: Alexey
- line: Absolutely. Thanks again for having me, it was great.
  sec: 3719
  time: '1:01:59'
  who: Arpit
- line: "It was great, indeed, a lot of information. I took so many notes. With these\
    \ tools I will reach out to you later today to get the links from you. Then I\
    \ will put them in the description. Thanks everyone for joining us today for listening.\
    \ I hope you enjoyed it. We didn\u2019t get any questions but there were a lot\
    \ of questions from me. I kept you entertained."
  sec: 3723
  time: '1:02:03'
  who: Alexey
- line: Yeah, it was great. I always like chatting about this stuff. Hopefully we
    will keep the conversation going in on Slack.
  sec: 3753
  time: '1:02:33'
  who: Arpit
- line: Definitely. Thanks again!
  sec: 3762
  time: '1:02:42'
  who: Alexey
---
