---
episode: 2
guests:
- liorbarak
ids:
  anchor: datatalksclub/episodes/How-to-Rebuild-Data-Trust--Mindful-Data-Strategy-and-Maintenance-vs-Innovation---Lior-Barak-e36obcs
  youtube: B76J4QkZPWs
image: images/podcast/s21e02-mindful-data-strategy-from-pipelines-to-business-impact.jpg
links:
  anchor: https://creators.spotify.com/pod/profile/datatalksclub/episodes/How-to-Rebuild-Data-Trust--Mindful-Data-Strategy-and-Maintenance-vs-Innovation---Lior-Barak-e36obcs
  apple: https://podcasts.apple.com/us/podcast/how-to-rebuild-data-trust-mindful-data-strategy-and/id1541710331?i=1000722107501
  spotify: https://open.spotify.com/episode/54B0xvUI1eQjXW0s1eqgbI
  youtube: https://www.youtube.com/watch?v=B76J4QkZPWs
season: 21
short: 'Mindful Data Strategy: From Pipelines to Business Impact'
title: 'Mindful Data Strategy: From Pipelines to Business Impact'
transcript:
- header: Community and mindful data strategy
- line: This week we'll talk about mindful data strategy and how teams can shift from
    building pipelines to delivering real business outcomes.
  sec: 0
  time: 0:00
  who: Alexey
- line: We will look at how principles from the Zen philosophy can help teams work
    more intentionally and effectively.
  sec: 0
  time: 0:00
  who: Alexey
- line: We have a special guest today, Lior. This is not the first time we have had
    a conversation. Last time we spoke a few years ago, more than two and a half.
    Primarily about humus if I remember.
  sec: 144
  time: '2:24'
  who: Alexey
- line: I don't remember other things. The funny thing is today I ate hummus. The
    one from Revit probably you will not approve of. I don't know your opinion about
    humus.
  sec: 144
  time: '2:24'
  who: Alexey
- line: I'm already disappointed
  sec: 168
  time: '2:48'
  who: Lior
- line: But this is at least some humus like it's better than the humus, right? Yeah.
    Lior is a data strategy consultant, former practitioner. Why the former though?
    Maybe you'll tell us. And the author of data is like a plate of humus which is
    why we talked primarily about humus last time.
  sec: 173
  time: '2:53'
  who: Alexey
- line: He developed the data existing vision board and the data product life cycle
    manager frameworks designed to help teams move from reactive tasks to more strategic
    low long-term thinking. Welcome.
  sec: 173
  time: '2:53'
  who: Alexey
- line: Hi, happy to be here. I think the last time we also discussed something very
    similar to this topic about efficiency in uh teams uh structure. So how to make
    sure communication is working well if I remember correctly.
  sec: 206
  time: '3:26'
  who: Lior
- line: I think when I was doing that interview I was actually a practicing manager.
    So let's see how
  sec: 223
  time: '3:43'
  who: Alexey
- line: much of the things we talk about today will resonate with me and uh let's
    see if I actually was able to follow your advice. Let's start with your uh career
    journey so far. Can you tell us more about that?
  sec: 223
  time: '3:43'
  who: Alexey
- header: Career journey and product management insights
- line: So, in the past year I've been working more with smaller-scale to medium-size
    companies trying to basically write down my second book. So when we spoke the
    last time we spoke about my first one which was Data is like a Plate of Humus
    and I'm working on a new book which is more taking the strategic aspect of data.
  sec: 246
  time: '4:06'
  who: Lior
- line: And I think that this is where I am today. Before that I was working at Idialo.
    I was the head of product for the data platform team. Just before that I was basically
    launching my own company Tele Data which the entire idea behind it was to create
    the infrastructure and the tables in an automatic way which will save a lot of
    cost for small companies that don't have the scales and the ability to hire engineers.
  sec: 266
  time: '4:26'
  who: Lior
- line: And before that I was working for Zelando leading there basically the entire
    marketing data operation from the product perspective. So setting up basically
    the infrastructure for the first time ever to have an infrastructure for data
    instead of having a horrible Excel sheet and pythons that break every week that
    you need to run them.
  sec: 294
  time: '4:54'
  who: Lior
- line: And then we moved to ROI forecasting creating basically a better understanding
    of data and then ended up in the marketing automation part of how you actually
    steer the budget of the campaigns and making the best decisions. So this is more
    or less my story path and today I'm practicing a lot of mindfulness in data and
    I think we're going to have a very interesting conversation today.
  sec: 312
  time: '5:12'
  who: Lior
- line: Mindfulness of data. Yes. Okay. That's interesting. So you're more like a
    product person if I got from your description.
  sec: 340
  time: '5:40'
  who: Alexey
- line: I am. I started my career actually as an engineer. I wasn't as good and I
    wasn't as fast as other engineers. I must admit it. I moved more towards the analytic
    side and then I found myself somehow in product something like seven, eight years
    ago and since then I'm staying in the product area. I'm very technical. So if
    you're going to ask me questions about tools I will be able to evaluate their
    architecture as well but my passion is really to bridge the gap between the business
    and the tech I think and actually bringing everybody together.
  sec: 354
  time: '5:54'
  who: Lior
- line: This is not one of the questions we have prepared for you in advance but I
    recently saw a question in one of the data science communities and the question
    was from an engineer. He was asking the community to recommend some resources
    about product management. So do you have any suggestions for somebody who works
    as an engineer or data scientist if they want to learn about product management
    and the product side of things do you have any recommendations for them?
  sec: 385
  time: '6:25'
  who: Alexey
- line: I will be honest. There is the Product Camp Berlin that is once a year if
    anybody is interested and I know they're doing a tour all over the world as well.
    But there's nothing specific for data product dictionaries because I think this
    is very different from the regular product. If you're learning about a product,
    it's a lot about users and communication which is very important for us to be
    able to know. But there is nothing specific yet that I'm aware of but I would
    love to learn if somebody finds something as well.
  sec: 420
  time: '7:00'
  who: Lior
- line: Product Camp, is this the people? I remember attending a workshop when I was
    still at Elix. I think it was Mind the Product something like that.
  sec: 452
  time: '7:32'
  who: Alexey
- line: This is also another one. There is also Buzzwords that is also happening somewhere
    in June I think usually that also connects tech and data together. So there are
    different ways to learn it but for products specifically for data products I haven't
    encountered anything. Maybe this is something I can do next.
  sec: 458
  time: '7:38'
  who: Lior
- header: Wabi-sabi data and the trust crisis
- line: Yeah. After this current book right, what is the title? Do you have the title
    already?
  sec: 483
  time: '8:03'
  who: Alexey
- line: I have a temporary one for now it's called Wabi Sabi Your Data.
  sec: 488
  time: '8:08'
  who: Lior
- line: What can you say it again slower?
  sec: 494
  time: '8:14'
  who: Alexey
- line: Wabi Sabi Your Data which is basically a Japanese concept about accepting
    the imperfections, the perfect imperfections basically and this is basically what
    I think about data. This is a lot of my philosophy about how to handle data. It's
    imperfect and we need to accept it and we should not always fight to have it perfect
    before we going forward. And I think this is one of the biggest issues that we
    are going through today.
  sec: 500
  time: '8:20'
  who: Lior
- line: I see where the mindfulness part comes from the acceptance, right? So don't
    fight it, accept it, right?
  sec: 533
  time: '8:53'
  who: Alexey
- line: Be aware of it, accept it and communicate it. I think if we need to take a
    core out of this conversation today it is be aware, accept it. This is the reality
    and make sure you're communicating it correctly. And I think that this is my biggest
    learning from leading a lot of data initiatives and failing many times as well.
    And I think that we always expect to have this perfect product. We are always
    in the hunt for the perfect product, the next technology, the next thing, the
    next always something next. And actually we should sometimes stop and accept the
    reality.
  sec: 540
  time: '9:00'
  who: Lior
- line: So how do we do this?
  sec: 580
  time: '9:40'
  who: Alexey
- line: Oh, that's a great way. So when we starting and we're talking about it, let's
    talk about the trust crisis, right?
  sec: 588
  time: '9:48'
  who: Lior
- line: So I think that there is a very big trust crisis right now in the industry.
    I saw a research a few weeks ago that 97% of the CEOs mentioned they are using
    data but only 24% said that they are data driven.
  sec: 588
  time: '9:48'
  who: Lior
- line: This is already saying something to us about the difference in how data is
    being used in the organization and how it's being leveraged.
  sec: 588
  time: '9:48'
  who: Lior
- line: And there is a data trust. We are launching products. Yes, we have data governance.
    Yes, we have monitoring. Yes, we have a lot of tools around it to make sure the
    data arrives to the users safely, but in reality the data or the people using
    this data don't trust it and basically this is where the crisis starts.
  sec: 615
  time: '10:15'
  who: Lior
- line: This is why we need to be aware of it. We need to be aware of where the flaws
    are. Data will never be perfect. It's enough that somebody changed one tab in
    the data that is being ingested into the data warehouse and everything can break.
    We need to learn here how to communicate it better.
  sec: 615
  time: '10:15'
  who: Lior
- line: And the fact is that we are looking at many issues right now that are related
    to the trust of people in the data.
  sec: 656
  time: '10:56'
  who: Lior
- line: I don't trust the data team because they are in constant migration. I have
    a CEO I spoke to recently and one of the things that still resonated with me,
    still stuck in my head, is that he has had the data team in the past three years
    running from migration to migration. Each migration taking them six to eight months.
    Everything stuck.
  sec: 656
  time: '10:56'
  who: Lior
- line: This again is a loss of trust in the data team and sometimes we are not even
    aware of it. We don't even see the issue because we are trying to achieve a goal
    but during the attempt to achieve it we actually miss some of the components that
    need to be there.
  sec: 656
  time: '10:56'
  who: Lior
- header: AI, data imperfection, and trust challenges
- line: Funny thing, when you mentioned the trust crisis what came to my mind was
    I have a son, he's nine years old and he likes to use Chip. He speaks with Charity
    a lot and Chip, as we all know, hallucinates sometimes. It comes up with things
    that don't exist.
  sec: 707
  time: '11:47'
  who: Alexey
- line: So he was like, why should we pay, because I have a premium subscription,
    he was like we pay for this tool, we pay them €20 or something like that and it
    outputs garbage, it outputs nonsense. How can we trust, how can we ever trust
    what it says if sometimes it hallucinates?
  sec: 707
  time: '11:47'
  who: Alexey
- line: But then my objection to that was it's actually a very useful tool because
    most of the time it is correct, sometimes it's not. You just need to, how to say,
    cook it. You like cook metaphors, right? You just need to cook it correctly.
  sec: 757
  time: '12:37'
  who: Alexey
- line: And we just accept the fact that sometimes it hallucinates, sometimes it does
    not provide the correct answer.
  sec: 757
  time: '12:37'
  who: Alexey
- line: We must not blindly trust whatever it says. We need to always double check.
    But overall it's quite a useful tool and if we use it, it is super convenient.
    It makes our life easier.
  sec: 757
  time: '12:37'
  who: Alexey
- line: We just need to be mindful of the fact that sometimes it may be super wrong
    but it does not mean we shouldn't stop. We should not continue using this tool
    because it's super useful.
  sec: 757
  time: '12:37'
  who: Alexey
- line: So I was explaining, I was also trying to explain how the model works, that
    it's a language model. All it does is trying to predict the next word and then
    people noticed with time that it's actually something useful. How about we start
    using it? Because most of the time the output is good and sometimes it's not.
  sec: 811
  time: '13:31'
  who: Alexey
- line: So I think it's maybe a very interesting example where there is a trust crisis
    because the tool is useful but then it was wrong a few times and then people think
    okay it's useless, like we should stop using it while it's not the case. It's
    a useful tool, we just need to be accepting of the fact that it might be wrong
    sometimes.
  sec: 811
  time: '13:31'
  who: Alexey
- line: Correct and you know I always explain it and I say also data is like Lego
    bricks. We can connect and we can build a lot of buildings inside it.
  sec: 849
  time: '14:09'
  who: Lior
- line: Sometimes we fall on a fake Lego brick that we bought from not Lego themselves
    but some other generic brand that looks like Lego but it is not connecting, it's
    not working well, right? It's not sitting there as it should and that's exactly
    the problem with data.
  sec: 849
  time: '14:09'
  who: Lior
- line: So we are building a castle out of Lego bricks and sometimes some of these
    bricks are not going to be the original ones and this is something we are going
    to fill in the rest of the construction. And it happens we cannot change it, right?
    Maybe we even need this brick because we don't have enough original bricks because
    we want to build a very big building.
  sec: 880
  time: '14:40'
  who: Lior
- line: But we need to find the right balance between how much we are willing to trust
    and invest in having the bigger picture, so this huge castle, or how much we are
    saying okay now we are stuck and we are waiting until we find a replacement for
    this brick which can take another week until we order it, receive it, and open
    the package.
  sec: 880
  time: '14:40'
  who: Lior
- line: This is something that we need to be aware of. Has it actually happened to
    you like the Lego brick thing?
  sec: 911
  time: '15:11'
  who: Alexey
- line: Oh yes. My kids have a huge box and they had one that was supposed to be Lego
    but it wasn't Lego. Then it didn't connect and they were sitting there frustrated
    trying to connect it to something.
  sec: 921
  time: '15:21'
  who: Lior
- line: Okay. Because what happened to me, I don't know if you're into Lego. I built
    the Millennium Falcon, which is one of the biggest Lego sets you have. And then
    a part was missing. So I had a choice whether to go to a store and buy not an
    original one or wait for two weeks till they sent the replacement.
  sec: 933
  time: '15:33'
  who: Alexey
- line: So I ordered the replacement because it was free but then I went to a store
    and just bought a part. The part was not actually fitting. It didn't fit. So I
    had to use a saw, I had to manually adjust it to make it fit but then in the end
    it worked. So by the time when the part arrived I actually had the entire set
    assembled.
  sec: 933
  time: '15:33'
  who: Alexey
- line: That's cool.
  sec: 983
  time: '16:23'
  who: Lior
- line: Yeah. So it didn't but with enough perseverance I managed to make it work.
    I will take it.
  sec: 988
  time: '16:28'
  who: Alexey
- line: I will keep it for the next time, maybe for the next crisis.
  sec: 994
  time: '16:34'
  who: Lior
- line: But again this is the same as data. When you think about it we sometimes manipulate
    the data so heavily so it's going to fit the pattern we need it, just we can continue
    the building, and then somebody comes like but hold on the color is not the same,
    I can notice it and this is not the original brick and then what do we do with
    it.
  sec: 1001
  time: '16:41'
  who: Lior
- line: I think that this is really where we go a lot of this direction. At the end
    of the day we trust it, we want this construction to sustain.
  sec: 1001
  time: '16:41'
  who: Lior
- line: What we want to do with it and we need it to look good at the end of the day
    as well. So what do we do with this trust crisis? So in my case, I try to explain
    to my son that this tool is useful. We just need to be mindful of its limitations.
  sec: 1022
  time: '17:02'
  who: Alexey
- line: Do you also suggest the same like when you speak with the CEOs that perhaps
    have these trust issues with the data? How do you convince them that we still
    need to rely on data?
  sec: 1022
  time: '17:02'
  who: Alexey
- line: I always say it's like a lot of times when I arrive at companies it's like
    this basketball team that everybody lost hope about and they keep losing. They
    know they have the capabilities and the right people to actually pull the season
    and make it successful. The owners are already frustrated. The fans are frustrated
    on them and they are just in this slow moment.
  sec: 1052
  time: '17:32'
  who: Lior
- line: And I think that what we need to do is have much better communication. So
    what I realized is that the default of a lot of us is to go into tools.
  sec: 1052
  time: '17:32'
  who: Lior
- line: Okay, so now we need to have a monitoring tool. Now we need to have a new
    governance system to do the catalog and the lineage and so on. And we keep extending
    tools instead of actually stopping for a second stepping backwards.
  sec: 1084
  time: '18:04'
  who: Lior
- line: This is where we go into mindfulness and reflect on why we have the crisis
    issues of losing trust. Why, what are the main drivers of it? Is it specific products?
    Is it specific things? How do we actually create the right environment for us
    to reflect and understand?
  sec: 1084
  time: '18:04'
  who: Lior
- line: And I think that this is something that we are missing a lot. And this is
    also something that will help the CEOs to understand where the problems are because
    when we come and say okay we need now a new tool most of the CEOs freak out already.
  sec: 1117
  time: '18:37'
  who: Lior
- line: It's like why do they need another tool now? I'm already paying 500,000, one
    million, two million dollars on the data team and now adding another tool to it.
    It's another 100,000 or 200,000 on overheads.
  sec: 1117
  time: '18:37'
  who: Lior
- line: What is actually the end goal of it? How do we actually create something?
  sec: 1144
  time: '19:04'
  who: Lior
- line: And I think again this is why we create this crisis because we don't communicate
    clearly. We don't really prioritize and clarify what is important, what is not,
    and we don't talk the language of impact. So if we say and we think that a data
    quality tool will be important and going to help us then why and how is it going
    to basically impact the business goals?
  sec: 1144
  time: '19:04'
  who: Lior
- line: Is it going to improve the stability of the marketing data? So they will be
    able to make better decisions and steer the budget?
  sec: 1144
  time: '19:04'
  who: Lior
- line: By that we are going to save between 20 to 50,000 euros a month on marketing
    campaigns that are basically wasting our money. We are already talking a monetary
    value. We have a different conversation and now people are looking at it not as
    a trust issue but more as a communication gap.
  sec: 1180
  time: '19:40'
  who: Lior
- line: And now let's see how we can figure this one out.
  sec: 1180
  time: '19:40'
  who: Lior
- header: Trust crisis examples and root cause analysis
- line: We should get out of the crisis. We should get out of the chaos. We should
    ride the chaos and flow with it. Accept it and continue there.
  sec: 1205
  time: '20:05'
  who: Lior
- line: To me it sounds a bit abstract. Do you have some examples to make it more
    concrete? Let's say we have this trust crisis but then you were saying that yeah
    we don't
  sec: 1218
  time: '20:18'
  who: Alexey
- line: I necessarily need another tool.
  sec: 1218
  time: '20:18'
  who: Alexey
- line: We need to think about what is important, what is not important. We need to
    take a step backwards. Do you have an example of a situation where, how to say,
    I'm just trying to visualize this and having a concrete example will help to understand
    it better.
  sec: 1228
  time: '20:28'
  who: Alexey
- line: Think about the core KPI dashboard for management. They need it daily to understand
    how the business operation goes.Let’s say it’s an e-commerce company selling shoes.
    The KPI could be the number of sales, for example.
  sec: 1250
  time: '20:50'
  who: Lior
- line: This is not related to any specific company, just the core principle here.
    The dashboard exists, and management needs to use it. When there is a lack of
    trust, what happens in many organizations is that the CEO asks the CFO, “Are the
    numbers accurate? Can I trust them?”
  sec: 1269
  time: '21:09'
  who: Lior
- line: Then the CFO goes to the analyst. The numbers include revenues, sales, stock
    availability, and so on. The CEO doesn’t have time to supervise this directly,
    and this is where the crisis starts.
  sec: 1286
  time: '21:26'
  who: Lior
- line: If the CEO needs to check every day whether the numbers are correct or not,
    and whether they can make decisions based on them or second guess themselves,
    this is a big problem.
  sec: 1286
  time: '21:26'
  who: Lior
- line: We want to make sure the core KPI is correct and delivered reliably to those
    who use it. What we need to check is what will improve this. If we invest in an
    extra tool, or check where the issues are in the data pipeline or lineage is the
    problem at the start, middle, or end?
  sec: 1322
  time: '22:02'
  who: Lior
- line: Maybe the SQL code is broken when computing the data for the dashboard, or
    ingestion is failing because a team isn’t ingesting the data correctly.
  sec: 1351
  time: '22:31'
  who: Lior
- line: We need to be much more aware of these patterns. A tool might be the easy
    solution, but implementing it can take six to eight months. It could be that the
    product team is ingesting incorrect data daily and constantly changing the data
    structure, screwing up reports upstream toward the dashboard.
  sec: 1363
  time: '22:43'
  who: Lior
- line: This is where data trust is lost in most cases.
  sec: 1387
  time: '23:07'
  who: Lior
- line: It’s usually not the tool malfunctioning, but failures in some process components
    that we are not aware of or don’t know how to fix. We often default to software
    solutions rebuilding pipelines or adding monitoring tools on data ingestion.
  sec: 1387
  time: '23:07'
  who: Lior
- line: But that is the easiest, not the core, solution for building trust.
  sec: 1406
  time: '23:26'
  who: Lior
- line: The CEO might still not trust the dashboard because of past bad experiences
    with data quality.
  sec: 1406
  time: '23:26'
  who: Lior
- line: Why does the CEO ask the CFO if the numbers are correct? Is it because the
    numbers look strange or because of previous problems with incorrect data?
  sec: 1430
  time: '23:50'
  who: Alexey
- line: There are many cases. Sometimes teams present different numbers. For example,
    marketing presents numbers different from the core KPI dashboard, creating a crisis.
  sec: 1451
  time: '24:11'
  who: Lior
- line: Another case is when the CEO used numbers later proven wrong by someone notifying
    him a month after the fact the numbers he showed to investors were not accurate.
    It was completely fake, and this happens a lot.
  sec: 1451
  time: '24:11'
  who: Lior
- line: As data people, we often see these problems but don’t act fast enough to solve
    them or to make people feel more trustful of the data.
  sec: 1482
  time: '24:42'
  who: Lior
- line: So trust is already lost. The CFO and CEO don't believe the data. We need
    to do something.
  sec: 1494
  time: '24:54'
  who: Alexey
- header: Regaining trust through mindful data management
- line: Let me ask you, if someone gave you a dashboard about your podcast listeners,
    would you automatically trust the data? Or would you validate it first?
  sec: 1506
  time: '25:06'
  who: Lior
- line: For Spotify, I automatically trust it because it’s the only data source I
    have. Having a number is better than no number.
  sec: 1518
  time: '25:18'
  who: Alexey
- line: That's the pragmatic approach. But if you run a business, you want numbers
    that create the right impact. For instance, with a podcast, when you approach
    advertisers, you want to give numbers that convince them it’s worth investing
    in ads.
  sec: 1535
  time: '25:35'
  who: Lior
- line: This also applies to CEOs who need to prove to investors that the business
    is functioning well and heading in the right direction. Investments often come
    in chunks based on milestones, so you need credible numbers to justify them.
  sec: 1560
  time: '26:00'
  who: Lior
- line: Otherwise, misreporting numbers can lead to accusations of fraud. This is
    why CEOs ask CFOs to validate numbers and ensure they match what’s in the bank.
  sec: 1590
  time: '26:30'
  who: Lior
- line: Otherwise, auditors might come and close the company.
  sec: 1609
  time: '26:49'
  who: Alexey
- line: Exactly. There is a case in the US where a CEO reported sales numbers ten
    times higher than reality due to a database error where figures were multiplied
    by about ten.
  sec: 1614
  time: '26:54'
  who: Lior
- line: After discovering it, he kept reporting the inflated numbers because he couldn’t
    go back on what he reported.
  sec: 1614
  time: '26:54'
  who: Lior
- line: So he knew about the mistake but continued to report inaccurate data?
  sec: 1648
  time: '27:28'
  who: Alexey
- line: Yes, because he didn’t have a solution. That’s a very bad case we should avoid.
  sec: 1655
  time: '27:35'
  who: Lior
- line: When a CEO realizes the data was drastically wrong, he needs to explain to
    investors why the error wasn’t found earlier, what is being done to prevent it,
    and how the numbers will be accurate going forward.
  sec: 1655
  time: '27:35'
  who: Lior
- line: This also affects future investment decisions.
  sec: 1682
  time: '28:02'
  who: Lior
- line: How do we regain trust?
  sec: 1687
  time: '28:07'
  who: Alexey
- line: 'Regaining trust requires a mindful approach to data management and better
    control over what we do. I see three main components in day-to-day work: maintenance,
    product rollouts, and product innovation.'
  sec: 1692
  time: '28:12'
  who: Lior
- line: In all three, we must focus on the end user  the data consumer. What do they
    need first? What does a minimum viable product (MVP) look like for reporting?
    We then work closely with users long term, especially during maintenance, understanding
    where issues come from, their frequency, and root causes.
  sec: 1718
  time: '28:38'
  who: Lior
- line: Many teams experience data incidents. But few use data from these incidents
    to identify recurring problems. If, for example, three core products cause 60-70%
    of incidents, we can focus on fixing root causes.
  sec: 1756
  time: '29:16'
  who: Lior
- line: Knowing where issues happen and how often helps communicate to teams the impact
    of their work. This transparency creates shared reality and easier company alignment.
  sec: 1756
  time: '29:16'
  who: Lior
- line: The dashboard is no longer seen as “broken because of you,” but a problem
    to solve collaboratively because incorrect data risks losing investments. This
    is the first part of regaining trust.
  sec: 1810
  time: '30:10'
  who: Lior
- header: Traffic light system and effective communication
- line: 'Second, for the CEO, we can add a traffic light indicator on the dashboard:
    green, yellow, red.'
  sec: 1847
  time: '30:47'
  who: Lior
- line: Green means data is reliable, yellow means data can be used but there are
    known issues, red means data is broken and not trustworthy.
  sec: 1847
  time: '30:47'
  who: Lior
- line: This shifts communication from the CEO asking “Is the data correct?” to “Here’s
    the current status.”
  sec: 1847
  time: '30:47'
  who: Lior
- line: When yellow or red occurs, the team explains the problem and estimated fix
    time.
  sec: 1891
  time: '31:31'
  who: Lior
- line: If following investigation the data is verified, yellow can turn green. If
    issues persist, it moves to red until fixed.
  sec: 1891
  time: '31:31'
  who: Lior
- line: From my experience talking to data teams, the biggest gap is communication,
    not technology.
  sec: 1998
  time: '33:18'
  who: Lior
- line: We often tell data users to find errors themselves because “they know their
    data best.”
  sec: 1998
  time: '33:18'
  who: Lior
- line: This causes lost trust, as users spend 2-3 hours daily validating data instead
    of working on features or campaign optimization.
  sec: 1998
  time: '33:18'
  who: Lior
- line: If users can tell us patterns of data quality, we can automate the status
    indicators — the traffic light system.
  sec: 1998
  time: '33:18'
  who: Lior
- line: Imagine an analyst sees a data discrepancy while doing their work. They flag
    it to the product manager to investigate.
  sec: 2079
  time: '34:39'
  who: Alexey
- line: Then the data team changes the dashboard traffic light from green to yellow,
    showing a potential issue being investigated. When the analyst provides concrete
    examples, the status might move to red until resolved. If a clear communication
    channel exists, this keeps all stakeholders informed that data is under investigation,
    not to be blindly trusted yet.
  sec: 2097
  time: '34:57'
  who: Alexey
- line: Is that how it works in practice? Or have you seen other ways to set this
    up?
  sec: 2142
  time: '35:42'
  who: Alexey
- line: There are many automation approaches. For example, analysts check data and
    create logs during ingestion that are stored in a simple database, like PostgreSQL.
  sec: 2147
  time: '35:47'
  who: Lior
- line: Daily scans compare logs against trends to flag anomalies. Analysts can then
    deep dive into suspicious data, adjusting the dashboard status as necessary. This
    provides an easy-to-understand system for all users.
  sec: 2165
  time: '36:05'
  who: Lior
- line: Data consumers don’t care about backend complexity; they just want reliable
    data. We must simplify communication to meet that need. Similarly, when a data
    incident occurs, users care about resolution, not the technical details.
  sec: 2198
  time: '36:38'
  who: Lior
- line: If data loss costs the company €200,000 to fix, we need to communicate clearly
    why and how the money is being spent.
  sec: 2198
  time: '36:38'
  who: Lior
- line: Based on my experience, transparency and communication are the biggest gaps,
    not the tools.
  sec: 2249
  time: '37:29'
  who: Lior
- header: Communication gaps and team workload balance
- line: If you start a project from scratch in a greenfield you can design this traffic
    light system from the beginning.
  sec: 2261
  time: '37:41'
  who: Alexey
- line: You create the dashboard with KPIs, and the traffic light is integrated from
    day one, which works well.
  sec: 2261
  time: '37:41'
  who: Alexey
- line: But in most cases, there’s already an existing product, dashboard, and trust
    issues. What do we do then?
  sec: 2287
  time: '38:07'
  who: Alexey
- line: We start by identifying patterns. One key area is team stress levels and how
    their efforts divide among maintenance, innovation, and rollout.
  sec: 2299
  time: '38:19'
  who: Lior
- line: Maintenance involves existing products used by users; we must track tickets,
    identify patterns, and prioritize fixes.
  sec: 2317
  time: '38:37'
  who: Lior
- line: Sometimes, products cause recurring issues and should be deprecated to focus
    efforts more effectively. New rollouts require user growth and integration with
    the traffic light system.
  sec: 2317
  time: '38:37'
  who: Lior
- line: Teams should analyze historical tickets to understand issues. If past data
    isn’t available, start now; 30 to 60 days are enough to get meaningful insights.
  sec: 2361
  time: '39:21'
  who: Lior
- line: This gives a good indication of product health and where trouble lies.
  sec: 2361
  time: '39:21'
  who: Lior
- line: You’re talking about the data team stress index, right?
  sec: 2391
  time: '39:51'
  who: Alexey
- line: Yes, that’s part of it.
  sec: 2394
  time: '39:54'
  who: Lior
- header: Maintenance stress and embracing Zen mindset
- line: I’m trying to understand how to implement this practically. Teams spend time
    on maintenance, rollout, and innovation.
  sec: 2398
  time: '39:58'
  who: Alexey
- line: As a former data scientist, I imagine people want to focus on innovation rather
    than maintenance or rollout.
  sec: 2409
  time: '40:09'
  who: Alexey
- line: Maintenance is fixing bugs, which is acceptable, but rollout isn’t very fun
    either. Yet these are necessary.
  sec: 2426
  time: '40:26'
  who: Alexey
- line: Does the stress index go up when teams get stuck mostly in maintenance and
    rollout with little innovation?
  sec: 2426
  time: '40:26'
  who: Alexey
- line: Maintenance is often higher than people realize, driven by multiple factors.
  sec: 2457
  time: '40:57'
  who: Lior
- line: We keep releasing new products but ignore ongoing maintenance and support.
  sec: 2457
  time: '40:57'
  who: Lior
- line: Healthy maintenance should be about 45 percent of time bug fixes, ad hoc requests,
    and even meetings count as disruptions.Innovation usually gets 10 to 20 percent
    of time; some teams reach 30 percent, but it’s often unclear how much they should
    allocate because maintenance constantly interrupts them.
  sec: 2481
  time: '41:21'
  who: Lior
- line: 'Rollout closes the loop: after innovating and creating something new, you
    ensure users actually use and like it, not just that project completion is ticked
    off. Maintenance over 45 percent already puts teams under stress.'
  sec: 2536
  time: '42:16'
  who: Lior
- line: Adding innovation targets raises stress further because maintenance pulls
    them back, making task completion difficult.
  sec: 2567
  time: '42:47'
  who: Lior
- line: For example, a team built a forecasting model for marketing CLV a valuable
    feature.  They gave it to marketing and product teams, who started using it; eventually,
    the model broke.
  sec: 2592
  time: '43:12'
  who: Lior
- line: No one monitored who the users were or how to use it; no one maintained it
    long term.
  sec: 2592
  time: '43:12'
  who: Lior
- line: This leads to chaos, collapse, and loss of trust. Once trust in a model is
    lost, it’s very hard to regain.
  sec: 2631
  time: '43:51'
  who: Lior
- line: One important thing I noted is that a healthy level of maintenance is around
    45 percent. If you only innovate all the time, you don’t have time for maintenance.
    You just keep releasing products and don’t fix the problems in them. We all know
    fixing problems isn’t fun; creating new things is more enjoyable.
  sec: 2652
  time: '44:12'
  who: Alexey
- line: But we need to take care of existing things too. If all we do is innovate,
    bugs and inconsistencies build up. That leads to lost trust. On the other hand,
    if we spend too much time on maintenance, we can’t innovate anymore. That’s also
    a problem.
  sec: 2679
  time: '44:39'
  who: Alexey
- line: Correct.
  sec: 2699
  time: '44:59'
  who: Lior
- line: Okay, clear. Now, the first question I had on the list, which we kind of diverged
    from, is about you describing yourself as a data Zen master.
  sec: 2709
  time: '45:09'
  who: Alexey
- line: What are these Zen principles? We talked about mindfulness, but in practice,
    how do you achieve Zen when dealing with all these problems? How do you make peace
    with yourself and the teams around you?
  sec: 2727
  time: '45:27'
  who: Alexey
- line: We talked about wabi-sabi, the concept of imperfection. I bring this key concept
    to many teams.
  sec: 2747
  time: '45:47'
  who: Lior
- line: We need to accept that whatever tool or product we innovate and roll out won’t
    be perfect long term; it will become imperfect at some point. It’s about being
    aware of what you’re doing, understanding its impact, and balancing short-term
    and long-term actions.
  sec: 2752
  time: '45:52'
  who: Lior
- line: It means planning a direction for a journey like having a vision for the next
    three years of how the data ecosystem will look. While we might commit to innovating
    50 initiatives this year, we won’t achieve all of them because disruptions happen.
  sec: 2778
  time: '46:18'
  who: Lior
- line: It’s about mindfulness and acceptance. It’s not about teams becoming completely
    relaxed or meditative.
  sec: 2799
  time: '46:39'
  who: Lior
- line: The data is wrong... but what can we do?
  sec: 2818
  time: '46:58'
  who: Alexey
- line: We’re just here for the paycheck, right?
  sec: 2824
  time: '47:04'
  who: Lior
- line: It’s broken but.
  sec: 2829
  time: '47:09'
  who: Alexey
- line: We have many options to handle this. The main idea is to be aware.
  sec: 2835
  time: '47:15'
  who: Lior
- line: For example, my late grandma used to make an amazing strawberry cake. The
    strawberry season lasts only about a month and a half.
  sec: 2835
  time: '47:15'
  who: Lior
- line: Her work took about three days to prepare the cake. When it was ready, she’d
    make sure to slice it carefully so everyone got a piece and enjoyed it. She said,
    “Enjoy the bites because it won’t come again until next year. I don’t freeze strawberries;
    I only use fresh ones.”
  sec: 2853
  time: '47:33'
  who: Lior
- line: This is like how data teams should think. There is a limited cake of hours
    we can invest. We must slice it carefully to deliver the right impact for the
    organization.
  sec: 2853
  time: '47:33'
  who: Lior
- line: At the same time, we need to enjoy the process not be in constant burnout,
    rushing to do everything. We shouldn’t always say, “It’s broken, it’s not the
    right cake.” We need to enjoy the strawberry cake.
  sec: 2900
  time: '48:20'
  who: Lior
- line: There’s no way around you. It’s always about cooking with you, huh? Does it
    have to do with cooking? Sorry. Wabi-sabi sounds like wasabi.
  sec: 2929
  time: '48:49'
  who: Alexey
- line: It sounds like it, but it’s not. It’s a concept of imperfection accepting
    reality as it is. It’s about riding the flow, accepting the imperfections, enjoying
    the seasons, just like going outside and seeing the changing seasons.
  sec: 2941
  time: '49:01'
  who: Lior
- header: Accepting imperfection and measuring impact
- line: You live in Berlin, right?
  sec: 2969
  time: '49:29'
  who: Alexey
- line: Just outside Berlin.
  sec: 2971
  time: '49:31'
  who: Lior
- line: In Berlin, if people want to swim in the sea, they go to the Baltic Sea, which
    is super cold and the only sea nearby.
  sec: 2976
  time: '49:36'
  who: Alexey
- line: So they either enjoy that sea or don’t enjoy the sea at all, right?
  sec: 2989
  time: '49:49'
  who: Alexey
- line: Similarly, there is data, and people need to use it. That’s not going to change.
  sec: 3008
  time: '50:08'
  who: Lior
- line: With large language models and generative AI, demand for data will increase
    massively.
  sec: 3008
  time: '50:08'
  who: Lior
- line: Some teams hide from this because of “garbage in, garbage out” fears.But we
    need to fix these issues, and we can’t fix them until we are aware of where the
    problems are and how to address them. For me, that awareness and acceptance that
    mindfulness toward data is what Zen means here. It’s philosophy, not religion.
  sec: 3014
  time: '50:14'
  who: Lior
- line: You mentioned accepting that a tool or product isn’t perfect. You launch an
    MVP acknowledging data might be off, but you have short-term and long-term plans
    to improve it.
  sec: 3047
  time: '50:47'
  who: Alexey
- line: If the project continues, here’s how it will improve step by step. How do
    you know when it’s good enough ready to be shown? When do you decide the imperfect
    data is still useful enough to make decisions?
  sec: 3076
  time: '51:16'
  who: Alexey
- line: We know by measuring impact. This is not spiritual, it's about what works
    and what creates value. If the MVP already supplies value even if ROI is negative
    but improving we did something good.
  sec: 3101
  time: '51:41'
  who: Lior
- line: 'In the long term, data products have a lifecycle: development (usually negative
    ROI), rollout (people start using it and ROI improves), maturity (value peaks),
    and then decline (ROI drops, user satisfaction lowers).'
  sec: 3124
  time: '52:04'
  who: Lior
- line: At decline, it may be time to kill the product and try something new. If the
    MVP produces value whether cost savings or revenue generation it’s a success.
  sec: 3178
  time: '52:58'
  who: Lior
- line: For example, a new recommendation engine might improve conversion by 2.5%.
    That increase translates to real revenue impact and can be forecasted long-term.
  sec: 3214
  time: '53:34'
  who: Lior
- line: In your example about customer lifetime value prediction, it went through
    all those lifecycle stages, right? At the start, a prototype could already make
    it possible for users to take action based on its output.
  sec: 3247
  time: '54:07'
  who: Alexey
- line: Most suggestions lead to positive ROI, even if sometimes the model isn’t perfect.
  sec: 3295
  time: '54:55'
  who: Alexey
- line: I have seen cases where a model was what users needed but the cost was higher
    than revenue generated, so ROI was negative. You need to evaluate if it makes
    sense to continue.
  sec: 3313
  time: '55:13'
  who: Lior
- line: 'The CLV model reached maturity and was valuable, but eventually declined
    because maintenance and optimization efforts stopped. This applies to any product:
    if you don’t keep maintaining and listening to users, people will drop it.'
  sec: 3338
  time: '55:38'
  who: Lior
- line: We have many audience questions. Do you need to leave soon or can we continue?
  sec: 3372
  time: '56:12'
  who: Alexey
- line: I can continue, let's do it.
  sec: 3374
  time: '56:14'
  who: Lior
- header: Legacy systems and managing executive requests
- line: 'Here is an interesting one about legacy monolith databases that remain the
    core of the business: how do you handle trust issues when these systems are already
    broken?'
  sec: 3379
  time: '56:19'
  who: Alexey
- line: Legacy projects often can’t be replaced easily. How do you find root causes
    and solve trust?
  sec: 3404
  time: '56:44'
  who: Alexey
- line: Legacy systems are tricky. I was at a company recently where a legacy system
    automated campaign budget steering. It was built by someone who left, and it started
    to fail.
  sec: 3415
  time: '56:55'
  who: Lior
- line: The replacement team tried maintaining it but couldn’t fix it. We worked together
    to calculate the cost of errors and decided to stop accepting the broken product
    as is.
  sec: 3441
  time: '57:21'
  who: Lior
- line: We agreed to do only minimal maintenance and focus on building a new product
    to replace it so the company could move forward.
  sec: 3460
  time: '57:40'
  who: Lior
- line: Legacy systems are often dead weight, but we carry them around trying to survive.
    At some point, we must stop and replace.
  sec: 3460
  time: '57:40'
  who: Lior
- line: At Zalando, when I arrived, there was a Python script that required six people
    to manually copy-paste data daily from Excel sheets. It was a huge operation that
    didn’t work well and only produced value once a week instead of daily.
  sec: 3486
  time: '58:06'
  who: Lior
- line: We stopped fighting to keep it going and built a new data warehouse using
    PostgreSQL with simple APIs, then connected Tableau dashboards.
  sec: 3520
  time: '58:40'
  who: Lior
- line: People loved the drag-and-drop dashboards compared to heavy Excel sheets that
    crashed frequently. When replacing legacy systems, we must focus on the impact
    and added value we deliver to users.
  sec: 3551
  time: '59:11'
  who: Lior
- line: This impact is the selling point for replacement.
  sec: 3551
  time: '59:11'
  who: Lior
- line: Legacy systems can seem good enough until they break, and then it’s hard to
    fix them.
  sec: 3574
  time: '59:34'
  who: Alexey
- line: Sometimes people fall in love with legacy systems and refuse to move on.
  sec: 3586
  time: '59:46'
  who: Lior
- line: Like a genius wrote it overnight, but nobody remembers how, and they’re still
    proud.
  sec: 3593
  time: '59:53'
  who: Alexey
- line: Yes. We need the right balance. Ultimately, it’s all about impact communicating
    the current bad impact and the better impact with replacement.
  sec: 3599
  time: '59:59'
  who: Lior
- line: Make sure the new product’s impact is much better than the old one.
  sec: 3599
  time: '59:59'
  who: Lior
- header: Role guidance and closing reflections
- line: 'Thanks. Another question: how do you handle ad hoc requests from executives?'
  sec: 3623
  time: '1:00:23'
  who: Alexey
- line: Say no. Just kidding.
  sec: 3628
  time: '1:00:28'
  who: Lior
- line: With executives, you need to understand why they need it and what impact they
    expect.
  sec: 3628
  time: '1:00:28'
  who: Lior
- line: When teams talk in the CEO’s language, CEOs start reacting differently.
  sec: 3659
  time: '1:00:59'
  who: Quantifying the value changes the conversation drastically.
- line: 'Thanks. Last question: you started in development, moved to analytics, then
    product. How can someone tell if they are more suited for analytics or engineering?'
  sec: 3704
  time: '1:01:44'
  who: Alexey
- line: It depends on what you feel comfortable with.
  sec: 3728
  time: '1:02:08'
  who: Lior
- line: Engineering is about solutions. I enjoyed solving problems, but honestly,
    it wasn’t my main fun.
  sec: 3735
  time: '1:02:15'
  who: Lior
- line: Analytics is about refining problems and providing solutions.
  sec: 3735
  time: '1:02:15'
  who: Lior
- line: Product is about defining and scoping problems, then passing them to engineers
    for solutions and refining based on feedback.
  sec: 3753
  time: '1:02:33'
  who: Lior
- line: 'Think about what you enjoy more: the problem space or the solution space?'
  sec: 3753
  time: '1:02:33'
  who: Lior
- line: In the solution space, do you prefer working on explaining problems or solving
    them?
  sec: 3779
  time: '1:02:59'
  who: Lior
- line: So it’s about mindset what you prefer doing.
  sec: 3792
  time: '1:03:12'
  who: Alexey
- line: I was always an engineer. I tried product management courses, like Mind the
    Product workshops. I took a Udacity nanodegree on product management. One module
    covered scrum and team processes.
  sec: 3798
  time: '1:03:18'
  who: Alexey
- line: I asked a product manager if that’s really what they do, and they said yes
    all day long. I realized I don’t want to do that; I’d rather just build things.
  sec: 3822
  time: '1:03:42'
  who: Alexey
- line: It gives perspective. Many engineers want to move to product and vice versa.
  sec: 3841
  time: '1:04:01'
  who: Lior
- line: Product is about problems, talking to stakeholders, creating tickets, and
    accepting that maybe only 20% of tickets will be relevant next month.
  sec: 3849
  time: '1:04:09'
  who: Lior
- line: 'Mindfulness and acceptance are key: it won’t always work perfectly.'
  sec: 3849
  time: '1:04:09'
  who: Lior
- line: Engineers also need to accept that some code won’t be accepted but at least
    they’re solving problems.
  sec: 3870
  time: '1:04:30'
  who: Lior
- line: Okay, thanks so much for the time and answers. Lovely talking with you. When
    you write your third book after Wabi-Sabi, you’re always welcome as a guest again.
  sec: 3876
  time: '1:04:36'
  who: Alexey
- line: Maybe sooner than three or four years! We’ll always need your advice on hummus.
    No way around that.
  sec: 3902
  time: '1:05:02'
  who: Alexey
- line: I still go to restaurants because most supermarket hummus in Berlin isn’t
    just chickpeas it has a lot of oil. I prefer pure. But the easiest is to buy a
    can of chickpeas, cook a bit, add tahini, mix it, and you have better hummus than
    most supermarket versions.
  sec: 3928
  time: '1:05:28'
  who: Lior
- line: Next time we speak, I’ll report on my progress making hummus at home.
  sec: 3965
  time: '1:06:05'
  who: Alexey
- line: Thank you! Amazing talking with you and thanks everyone for listening today.
  sec: 3965
  time: '1:06:05'
  who: Alexey
---

Links:

* [LinkedIn](https://www.linkedin.com/in/liorbarak/){:target="_blank"}
* [Website](https://cookingdata.substack.com/){:target="_blank"}
* [Cooking Data newsletter](https://cookingdata.substack.com/){:target="_blank"}
* [Product product lifecycle manager](https://app--data-product-lifecycle-manager-c81b10bb.base44.app/){:target="_blank"}