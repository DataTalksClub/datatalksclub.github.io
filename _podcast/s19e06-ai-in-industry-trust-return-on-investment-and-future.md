---
episode: 6
guests:
- mariasukhareva
ids:
  anchor: atalksclub/episodes/AI-in-Industry-Trust--Return-on-Investment-and-Future---Maria-Sukhareva-e2rp9f8
  youtube: bT7-HRNCltk
image: images/podcast/s19e06-ai-in-industry-trust-return-on-investment-and-future.jpg
links:
  anchor: https://creators.spotify.com/pod/show/datatalksclub/episodes/AI-in-Industry-Trust--Return-on-Investment-and-Future---Maria-Sukhareva-e2rp9f8
  apple: https://podcasts.apple.com/us/podcast/ai-in-industry-trust-return-on-investment-and-future/id1541710331?i=1000679505962
  spotify: https://open.spotify.com/episode/5GOBabz65IRmiMow8FYbr5?si=a99463e34ffb48f1
  youtube: https://www.youtube.com/watch?v=bT7-HRNCltk
season: 19
short: 'AI in Industry: Trust, Return on Investment and Future'
title: 'AI in Industry: Trust, Return on Investment and Future'
transcript:
- header: 'AI in Industry: Trust, Return on Investment and Future'
- line: This week, we’re discussing the practical application of generative AI in
    industry. Our special guest today is Maria, a Principal Key Expert in Artificial
    Intelligence at Siemens.
  sec: 0
  time: 0:00
  who: Alexey
- line: Maria has over 15 years of experience in AI and has a reputation for transforming
    advanced AI research into impactful, practical tools. Her work focuses on creating
    scalable solutions that enhance decision-making and streamline processes.
  sec: 0
  time: 0:00
  who: Alexey
- line: Also, for anyone only listening to the audio version, you might want to check
    out the video because we just saw a cute cat!
  sec: 0
  time: 0:00
  who: Alexey
- line: Welcome, Maria! Thanks to Johanna Bayer for preparing today’s questions. Let’s
    start with your background. Can you tell us about your career journey so far?
  sec: 0
  time: 0:00
  who: Alexey
- header: 'Career journey: From linguistics to AI'
- line: Thank you for the introduction. I started as a linguist, studying traditional
    linguistics and translation over 20 years ago. I later discovered my interest
    in programming and computer science, but I already had a degree in linguistics.
  sec: 133
  time: '2:13'
  who: Maria
- line: I applied for and received a scholarship to pursue a master’s degree in computational
    linguistics in Ireland. Afterward, I worked as a researcher in Frankfurt and then
    in the UK with the P Group under Irina Grech. Following that, I transitioned to
    the industry, starting as a data scientist at BMW in the NLP group.
  sec: 133
  time: '2:13'
  who: Maria
- line: 'Eventually, I moved to Siemens, where I currently work. A quick note, as
    per my legal department: I’m a Siemens employee, but all opinions expressed during
    this podcast are my own.'
  sec: 133
  time: '2:13'
  who: Maria
- line: Now, I’m a Principal Key Expert in Artificial Intelligence, focusing on innovative
    applications of AI.
  sec: 133
  time: '2:13'
  who: Maria
- line: In industry, we often hear titles like Junior Data Scientist or Senior Data
    Scientist. What does "Key Expert" mean in your role?
  sec: 228
  time: '3:48'
  who: Alexey
- line: Great question! These days, the term "AI expert" can carry mixed connotations
    because it seems like everyone claims to be one.
  sec: 251
  time: '4:11'
  who: Maria
- line: As an AI expert, our role is to manage technology, not people. We stay updated
    on state-of-the-art advancements, critically evaluate them, and advise management
    on which technologies to adopt or avoid. This includes understanding the limitations
    and potential risks of various AI solutions.
  sec: 251
  time: '4:11'
  who: Maria
- line: Why do you think there are so many "AI experts" now? Is it because tools like
    ChatGPT have made AI more accessible?
  sec: 328
  time: '5:28'
  who: Alexey
- line: Exactly. AI has become very accessible. Previously, being an AI expert required
    coding skills. Now, simply knowing how to use a keyboard and craft prompts can
    position someone as a "prompt engineer" or even an AI expert.
  sec: 342
  time: '5:42'
  who: Maria
- line: Of course, this trend won’t last forever. The demand for such roles will eventually
    stabilize as industries refine their needs.
  sec: 342
  time: '5:42'
  who: Maria
- line: Additionally, many companies want to appear innovative by adopting AI, whether
    or not it’s the best fit. As the saying goes, "When all you have is a generative
    AI hammer, everything looks like a generative AI nail."
  sec: 342
  time: '5:42'
  who: Maria
- line: I just came back from a forest, and the weather has been perfect for mushrooms—lots
    of humidity. It reminds me of the growth of AI experts these days.
  sec: 449
  time: '7:29'
  who: Alexey
- line: I’m a big fan of mushroom picking! I’ve stored about 10 kilograms of frozen
    mushrooms this season. It’s been a great year for both mushrooms and AI experts.
  sec: 463
  time: '7:43'
  who: Maria
- header: The Evolution of AI Expertise and its Future
- line: That’s exactly what I was getting at. But maybe this wave of new AI experts
    isn’t entirely bad. It allows people without a technical background to contribute
    meaningfully.
  sec: 482
  time: '8:02'
  who: Alexey
- line: That’s a natural evolution. When any field becomes popular, those who are
    genuinely successful stay, while others eventually move on.
  sec: 504
  time: '8:24'
  who: Maria
- line: 'We often see this pattern in Gartner’s Hype Cycle: initial high expectations
    give way to a more practical and integrated adoption of the technology. The same
    will happen with AI.'
  sec: 504
  time: '8:24'
  who: Maria
- line: Also, I think it’s great that so many people are experimenting and learning.
    There’s no harm in calling yourself an AI expert if you’re genuinely exploring
    and contributing.
  sec: 504
  time: '8:24'
  who: Maria
- line: You mentioned helping people enter AI. How do you do that? Through courses?
  sec: 560
  time: '9:20'
  who: Alexey
- line: Currently, I focus on my work at Siemens, which includes providing training
    and delivering keynotes.
  sec: 568
  time: '9:28'
  who: Maria
- line: One interesting initiative I organized was inspired by a startup working on
    chatbot safety. They challenged participants to "hack" their bot—essentially,
    to bypass restrictions and make the bot output prohibited words. We ran a similar
    challenge at Siemens with 1,500 participants. It was fascinating to see the creativity
    people used, even at 3 a.m., to outsmart the bot!
  sec: 568
  time: '9:28'
  who: Maria
- line: Is this similar to trying to bypass filters in ChatGPT? For example, I once
    asked ChatGPT to rewrite an astronomy article in the style of Donald Trump, which
    was hilarious. Eventually, though, they added filters to prevent that. Would bypassing
    such restrictions be considered hacking?
  sec: 643
  time: '10:43'
  who: Alexey
- line: Yes, it can be even more dangerous. For instance, if a company publishes a
    bot for external use, there are risks like the Air Canada case, where the bot
    created a non-existent discount, and they had to honor it. Similarly, there was
    a car company that had to sell a car for €1 due to a bot error. This is precisely
    what companies aim to prevent. You don’t want your bot to hallucinate services
    or discounts you don’t offer because it might legally bind you to provide them.
  sec: 698
  time: '11:38'
  who: Maria
- line: In theory, you can prompt a model to tell you almost anything, even create
    non-existent discounts or leak confidential information. For example, we once
    hid the name of my cat in a database as a challenge. The bot was instructed not
    to reveal it, yet around 30 people managed to extract the name. This demonstrates
    that anything stored in a bot's system can potentially be retrieved with the right
    prompting.
  sec: 698
  time: '11:38'
  who: Maria
- header: 'AI vulnerabilities: Bypassing bot restrictions'
- line: Can you explain how the name of the cat was hidden and how it was retrieved?
  sec: 790
  time: '13:10'
  who: Alexey
- line: The name was hidden in a knowledge database.
  sec: 800
  time: '13:20'
  who: Maria
- line: Was this part of an application, like a backend system?
  sec: 808
  time: '13:28'
  who: Alexey
- line: Yes, exactly.
  sec: 811
  time: '13:31'
  who: Maria
- line: We had measures in place to prevent the bot from revealing the cat’s name.
    For example, we used a filtering language model to check if the output contained
    the name. Despite this, people found ways to bypass the system. Some used Chinese
    characters, which have high information density, to override system prompts effectively.
    Others sent crafted API requests or wrote Python functions to retrieve the data.
  sec: 814
  time: '13:34'
  who: Maria
- line: The key technique was to overload the bot with irrelevant instructions. Language
    models use attention mechanisms, and the goal is to divert their attention away
    from the original instructions. This can make the bot forget restrictions and
    reveal information. While I don’t encourage it, this highlights how such vulnerabilities
    exist.
  sec: 814
  time: '13:34'
  who: Maria
- line: So, in this setup, a typical prompt might include context and instructions
    like, “If there’s confidential information, do not expose it to the user.” Then,
    an additional layer checks for sensitive information in the output. Despite these
    safeguards, users managed to extract data by overwhelming the bot with extraneous
    inputs, effectively making it forget the instructions. Is that correct?
  sec: 912
  time: '15:12'
  who: Alexey
- line: Exactly. The idea is to distract the bot from its initial instructions. There
    are ways to make these systems safer. For example, you can analyze user queries
    for attempts to extract sensitive data, validate the output for confidential information,
    and use classifiers to flag or filter sensitive content. Multiple layers of security
    are essential to ensure a bot is reliable.
  sec: 975
  time: '16:15'
  who: Maria
- header: Non-LLM classifiers as a more robust solution
- line: Using a non-LLM classifier sounds interesting because it’s harder to manipulate
    compared to a generative model, right?
  sec: 1020
  time: '17:00'
  who: Alexey
- line: Exactly. Non-LLM classifiers can be simpler and less prone to manipulation.
  sec: 1026
  time: '17:06'
  who: Maria
- line: It’s harder to trick such models because they lack the complexity that allows
    for creative exploitation, correct?
  sec: 1032
  time: '17:12'
  who: Alexey
- line: Yes, that’s true. These simpler models are more robust against such tactics.
  sec: 1036
  time: '17:16'
  who: Maria
- line: One of your responsibilities as a Principal Key Expert in Artificial Intelligence
    is advising management on technology and its associated risks. For example, we
    discussed how chatbots can be vulnerable to exploits, leading to unintended outcomes
    like selling a plane ticket for $1. But you mentioned the reputational damage
    caused by these vulnerabilities might be even more critical. Could you elaborate?
  sec: 1040
  time: '17:20'
  who: Alexey
- line: Exactly. The monetary loss from an error like selling a plane ticket for $1
    might be small, but the reputational damage can be severe. It shows the company
    released an unsafe product. Another issue is hallucinations. If a bot behaves
    like an untrustworthy friend who lies, users may lose confidence and stop using
    it. This undermines user adoption.
  sec: 1081
  time: '18:01'
  who: Maria
- line: People without prior experience with machine learning might take a bot's answers
    at face value. For instance, I once asked ChatGPT about mushrooms while mushroom
    picking with my son. It invented names for mushrooms that don’t exist. I could
    tell they were fake because I have some experience, but someone without that background
    might trust it.
  sec: 1156
  time: '19:16'
  who: Alexey
- line: That’s a valid concern. For example, I once tested ChatGPT with a deadly mushroom
    called a death cap, which can kill up to seven people. It suggested recipes for
    cooking it, treating it as edible. This highlights the need for user education
    about the limitations of AI. Some demographics, especially less tech-savvy individuals,
    might blindly trust such outputs, leading to dangerous consequences.
  sec: 1200
  time: '20:00'
  who: Maria
- line: Moreover, chatbots often fail to gain user adoption. Companies invest significant
    resources in developing them, but users may find the responses inaccurate, overly
    verbose, or unhelpful. This creates frustration. For example, many people avoid
    interacting with chatbots when contacting customer support. The lack of trust
    and poor usability can result in low adoption rates, making the investment less
    effective.
  sec: 1200
  time: '20:00'
  who: Maria
- line: I think we see them quite often.
  sec: 1236
  time: '20:36'
  who: Alexey
- line: They look very similar to champignons, which is why people sometimes get poisoned.
    They mistake them for champignons. I tried asking ChatGPT a couple of times, and
    it gave me recipes for cooking them, treating them as edible.
  sec: 1239
  time: '20:39'
  who: Maria
- line: This shows why education is essential. People shouldn't blindly trust AI when
    it tells them something is safe or edible. Some demographics, particularly older
    generations, might find it harder to discern this and could trust AI blindly.
    This poses a problem, especially when using AI in public-facing applications.
  sec: 1239
  time: '20:39'
  who: Maria
- line: Another issue is the risk companies face when they invest heavily in building
    chatbots. If the chatbot frequently gives hallucinated answers, is too verbose,
    or off-topic, users may not adopt it. Nowadays, everyone wants to build a chatbot,
    but very few people want to use them.
  sec: 1239
  time: '20:39'
  who: Maria
- line: 'Take customer service chatbots, for example. Have you ever heard someone
    say they enjoy interacting with a chatbot when calling Vodafone? Users often find
    these systems frustrating. This raises critical questions: if a chatbot provides
    incorrect information, will users trust it? Could it lead to serious consequences,
    like mistaking a death cap mushroom for a champignon? It''s vital to consider
    whether there''s a better way to adopt AI technologies rather than rushing to
    deploy chatbots.'
  sec: 1239
  time: '20:39'
  who: Maria
- header: 'Risks of chatbot deployment: Reputational and financial'
- line: 'There are two major risks: first, reputational damage if the product isn''t
    secure or reliable, and second, the uncertainty around return on investment. Users
    might reject it entirely. Are there other common risk factors?'
  sec: 1376
  time: '22:56'
  who: Alexey
- line: Those are the main risks when building a chatbot, as creating a good one is
    quite expensive. Another issue developers face is getting stuck in endless loops
    of prompt engineering, trying to fine-tune outputs to eliminate errors.
  sec: 1399
  time: '23:19'
  who: Maria
- line: So a third risk is the cost of development time. Developers can get too focused
    on optimizing prompts, which can be risky. For example, if OpenAI releases a new
    model version, previous prompts might not work anymore.
  sec: 1445
  time: '24:05'
  who: Alexey
- line: Exactly. That's another significant risk. You may invest time crafting perfect
    prompts, only for them to fail with a model update. Even within the same model,
    nondeterministic behavior means the same question can yield different answers.
  sec: 1465
  time: '24:25'
  who: Maria
- line: Knowing these risks, what can we do to address hallucinations? Beyond just
    warning users to approach AI responses cautiously, what solutions exist? For instance,
    ChatGPT mentions it's an AI and may make mistakes.
  sec: 1490
  time: '24:50'
  who: Alexey
- line: Yes, that's what it says, but this disclaimer isn't included in business applications.
    For instance, if I contact Vodafone or my bank, I don’t see a message warning
    me that the chatbot could be wrong.
  sec: 1517
  time: '25:17'
  who: Maria
- line: But shouldn't we include such disclaimers everywhere?
  sec: 1530
  time: '25:30'
  who: Alexey
- line: Exactly. For example, if you want to ensure users get accurate information,
    you could integrate human oversight. Instead of having the chatbot send responses
    directly to users, it could forward answers to a human for review. The human approves
    or corrects the response before it reaches the user.
  sec: 1534
  time: '25:34'
  who: Maria
- line: This hybrid approach has proven effective because it saves time while maintaining
    accuracy. It also addresses a common misconception about AI—that it replaces human
    workers. Instead, AI should be viewed as a tool or assistant to enhance existing
    workflows. Many chatbots fail because they try to replace human support instead
    of assisting it.
  sec: 1534
  time: '25:34'
  who: Maria
- header: The role of AI as a tool, not a replacement for human workers
- line: That makes sense. In my previous company, I worked in moderation for an online
    marketplace. Users would list items like a computer mouse for sale, including
    descriptions and photos. However, listings didn’t go live immediately. The system
    checked for potential fraud. For example, if someone listed a suspiciously cheap
    phone, it might not be legitimate.
  sec: 1633
  time: '27:13'
  who: Alexey
- line: We used a model to flag fraudulent listings. Moderators were initially worried
    the system would replace them. This was long before modern AI systems, but we
    had to explain that the tool was there to assist them, not replace them.
  sec: 1633
  time: '27:13'
  who: Alexey
- line: 'One product manager used the autopilot analogy: pilots don''t steer planes
    manually the entire time—they use autopilot and step in when needed. This metaphor
    helped moderators feel more comfortable. I think we need similar messaging today
    to alleviate fears about AI replacing jobs.'
  sec: 1633
  time: '27:13'
  who: Alexey
- line: Exactly. We've seen this narrative play out for decades. In the 1950s, machine
    translation was supposed to eliminate human translators, but look at where we
    are now. Machine translation is a great example of AI as an assistant rather than
    a replacement.
  sec: 1756
  time: '29:16'
  who: Maria
- line: Why aren’t translators in danger, even with advancements like ChatGPT?
  sec: 1789
  time: '29:49'
  who: Alexey
- line: Because technical translation requires precision. It must adhere to company
    standards and use consistent terminology. For example, a button label shouldn't
    be translated differently across documents. Human translators review AI-generated
    translations to ensure accuracy and consistency.
  sec: 1793
  time: '29:53'
  who: Maria
- line: While the cost of translation has decreased, the demand for skilled translators
    hasn’t diminished. Instead, translators can handle more volume. Poor-quality translations,
    such as simple or non-technical texts, might be automated, but critical tasks
    still need human expertise.
  sec: 1793
  time: '29:53'
  who: Maria
- line: For example, in product manuals, a mistranslation could lead to dangerous
    mistakes, like someone sticking their fingers in a socket due to an error. This
    shows that translators remain essential despite AI's advancements.
  sec: 1793
  time: '29:53'
  who: Maria
- header: The role of human translators in the age of AI
- line: When I said you need an editor, I didn’t think about the fact that the person
    actually needs to understand the source language too, not just the target language.
  sec: 1901
  time: '31:41'
  who: Alexey
- line: Exactly.
  sec: 1910
  time: '31:50'
  who: Maria
- line: You also need to ensure that the translation is accurate. How do you approach
    that?
  sec: 1912
  time: '31:52'
  who: Alexey
- line: Human translation has changed significantly. It relies heavily on automated
    tools now, making the process more productive. However, it's not disappearing
    as a profession—unless you’re a bad translator. In that case, yes, you could be
    replaced by GPT.
  sec: 1917
  time: '31:57'
  who: Maria
- line: I stopped using Google Translate. Now I use ChatGPT for translations instead.
  sec: 1941
  time: '32:21'
  who: Alexey
- line: That’s interesting.
  sec: 1947
  time: '32:27'
  who: Maria
- line: With ChatGPT, I can provide specific instructions. For example, I can ask
    it to use the informal plural instead of the formal one. Google Translate doesn’t
    allow for that level of customization, which makes ChatGPT much more practical.
    By the way, you started your career in computational linguistics and machine translation,
    didn’t you?
  sec: 1948
  time: '32:28'
  who: Alexey
- line: Yes, that’s right. I worked a lot on low-resource languages, which remain
    a challenge for large language models. Whenever we begin a use case, I often ask,
    “Do you have data in English?” Why? Because English is a high-resource language,
    and most models are primarily trained on English data.
  sec: 1977
  time: '32:57'
  who: Maria
- line: In my earlier work, I focused on low-resource and historical languages like
    Gothic, Middle Low German, Middle High German, and Middle English. These are very
    different from modern English. For instance, Middle English—like the language
    Chaucer wrote in—sounds much closer to German than the English we speak today.
  sec: 1977
  time: '32:57'
  who: Maria
- line: Shakespeare in the original is still somewhat similar to modern English, but
    Middle English seems much further removed.
  sec: 2034
  time: '33:54'
  who: Alexey
- line: 'Exactly. Middle English is quite distinct. For example, Chaucer’s Canterbury
    Tales begins: “Whan that Aprille with his shoures soote…” It sounds very different
    from modern English, almost like another language.'
  sec: 2038
  time: '33:58'
  who: Maria
- line: Hearing that reminds me of two things. First, it sounds like something out
    of The Lord of the Rings. Second, it feels Scandinavian. English is somewhat Scandinavian,
    right? It’s part of the same family as Scandinavian and Germanic languages.
  sec: 2064
  time: '34:24'
  who: Alexey
- header: Evolution of English and its Germanic roots
- line: That’s correct. English belongs to the vast Germanic language family. Its
    closest relatives are German and Dutch. Historically, English had grammatical
    cases like nominative and accusative, but it gradually dropped them—similar to
    what’s happening with some German dialects today.
  sec: 2089
  time: '34:49'
  who: Maria
- line: And those dialects are simplifying even further, aren’t they?
  sec: 2113
  time: '35:13'
  who: Alexey
- line: Yes, especially in Northern German dialects like Plattdeutsch. Some have even
    dropped grammatical genders.
  sec: 2116
  time: '35:16'
  who: Maria
- line: I don’t think I’ll live long enough to see English evolve further in this
    direction.
  sec: 2129
  time: '35:29'
  who: Alexey
- line: Language change takes time, but it’s fascinating to study. For instance, I’ve
    asked ChatGPT to generate text in Middle English or even Gothic.
  sec: 2144
  time: '35:44'
  who: Maria
- line: About that Middle English quote—how do you even pronounce a language that
    doesn’t exist anymore? There are no recordings, right? How do we know how it sounded?
  sec: 2158
  time: '35:58'
  who: Alexey
- line: We can make educated guesses through comparative linguistics. By comparing
    spellings and sounds in related languages, we infer pronunciations. For instance,
    in Germanic and Latin languages, the letter “a” was often pronounced as “ah.”
    Similarly, in words like “knight,” the “k” was originally pronounced, as seen
    in German Knecht. Spelling reforms—or lack thereof—also give us clues.
  sec: 2184
  time: '36:24'
  who: Maria
- line: That sounds like reconstructing dinosaurs from bones. We don’t have the complete
    picture, so we rely on imagination and comparison.
  sec: 2199
  time: '36:39'
  who: Alexey
- line: Exactly. Linguistic evolution follows logical patterns. For instance, in Middle
    English, “time” was pronounced with a long “e,” like “teem.” Over time, vowel
    shifts occurred, transforming how words are articulated. By studying such patterns,
    linguists deduce historical pronunciations.
  sec: 2211
  time: '36:51'
  who: Maria
- line: What about the epic poem Beowulf? Is it written in Middle English?
  sec: 2318
  time: '38:38'
  who: Alexey
- header: Beowulf and Old English
- line: No, Beowulf is in Old English, which predates Middle English. It’s much harder
    to understand without specialized study. Old English was heavily influenced by
    Norse and later by Norman French during the occupation of England. This significantly
    shaped the development of modern English.
  sec: 2324
  time: '38:44'
  who: Maria
- line: I remember learning that during the Norman occupation, English was mostly
    spoken by peasants, while the elite spoke French. Is that why English grammar
    became simpler?
  sec: 2360
  time: '39:20'
  who: Alexey
- header: Impact of the Norman occupation on English grammar
- line: Yes, exactly. Many Germanic languages were spoken primarily by the lower classes.
    The Protestant Reformation played a significant role in shaping these languages.
    When religious leaders began translating the Bible into vernacular languages,
    it standardized spelling and grammar. For my research, I relied heavily on Biblical
    texts because they were often the only written resources available in low-resource
    languages. They’re also useful for translation studies since they exist in multiple
    languages.
  sec: 2383
  time: '39:43'
  who: Maria
- line: And the Middle English quote you shared earlier—what did it mean? I understood
    the word knight, but not the rest.
  sec: 2459
  time: '40:59'
  who: Alexey
- line: There was a knight who thought about busyness and worthiness. From the time
    he first started reading and writing, he loved chivalry. He valued truth, honor,
    freedom, and courtesy.
  sec: 2466
  time: '41:06'
  who: Maria
- line: When you say it like that, I can see the resemblance. Some words are actually
    very similar. But the first time you said it, I couldn't catch anything. It's
    interesting. We also make transcripts for our podcasts, and I'm curious about
    something.
  sec: 2496
  time: '41:36'
  who: Alexey
- line: I could send you the Middle English text. When you read it, you can understand
    everything—it’s written like English. The difference is mainly in pronunciation.
    It also shows how English hasn't undergone a spelling reform for a long time and
    how that impacts reading it now.
  sec: 2517
  time: '41:57'
  who: Maria
- line: 'There''s a question from Irina: "Did you know the old housemate?" I''m not
    sure what it means, but do you use an AI app to identify mushrooms you pick, Maria?'
  sec: 2540
  time: '42:20'
  who: Alexey
- header: Identifying mushrooms with AI apps and safety precautions
- line: Yes, I used to use a simple classifier before ChatGPT. However, I learned
    you can’t rely on top-one guesses. I would usually look through the top 10 guesses,
    checking if any were poisonous. Then I’d compare them. Honestly, I still wouldn’t
    eat the mushrooms because you only need to be wrong once with something poisonous.
  sec: 2554
  time: '42:34'
  who: Maria
- line: Exactly. I assume all mushrooms are poisonous by default.
  sec: 2597
  time: '43:17'
  who: Alexey
- line: There are some very good ones, but I understand.
  sec: 2603
  time: '43:23'
  who: Maria
- line: For me, since I’m not sure which ones are safe, it’s better to assume they’re
    all poisonous.
  sec: 2606
  time: '43:26'
  who: Alexey
- line: That’s how my husband feels too. He refuses to eat the mushrooms I pick and
    won’t even try them.
  sec: 2616
  time: '43:36'
  who: Maria
- line: Coming back to translations and low-resource languages, we've talked about
    Old English and German. But what about languages where we don’t even have resources,
    like Sumerian? I’ve seen pictures of those texts. They’re written on clay tablets,
    not paper or books. The symbols look like triangles rotated in different directions.
    It’s not like a Bible—it’s just a plate with rows of symbols. How do you even
    begin to understand what’s written there?
  sec: 2626
  time: '43:46'
  who: Alexey
- header: Decoding ancient languages like Sumerian
- line: That was a fascinating project involving Mesopotamian languages, like Sumerian,
    written in cuneiform. This was before large language models existed, and even
    today, they wouldn’t work well for this because we don’t have large datasets for
    these languages.
  sec: 2708
  time: '45:08'
  who: Maria
- line: First, cuneiform experts take photos of the tablets and transcribe them into
    a script using Latin characters. Each symbol gets a phonetic representation. Sometimes,
    these scripts don’t even align with a single language—they can mix styles and
    even languages.
  sec: 2708
  time: '45:08'
  who: Maria
- line: Is it like Chinese, where a character can represent a word? Or like Ancient
    Egyptian hieroglyphs?
  sec: 2769
  time: '46:09'
  who: Alexey
- line: As I recall, it was a mix. Some characters represented words, while others
    added grammatical or contextual information. The linguists working on this know
    more.
  sec: 2785
  time: '46:25'
  who: Maria
- line: Our role was to create a machine translation system to assist them. Since
    there wasn’t enough data for neural machine translation, we used older statistical
    approaches. The goal was to align words from Sumerian to English to identify parts
    of speech, such as nouns or adjectives. It wasn’t perfect, but it helped linguists
    analyze grammatical properties.
  sec: 2785
  time: '46:25'
  who: Maria
- line: Eventually, I left the project to work in the industry, so I’m unsure about
    its current status.
  sec: 2785
  time: '46:25'
  who: Maria
- line: While you were talking, I Googled Sumerian, and I found a table showing how
    each symbol corresponds to a Latin letter. So on these tablets, one symbol equals
    one character, right?
  sec: 2906
  time: '48:26'
  who: Alexey
- line: It’s a mix. Some symbols represent letters, and others represent words or
    concepts. Someone more familiar with Sumerian could clarify, but I know that languages
    like Akkadian borrowed elements from Sumerian.
  sec: 2943
  time: '49:03'
  who: Maria
- header: The evolution of machine translation and multilingual models
- line: You speak German, right?
  sec: 2983
  time: '49:43'
  who: Alexey
- line: Yes, I speak German and English.
  sec: 2985
  time: '49:45'
  who: Maria
- line: When you moved to Germany, did you already speak German?
  sec: 2992
  time: '49:52'
  who: Alexey
- line: Yes, it was part of my linguistics training before I came to Germany. Learning
    German wasn’t too difficult because it’s similar to English. The grammar was intuitive,
    and many words were already familiar.
  sec: 3003
  time: '50:03'
  who: Maria
- line: I remember living in Poland about 12 years ago. Polish is close to Russian,
    so it was relatively easy for me to pick up. Just hearing people and trying to
    understand was enough. But back then, machine translation was terrible because
    it often pivoted through English, resulting in strange translations.
  sec: 3070
  time: '51:10'
  who: Alexey
- header: Challenges with low-resource languages and inconsistent orthography
- line: Exactly. Machine translation relies on parallel texts—sentences translated
    into multiple languages. For languages like Russian and Ukrainian, it’s easier
    to find parallel texts because they were widely used together.
  sec: 3181
  time: '53:01'
  who: Maria
- line: For low-resource languages, it’s much harder. Modern approaches use multilingual
    models trained on many languages together. These models can generalize to new
    language pairs, even if the pair wasn’t explicitly trained.
  sec: 3181
  time: '53:01'
  who: Maria
- line: In the past, translations would pivot through English. For instance, translating
    Polish to Chinese might have gone Polish → English → Chinese. Multilingual models
    reduce the need for this pivoting, but challenges remain, especially with languages
    lacking digital resources or standardized spelling.
  sec: 3181
  time: '53:01'
  who: Maria
- line: I imagine older languages, like Middle Low German, had even more challenges
    because of inconsistent spelling.
  sec: 3406
  time: '56:46'
  who: Alexey
- line: Exactly. In the past, every village might have had its own spelling. There
    were no standardized grammar rules or punctuation until the 19th century. This
    made machine translation even harder.
  sec: 3412
  time: '56:52'
  who: Maria
- line: 'Irina has another question that might take a while: What was the biggest
    challenge in leaving academia and moving to a major company in Germany?'
  sec: 3439
  time: '57:19'
  who: Alexey
- header: Transition from academia to industry in AI
- line: The biggest challenge was understanding that the most innovative, state-of-the-art
    approach isn’t always what industry needs. Companies often prioritize fast, practical
    solutions over perfection.
  sec: 3448
  time: '57:28'
  who: Maria
- line: You need to consider factors like return on investment and operational efficiency.
    Research focuses on pushing boundaries, while applied AI is about creating something
    usable. It took time to adjust, but I think I’ve adapted well.
  sec: 3448
  time: '57:28'
  who: Maria
- line: Thank you, Maria! And thanks to Irina for joining us. She’s been a guest before
    and will return soon for a webinar. Maria, it was a pleasure having you here today.
    Thank you for sharing your insights and stories.
  sec: 3554
  time: '59:14'
  who: Alexey
- line: Thank you for inviting me. It was a great experience.
  sec: 3590
  time: '59:50'
  who: Maria
- line: Have a great day, everyone, and thanks again!
  sec: 3593
  time: '59:53'
  who: Alexey
---