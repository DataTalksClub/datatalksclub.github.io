---
title: 'Practical Skills for Data Professionals in SaaS: Bridging the Gap between Data and Business'
short: Practical Skills for Data Professionals in SaaS
season: 12
episode: 2
guests:
- lorismarini
image: images/podcast/data-professionals-business-skills-in-saas.jpg
ids:
  anchor: Business-Skills-for-Data-Professionals---Loris-Marini-e1s89hu
  youtube: xMYRUiTu960
links:
  anchor: https://anchor.fm/datatalksclub/episodes/Business-Skills-for-Data-Professionals---Loris-Marini-e1s89hu
  apple: https://podcasts.apple.com/us/podcast/business-skills-for-data-professionals-loris-marini/id1541710331?i=1000590422440
  spotify: https://open.spotify.com/episode/5tw3qs1XHETDPYrxdEaVbK?si=QIclWOT_QhKhIGrcl-KQXg
  youtube: https://www.youtube.com/watch?v=xMYRUiTu960

description: 'Discover practical data science for SaaS: deploy ML, build marketing automation, define metrics and reduce churn—stakeholder tactics, tooling, and storytelling insights.'
intro: 'How do you move data science from experiments to measurable impact in a SaaS business? In this episode, Loris Marini — CEO and founder of Discovering Data and host of the Discovering Data podcast — walks through practical approaches to deploying models, building marketing automation, and turning metrics into persuasive stories. <br><br> Loris covers production challenges for model deployment in SaaS, a marketing automation use case (recommendations and reporting), and how applied research like reinforcement learning maps to real problems. We dig into semantic alignment — defining "customer" and core metrics — plus lead indicators, stickiness, churn, and causal thinking for product metrics. Loris also shares tactics for onboarding stakeholders: stakeholder mapping, CRM-style context capture, meeting immersion, and Notion-based note systems. He emphasizes pragmatic tools (Excel, pivots), prioritizing high-connectivity opportunities, and a conversation-first diagnostic before ML. Finally, learn data storytelling techniques, building trust through active listening and business literacy, and where to find further resources and community. <br><br> Listen to gain concrete strategies for model deployment, marketing automation, measurement, and communicating data-driven outcomes in SaaS.'
dateadded: 2022-12-17

duration: PT01H15S

quotableClips:
- name: Podcast Introduction
  startOffset: 0
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=0
  endOffset: 102
- name: 'Guest Background: From Physics to Data Science'
  startOffset: 102
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=102
  endOffset: 165
- name: 'Early Data Role: Research Skills Applied in a Startup'
  startOffset: 165
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=165
  endOffset: 291
- name: 'Production Challenges: Deploying Models in a SaaS'
  startOffset: 291
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=291
  endOffset: 378
- name: 'Marketing Automation Use Case: Recommendations & Reporting'
  startOffset: 378
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=378
  endOffset: 510
- name: 'Applied Research: Reinforcement Learning to Practical Problems'
  startOffset: 510
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=510
  endOffset: 739
- name: 'Semantic Alignment: Defining "Customer" and Core Metrics'
  startOffset: 739
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=739
  endOffset: 946
- name: 'Lead Indicators & Stickiness: Churn and Causal Thinking'
  startOffset: 946
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=946
  endOffset: 1080
- name: 'Context & Semantics: Cross-Functional Meaning in Data'
  startOffset: 1080
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=1080
  endOffset: 1306
- name: 'Data Storytelling: Marketing Techniques for Memorable Communication'
  startOffset: 1306
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=1306
  endOffset: 1553
- name: 'Building Trust: Active Listening and Business Literacy'
  startOffset: 1553
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=1553
  endOffset: 1675
- name: 'Onboarding Strategy: Stakeholder Mapping and Prioritization'
  startOffset: 1675
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=1675
  endOffset: 2120
- name: 'Stakeholder CRM: Capturing Names, Roles, and Context'
  startOffset: 2120
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=2120
  endOffset: 2271
- name: 'Meeting Immersion: Learning Business Language by Attendance'
  startOffset: 2271
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=2271
  endOffset: 2493
- name: 'Note Systems: Using Notion to Track Meetings and Key Activities'
  startOffset: 2493
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=2493
  endOffset: 2622
- name: 'Tooling & IP Considerations: Personal Knowledge vs Company Systems'
  startOffset: 2622
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=2622
  endOffset: 2713
- name: 'Prioritization: Choosing Projects by Stakeholder Impact'
  startOffset: 2713
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=2713
  endOffset: 2830
- name: 'Opportunity Selection: Finding High-Connectivity Data Projects'
  startOffset: 2830
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=2830
  endOffset: 3061
- name: 'Pragmatism in Tools: Excel, Pivot Tables, and Rapid Experiments'
  startOffset: 3061
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=3061
  endOffset: 3188
- name: 'Conversation First: Description and Diagnostic Before ML'
  startOffset: 3188
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=3188
  endOffset: 3373
- name: 'Presenting Online: Podcasting, Pauses, and Audio Practices'
  startOffset: 3373
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=3373
  endOffset: 3515
- name: 'Resources: Discovering Data Podcast for Business Skills'
  startOffset: 3515
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=3515
  endOffset: 3633
- name: 'Community Building: Joining the Discovering Data Discord'
  startOffset: 3633
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=3633
  endOffset: 3683
- name: Episode Wrap-Up and Contact Links
  startOffset: 3683
  url: https://www.youtube.com/watch?v=xMYRUiTu960&t=3683
  endOffset: 3615

transcript:
- header: Podcast Introduction
- header: 'Guest Background: From Physics to Data Science'
- line: This week we'll talk about business skills for data professionals. We have
    a special guest today, Loris. Loris is the CEO and founder of Discovering Data,
    where he's on a mission to build a bridge between business leaders and data leaders.
    Loris hosts the Discovering Data Podcast, a show for business leaders and data
    professionals who want to turn data into outcomes. Welcome Loris!
  sec: 102
  time: '1:42'
  who: Alexey
- line: Yeah, absolutely. Thank you. Thank you for having me here. It's crazy to be
    on the other side. I watched the show recently as a listener and every time you're
    invited, there's this weird Inception thing, where you don't know what's actually
    happening. It's super keen to be here, so thank you.
  sec: 127
  time: '2:07'
  who: Loris
- line: Yeah, it's always an interesting experience to be on the other side – not
    to host but to be a guest. Before we go into our main topic of building skills
    for data professionals, let's start with your background. Can you tell us about
    your career journey so far?
  sec: 146
  time: '2:26'
  who: Alexey
- header: 'Early Data Role: Research Skills Applied in a Startup'
- line: Yeah, sure. In a way, it’s very typical for data people. I started out with
    a background in engineering and then I got passionate about physics. I thought
    for a moment I would one day become a researcher – a professor in quantum physics
    – then I got to understand how academia works and I realized that wasn't quite
    what I wanted.
  sec: 165
  time: '2:45'
  who: Loris
- line: The first job that I landed after my PhD in quantum physics was data science,
    which aligned really well with a lot of the work that I've done in engineering
    as well. My background is Information Engineering, so it's a lot about entropy,
    mutual information, statistics – a lot of statistics – and data science, as we
    know, is founded, really, on statistics. I managed to convince someone that I
    could have done the job and they hired me. That was the first data hire in that
    company – a startup in marketing. So – very scary.
  sec: 165
  time: '2:45'
  who: Loris
- line: That’s amazing. Somebody without experience as a first hire in data science,
    that's a success, right? [chuckles]
  sec: 233
  time: '3:53'
  who: Alexey
- line: Exactly. Typical 2018, right? That was the thing at the time. If you didn't
    have a data scientist, you were behind – that was the business perception. So
    the chief executive said, “Okay, we need to hire a data scientist,” and started
    asking around to everybody, “Do you know a good data scientist?” And a friend
    of mine said, “Well, I know someone that is pretty smart.” I had that classic
    conversation, sitting at a table across from the other side was the Chief Technical
    and Chief Executive and they were like, “Okay, so we have a bold strategy and
    lots and lots of complex business questions to answer. Now you’re clearly smart.
    You’ve done a PhD in physics, so you work it out. This is your desk. He's your
    MacBook Pro. I'll see you in the stand-up tomorrow.”
  sec: 241
  time: '4:01'
  who: Loris
- line: That's the entire interview process? Or did they actually ask something?
  sec: 287
  time: '4:47'
  who: Alexey
- header: 'Production Challenges: Deploying Models in a SaaS'
- line: That was my day one. The interview was actually very interesting. We can talk
    about the interview, but day one was that. On day two, the CTO looked at me from
    across the room during stand-up and asked me, “Okay, so when is the project going
    to get done?” [chuckles] And I'm like, “Okay… things are fast here.” So that was
    a bit of a shock coming from academia. But that's where I learned the ropes and
    ended up doing a lot of data management and data engineering, just to get the
    data that I needed [chuckles] and just to avoid using Excel.
  sec: 291
  time: '4:51'
  who: Loris
- line: At the time, there was a very compelling business need – they wanted to create
    some models and integrate them into the app. So it was exciting. I couldn't believe
    it. I was like, “Wow, we get to see the whole workflow from the source data all
    the way to the application of the user and get some feedback and iterate.” It
    took us nine months to deploy the first model into production at the time, which
    for me was forever. Then I learned how hard it was for data scientists to put
    anything into production at that time. So I felt, “Well, maybe I was actually
    lucky. Maybe it was actually an achievement to manage to deploy a model in real
    life.”
  sec: 291
  time: '4:51'
  who: Loris
- line: What was the app actually doing and what was the model?
  sec: 374
  time: '6:14'
  who: Alexey
- header: 'Marketing Automation Use Case: Recommendations & Reporting'
- line: Oh, the app was just recommending. Autopilot is a SaaS business. Now they
    are rebranded, so you wouldn't find it on LinkedIn. But what they were doing was
    marketing automation. You could create journeys, and tag people, and make the
    whole workflow for someone in marketing a lot easier and more intuitive. The platform
    was incredibly flexible. We had this drag-and-drop functionality with blocks.
    There were actions and triggers sort of similar to ConvertKit, for those that
    have an experience with that software, but way more powerful. You could do literally
    everything, and it would natively integrate with everything else. [chuckles]
  sec: 378
  time: '6:18'
  who: Loris
- line: They had a lot of engineers. I think more than 30% of the engineering team
    was focused on integration. The product was really, really cool. My job was to
    make the dashboard and the reporting way more actionable. Because the problem
    was information overwhelm – you will log in, and you will find logs, real-time
    information on what was happening across all your campaigns and across all your
    contexts and leads. But it was very hard to focus the attention on “Okay, here's
    what you can do right now to improve the campaigns.”
  sec: 378
  time: '6:18'
  who: Loris
- line: It was analytics – it was reporting and sort of basic descriptive work, and
    there was also some diagnostic work on top. The idea then was to leverage the
    human intellect to cover the last part, which was prediction and prescription.
    So a bit of anomaly detection stuff – very simple from an algorithmic standpoint,
    but very convoluted from an architectural standpoint. [chuckles]
  sec: 378
  time: '6:18'
  who: Loris
- line: Interesting. Your background was engineering and physics, yet the work (the
    job, the app that you worked on) was in marketing. This is like two different
    worlds. How did you actually convince them to hire you? Was it enough to say,
    “Hey, I know physics. I'm smart.”?
  sec: 491
  time: '8:11'
  who: Alexey
- header: 'Applied Research: Reinforcement Learning to Practical Problems'
- line: '[cross-talk] Well, they were a tech startup, right? So very technical people.
    It was very easy to convince them, to be honest. It was one of the easiest interview
    processes. We started talking and I described some of the projects that I worked
    on. In academia, in the context of university, I’ve actually done some really
    interesting work that never saw the light of the wider community it was stuck
    in – published a paper, it ended up on the IEEE, and that was it. But if you unpack
    that, that was a work on reinforcement learning.'
  sec: 510
  time: '8:30'
  who: Loris
- line: I was looking at non-polynomial hard problems for those in the audience that
    love mathematics, which I think are most of them. I used reinforcement learning
    to create basically a game where a bunch of actors would take actions, and their
    actions would compete and cause other actors to feel the effects of these actions
    until the network eventually converges to a non-optimal, but very close to optimal
    solution in like record time – in like 30 or 40 iterations, compared to being
    an intractable problem, if you want to approach it exhaustively. So that was cool.
    And then I just happened to meet this person. I wanted to build a laser lab in
    quantum physics. I switched from whatever I was doing when I saw lasers – a shiny
    thing – I couldn’t resist. [chuckles] Like, “Let's do it.” [laughs]
  sec: 510
  time: '8:30'
  who: Loris
- line: So previously, in academia, your work was published in papers on IEEE and
    after we published, the work was done, but then you joined a company, which was
    a completely different domain – marketing. And to deploy something, it took nine
    months, which was very unusual for you. Right?
  sec: 605
  time: '10:05'
  who: Alexey
- line: Yeah. I was expecting less. The basics of the model were ready to be tested
    on a larger sample than what I had available and were ready to do some basic A/B
    testing after a month from when I started. Because I had that good friend of mine
    in engineering, I said, [chuckles] “Hey, I need some data. Beer’s on me, launch
    is on me – help me out.” And so he did. He did help me out and gave me a dataset
    and I built the initial models off of that. The actual integration to live, that
    was a beautiful exercise of learning how DevOps works, and how the world of software
    development works, which is very different from statistics and data science, as
    we know.
  sec: 623
  time: '10:23'
  who: Loris
- line: So that was exposure end-to-end – from the user needs to the engineer that
    needs to deploy a server in AWS to make that thing happen. Then eventually, that
    engineer was too busy, so I took over that part. I became very quickly more of
    a data engineer than a data scientist. Luckily, I knew the basics of coding, so
    I managed to survive. Eventually, we published that stuff into production, which
    was great. And then I started developing this passion around, aligning people
    on concepts and trying to really understand what they're trying to achieve and
    map those requirements into data requirements. I found that part extremely refreshing
    and energizing, so I focused on that. That was a lot of fun. [cross-talk]
  sec: 623
  time: '10:23'
  who: Loris
- line: What do you actually mean by “aligning people on concepts”? This entire thing
    – maybe we can unpack it a little bit.
  sec: 731
  time: '12:11'
  who: Alexey
- header: 'Semantic Alignment: Defining "Customer" and Core Metrics'
- line: Yeah, sure. It's also one of the points in our outline for the talk today.
    “Data that makes sense – context, semantics, and meaning.” I guess I found the
    first hints that this was a problem when we're having a conversation after a hackathon.
    We did a hackathon one day – it was fun, everybody was free to spend one day solving
    a business problem they were in love with. I found myself contributing to a customer
    success problem. We did that and at the end of the day, we were drinking beers
    [chuckles] and this friend of mine said something that completely shocked me.
    I remember, essentially, freezing and staring at her in the eyes. I couldn't believe
    what I heard. I was like, “Is this what you mean? Or is that what you mean?”
  sec: 739
  time: '12:19'
  who: Loris
- line: I realized that in that moment, we had two completely different understandings
    of what we did for eight hours together. She built a picture in her head that
    was different from mine and they were both very valid pictures – just not the
    same picture. [chuckles] And I thought, “Oh, okay. Interesting. How many ways
    can we have different views of the world, even if we use the same words – the
    concepts that we associate with those words can be different if our backgrounds
    and our priorities are different.” She was in customer success, while I was more
    in data science and data engineering. [cross-talk]
  sec: 739
  time: '12:19'
  who: Loris
- line: Customer success is like customer support? What is customer success?
  sec: 837
  time: '13:57'
  who: Alexey
- line: No. The customer success department was more focused on some of the 5% of
    customers by revenue and try to get them to grow even more.
  sec: 844
  time: '14:04'
  who: Loris
- line: Account management, right?
  sec: 855
  time: '14:15'
  who: Alexey
- line: Yeah, but more focused on adoption and proficiency of the product. Because
    even the big ones were actually not using the product – just scratching the surface
    of what the functionality was that we had available to them.
  sec: 857
  time: '14:17'
  who: Loris
- line: My work there was to analyze the usage of the product. I was scanning the
    metadata (the logs) that came from the Elasticsearch background that we had and
    tried to describe the usage. Before I could even describe usage, I had to describe
    what “good usage” meant. So we ended up doing the session and whiteboarding “What
    is success for the product? What are the key metrics? Is it the number of elements
    they use? Is it the complexity of the graph that they build? Is it the number
    of tags or advanced features? Is the ability to export that information with other
    things (integration and ecosystem building)?”
  sec: 857
  time: '14:17'
  who: Loris
- line: That potentially could have been a lead indicator for stickiness. You could
    then argue that if people use the product and it's embedded (they use a lot of
    integrations) then they're less likely to churn, because it's part of the ecosystem.
    It’s going to cost them time and energy to kill it. So that will tie in with the
    lifetime value of the customer and all the business metrics that the business
    was following. So context, the semantics and meaning – yeah.
  sec: 857
  time: '14:17'
  who: Loris
- header: 'Lead Indicators & Stickiness: Churn and Causal Thinking'
- line: '[chuckles] You said something that is quite interesting and I wanted to ask
    you about that. You said that “It''s a lead indicator of stickiness.” So what
    is a “lead indicator”? And what is “stickiness”?'
  sec: 946
  time: '15:46'
  who: Alexey
- line: Yeah, good point. [chuckles] Stickiness is not the stuff you find on scotch
    tape – it's more, in the context of a SaaS, it’s the probability of churning,
    which essentially means canceling the account and picking a competitor.
  sec: 958
  time: '15:58'
  who: Loris
- line: So just like the opposite of churning? Right?
  sec: 976
  time: '16:16'
  who: Alexey
- line: The opposite of churning, yeah. If you have high stickiness, people tend to
    keep using the product. [chuckles] And so their lifetime value increases.
  sec: 979
  time: '16:19'
  who: Loris
- line: And “lead indicator” is some actions or some numbers (a figure) that tells
    you that they're about to leave or they are more likely to continue using the
    product, right?
  sec: 990
  time: '16:30'
  who: Alexey
- line: Yeah, that's right. I don't know how many people in the audience have ever
    seen a causal graph, but you can think about causality and a causal graph like
    a connection of nodes with arrows. The arrows typically go only one way. Could
    be that way [points in one direction], or this way [points in another direction],
    but one way only. And the causal graph tells you, “Okay, if this happens, then
    this happens and then that happens”. It's about establishing a direction on that
    arrow.
  sec: 1002
  time: '16:42'
  who: Loris
- line: A lead indicator is an event or some conditions that are very likely to lead
    to a transition to the next stage. In that case it was churn, but it could be
    anything else. For example, in my relationship with my wife, I know that my ability
    to keep a strong separation between my professional work and my home work is a
    lead indicator of how well we go along together [laughs] and how strong and healthy
    our marriage is. I hope that answers that.
  sec: 1002
  time: '16:42'
  who: Loris
- line: '[chuckle] Yeah, it does. I interrupted you, sorry. You were going to say
    something about context, semantics, and meaning, I guess.'
  sec: 1070
  time: '17:50'
  who: Alexey
- header: 'Context & Semantics: Cross-Functional Meaning in Data'
- line: Yeah. I learned over time that this applies a lot more with cross-functional
    teams and larger organizations than it does in startups. The fundamental mechanics
    of it are just cognitive biases and just the cognitive structure – the way that
    we process information as humans – which is something that always fascinated me.
    I never had the opportunity to dive deeper into the topic.
  sec: 1080
  time: '18:00'
  who: Loris
- line: We see a lot of the data information knowledge wisdom pyramid, which is one
    way of understanding the different levels in data. But I recently learned to extend
    that pyramid, in two interviews in particular – one with Jessica Talisman, on
    my podcast (the podcast title is True Data Mesh, semantics, ontologies and then
    a true data mesh) and the other one with Ron Itelman. Ron has done a lot of work
    at the intersection of machines and humans, so he loves that machine-human interface.
    And it's just that multidisciplinary sort of stuff that really gets me out of
    bed in the morning – studying cognition, psychology, and how we make sense of
    the world, essentially. And it's so messy, because everybody has a different way
    of processing information and building pictures of what reality is.
  sec: 1080
  time: '18:00'
  who: Loris
- line: So how do you align people on the same understanding – on the same thing?
    Very practically, an example is – the definition of customer. It's the most used
    in the data management space. You ask someone in sales and have one conceptual
    understanding of what a customer is, then you ask marketing and they have a different
    one. The problem is that these different understandings then reflect in the data
    and how people use the data to do what they do.
  sec: 1080
  time: '18:00'
  who: Loris
- line: As data scientists and data analysts, if we want to support the business,
    to achieve the targets that are set up as part of the strategy, we need to understand
    that different people might have different understandings of what we see as one
    metric – customer, how hard can it possibly be? There’s one example with Scott
    Taylor, where he tells me the story of the hospital with 170 definitions of what
    a patient is. It's like, “How can you possibly have 170 definitions of what a
    patient is?”
  sec: 1080
  time: '18:00'
  who: Loris
- line: How did they even count this?
  sec: 1241
  time: '20:41'
  who: Alexey
- line: At some points, things got broken, someone suffered – potentially physical
    suffering, not just psychological suffering – and they must have gotten to a stage
    where they engaged with an external firm to do some audits, and they looked into
    the databases and accounts. They counted 170 definitions. It doesn't surprise
    me. So how do we use data to actually have an impact on the organization when
    we know that our cognition – the very system we use to make sense of the world
    – is so unpredictable, and so random, and so different? [chuckles] That fascinates
    me.
  sec: 1243
  time: '20:43'
  who: Loris
- line: I guess another good example would be the definitional of churn, right? You
    can define churn or “stickiness” in so many ways. Everything you do, when you
    need to analyze data on churn, depends on this definition. If you use a different
    definition, then your analysis will be different.
  sec: 1283
  time: '21:23'
  who: Alexey
- header: 'Data Storytelling: Marketing Techniques for Memorable Communication'
- line: Yeah. In this one – I think this could actually be a fantastic introduction
    to the next point that we have in our outline. There’s this one point that I wrote
    around communicating – building better models by building relationships and earning
    trust, which connects really, really well with communication and storytelling.
    It's something that (I'm really curious to hear from the audience about this)
    I didn't even conceive of at the beginning of my career. For me, marketing was
    sort of the enemy. [cross-talk]
  sec: 1306
  time: '21:46'
  who: Loris
- line: Coming from physics, right? And reinforced learning.
  sec: 1353
  time: '22:33'
  who: Alexey
- line: Yeah! From physics, man. This is like science and hard facts and numbers.
    Everything has a standard deviation, everything has a mean – everything has a
    model that can describe it. And if you don't have a model, I can sample it and
    I can estimate the model. This theory and the books were written many decades
    ago. To me, that was solid, verifiable, reproducible thinking. With marketing,
    I always saw it as magic. I also associated persuasion as something very bad.
    You don't want to be the one that persuades people, because it sounds like you’re
    manipulating them. It sounds like you’re getting in their heads, right? [Alexey
    agrees]
  sec: 1357
  time: '22:37'
  who: Loris
- line: You want to stick to the facts. You want to show them the numbers. And I changed
    my mind. I changed my mind big time on that topic. In fact, I think as data professionals,
    we don't do that nearly enough. If you think about it, we're competing for the
    same amount of funding. There's only so much money that the organization has to
    invest in projects and we're competing against each other – the sales folks, the
    marketing folks, they know how to tell a story. They know how to be memorable.
    They leverage the way that our brain works, the way that we process information
    – not necessarily to lead the organization in the wrong way – just to have that
    edge. Just to be remembered, really.
  sec: 1357
  time: '22:37'
  who: Loris
- line: In data, we just blather a lot about databases and models and we forget that
    we're talking to people that don't know what we're talking about. They really
    don't. They really don't know what you're talking about [chuckles] with some exceptions.
    I mean, think about data maturity scales – zero to five – zero being all paper,
    where we barely use a laptop and 0.5 being the majority of organizations. Maybe
    I'm being too harsh. I think Doug Laney put it around 2 being like 45% of the
    organizations that they use for statistics, back when he was a gardener – between
    two and three in the data maturity space.
  sec: 1357
  time: '22:37'
  who: Loris
- line: I think two is when you do have digital systems, but you don't really have
    a strategy. You don't really use data. You talk about data, but the data is in
    excel (in a spreadsheet) there has no heading, no metadata in the title is “_v1”
    or “_final_final”. That's kind of level 2. So it's still pretty bad. [laughs]
    Level 3 is when you start having a bit of a function – you have a data team, maybe
    an analyst or two. And level 4 is when you start doing more predictive, and 5
    is the prescriptive, but it's really embedded within the strategy of the organization.
    Most organizations don't really do that sort of stuff and they don't have that
    data literacy that’s high enough so that the business can understand what the
    heck we’re talking about.
  sec: 1357
  time: '22:37'
  who: Loris
- line: How can we make business understand what we're talking about? What can we
    learn from marketing to actually do that?
  sec: 1543
  time: '25:43'
  who: Alexey
- header: 'Building Trust: Active Listening and Business Literacy'
- line: Yes. For me, this has been the focus for the last year, to be honest, and
    it's gonna keep continuing being the focus in the next two or three years. I think
    the key is to unlearn some of the concepts and the beliefs that we built up over
    time, especially for those that have resonated with the story that I shared and
    the way that I felt about marketing, and learn to see it in a different light
    – as a tool.
  sec: 1553
  time: '25:53'
  who: Loris
- line: Like any tool, we know that if we want to do classification, we can hop on
    SciKit Learn and we have a whole plethora of systems that allow us to do classification.
    Just in the same way, if we want to have any impact in the organization, we need
    to use those tools. A tool is a tool, right? It's not bad, it's not evil, it’s
    not good by itself – it’s just a tool. It's how we use it that gives that tool
    the objective. Is it good? Is it bad? Are you doing it ethically? Are you doing
    it the wrong way? But we can’t just say, “Hey, because there are examples of people
    that are manipulating other people with marketing slogans, then I want to be a
    purist. I'm gonna just step back, walk away, won't even get my hands dirty.”
  sec: 1553
  time: '25:53'
  who: Loris
- line: I think that was the mindset that I had to overcome and learn how to be like
    them, but while retaining my intentions. My intentions as a data professional
    are to have any impact, to be honest. I hate the idea of working on things and
    just having zero adoption. That is my biggest nightmare when I do any data work.
    It just doesn't feel good for me.
  sec: 1553
  time: '25:53'
  who: Loris
- line: How does somebody coming from a physics background – from a mathematical background
    – work on marketing? How do you unlearn these things? How do you start building
    trust with business people?
  sec: 1656
  time: '27:36'
  who: Alexey
- header: 'Onboarding Strategy: Stakeholder Mapping and Prioritization'
- line: Yeah, it's a fantastic question. I think it starts with active listening.
    But before you can listen, you have to learn to be comfortable with not knowing
    what the hell people are talking about. And it's incredibly frustrating. I have
    fresh memories, because I just started a new position two months ago. I'm what's
    called now an Industrial Engineer, but essentially, I'm an analyst. I'm trying
    to help the business reduce costs, increase margins, and reduce waste, which is
    what data people do. That’s what any business wants to do – one of those things,
    if not all of them at the same time.
  sec: 1675
  time: '27:55'
  who: Loris
- line: There's so much domain knowledge when you join a new company, that it's overwhelming.
    We also live in a moment of volatility, so I'm sure that a lot of the listeners
    have fresh memories as well, of what it’s like to start a new job in a new organization.
    And it's awful. We do it because we have to do it and we can't wait to go past
    that first steepest part of the learning curve, so that we become comfortable
    – we know where we are in the organization, we know who our stakeholders are.
    Stakeholder mapping is one of the first things you do in any new position. That
    gives us reference points, we build a kind of map of what we're doing, why we're
    doing it, who the people that we need to please are, who we need to be careful
    of, etc. It's basic survival, if you think about it.
  sec: 1675
  time: '27:55'
  who: Loris
- line: As a data professional, if you want to really have an impact, you have to
    get close to the business – “the business” meaning anyone in the organization
    that is trying to achieve something tangible and they're struggling to do it,
    or they have difficulties and they need help. So first, you need to know who they
    are, what the problems are, whether the problems are worth your time. So there's
    a whole prioritization of projects you can work on, because you’re only one person.
    As an individual contributor, at least – if you're leading a team it’s different,
    but the same principles apply. You still have to prioritize. That requires business
    literacy. That requires mumbo jumbo [chuckles] going to meetings where people
    talk about stuff that, to be honest, we’re not ready for. Most data professionals
    don't come from a business school – they don't have an MBA, they've studied technical
    stuff. The engineers… [cross-talk]
  sec: 1675
  time: '27:55'
  who: Loris
- line: I don’t know anyone who actually has an MBA, at least those from the data
    world. [chuckles]
  sec: 1844
  time: '30:44'
  who: Alexey
- line: Yeah. Because we don't need it, right? To get hired, you need to demonstrate
    that you have a prolific GitHub account and that you are active on Kaggle. You
    don't need to demonstrate business knowledge. But to have an impact – after you're
    hired – you need to know how a business operates. You need to know to speak that
    language.
  sec: 1849
  time: '30:49'
  who: Loris
- line: I think I wasn't completely correct when saying I don't know anyone. It occurred
    to me that I do. But usually, the people who studied MBA, studied business – they
    don't start as junior data scientists. They start as head of product or head of
    data, right?
  sec: 1869
  time: '31:09'
  who: Alexey
- line: Well [chuckles] I hope not. A head of data and data lead are typically really
    technical positions. I mean, it depends.
  sec: 1893
  time: '31:33'
  who: Loris
- line: I mean, if you start with the head of product, this is a good place to… well,
    maybe a product manager and then you become head of product. Then you get into
    data because you've worked with analysts. So eventually, you might become head
    of data. In many organizations, actually, the head of data or director of data
    reports to the product function – to the CPO or whoever – which is fine, I guess.
    But most of us, we studied engineering, we studied computer science, economics
    and not business development.
  sec: 1899
  time: '31:39'
  who: Alexey
- line: Yeah, absolutely. When we see that the business talks about targets on specific
    values that they need to increase – they talk about penetration, they talk about
    differentiation and humanization of the product. They talk about education that
    they are actively doing to turn customers (leads) that are not even aware that
    they have a problem and walk them through the five stages – from unaware to super
    fan. They talk about the cost of acquisition for marketing. They talk about conversion
    rates for a campaign. Every domain within the business has a language that is
    different from the other.
  sec: 1940
  time: '32:20'
  who: Loris
- line: And if you change industries, the language keeps changing. Plus, in addition
    to all of that, there is the lingo that is actually spoken by the people on the
    job, which may be filled with acronyms and inside jokes and the whole thing. So
    you kind of have to become one of them if you want to win their trust and make
    them understand that you are there to try and help, that you, by no means, have
    all the answers. Because these people may have been there for like 5, 7, 10 –
    in the case of the company that I’m in – 20, 25 years. I have four key stakeholders
    and the average time that they have been employed in the same organization is
    20 years. So I walk in as the data person, and I'm like, “I have zero domain knowledge.
    I need to learn from you and demonstrate that I'm genuinely curious. I actually
    want to learn what it's like to be you at work. What keeps you busy? What worries
    you? What are your aspirations? What do you want to achieve? Personally, as a
    team, and for the business.” Hopefully those three are aligned, [chuckles] but
    in some cases, they're not.
  sec: 1940
  time: '32:20'
  who: Loris
- line: And only when you have that kind of welcome, then you see that people open
    up and they come to you with ideas. So you don't have to chase for case studies,
    you don't have to do the research – the research is done by establishing those
    relationships first. I think those are the foundations of successful data professionals
    and don't see a lot of that.
  sec: 1940
  time: '32:20'
  who: Loris
- line: How do you actually do this? So you join a new company. Then you said that
    one of the first things is stakeholder mapping – for each stakeholder, you try
    to understand what they do and why they do this. You also want to prioritize and
    understand who is more important – like you said, who you need to please and who
    you need to stay away from. So how do you do this? How does it work?
  sec: 2088
  time: '34:48'
  who: Alexey
- header: 'Stakeholder CRM: Capturing Names, Roles, and Context'
- line: Okay. You have to know one thing about me and that's – I have a terrible memory.
    [chuckles] For a long time, one of the biggest challenges I had when it comes
    to knowing people – it's remembering their names. I'm incredibly bad with names
    to a point that is almost ridiculous. How can you build relationships? [Alexey
    concurs] Yes! Sometimes it’s like I have to avoid people, because they recognize
    me – they call me by name, and I, for the love of God, I don’t remember their
    name. It feels so bad, so I kind of tried to avoid it. [Alexey concurs]
  sec: 2120
  time: '35:20'
  who: Loris
- line: I've been stuck in that for years. Trust me. So one day, I learned about Notion.
    Now there are many systems, but Notion was one of the first, and when I learned
    it was the only one. I was like, “Oh, maybe I can build a system where every time
    I meet someone, I can Google them (everybody has LinkedIn) get a copy of their
    photo, attach it to the system and build a database with people.” I started out,
    actually.
  sec: 2120
  time: '35:20'
  who: Loris
- line: Like a CRM, right? But for colleagues.
  sec: 2189
  time: '36:29'
  who: Alexey
- line: For colleagues, yes.
  sec: 2193
  time: '36:33'
  who: Loris
- line: That sounds very creepy. [laughs]
  sec: 2194
  time: '36:34'
  who: Alexey
- line: I know, I know. I know it's creepy and it sounds really, really bad. But it
    helped me enormously. [chuckles] So if you ask tactically, practically, “How do
    I solve the biggest barrier to building relationships?” It’s remembering people's
    names, what they do, what they care about. I obviously don't take notes when I
    meet someone over coffee, like, “Okay, let me take notes about you.” No. we're
    humans – normal relationships.
  sec: 2196
  time: '36:36'
  who: Loris
- line: But as soon as that interaction ends, I know that I have to do it. I have
    to collect that information, that knowledge, and resurface it whenever I need
    it. Otherwise, it's lost. And that helps a lot. Because people – we're humans,
    right? We want to feel acknowledged, recognized, and respected. We want to feel
    that sense of belonging and connection. It's not manipulation, it’s simply just…
    normal people are born with a solid memory. My memory is crap. So I need a database.
    [laughs]
  sec: 2196
  time: '36:36'
  who: Loris
- line: A second brain, right? [Loris agrees] This is your stakeholder mapping – or
    this is like a stakeholder relationship management system?
  sec: 2256
  time: '37:36'
  who: Alexey
- line: No, this is just awareness of who is who and what their names are.
  sec: 2266
  time: '37:46'
  who: Loris
- line: But it's like the first step, right?
  sec: 2269
  time: '37:49'
  who: Alexey
- header: 'Meeting Immersion: Learning Business Language by Attendance'
- line: The first step, yeah. This is just overcoming my terrible memory. Then, step
    two is to attend business meetings. There are many in any organization. In any
    organization – from startups to enterprises, people talk business every day, all
    day – many times a day. Some of those meetings are more engaging, some are boring,
    but you'll never know which ones are valuable until you sample them. I know it's
    crazy, right? I know it's absolutely crazy. Something you will never do. You join
    and there’s this “data” in your title. What do you do? You just go around and
    get random invitations to Teams and Google Meets to sit there and just look? It
    sounds like there is no meaning whatsoever.
  sec: 2271
  time: '37:51'
  who: Loris
- line: The first 10 meetings you go to, it's just a different language. It’s like
    when you go and visit a different country where they speak a different language
    like, “I don't know what you're talking about. There's no way I can understand
    the conversation.” And that's where a lot of people quit. They're like, “Ah, SciKit
    Learn is so much better. It gives me good vibes, I can build models. I don’t need
    that. This is bad for me.” Right? And I think that's where we need to go against
    our instincts. Because the instinct tells you “Play safe. Stay within the comfort
    zone and just get attached to those pleasant sensations that arise when you know
    that you're on top of your work.” When you know what you're doing.
  sec: 2271
  time: '37:51'
  who: Loris
- line: Nobody wants to feel like they're lost. But if you stick to it long enough,
    then those words start making sense. Now you start seeing patterns and connections.
    Repeat, rinse, repeat. [chuckles] You do it over and over and over. And after
    – sooner than you think, actually – within less than three months, I guarantee
    you that you will start seeing things from a completely different perspective.
    Now those people recognize you – you’ve built a habit of attending those meetings,
    and maybe you didn't ask a single question for a couple months. Now the first
    question comes to mind. You'll ask it maybe privately because nobody wants to
    ask a stupid question in front of like 40 people that may one day be your key
    stakeholders.
  sec: 2271
  time: '37:51'
  who: Loris
- line: At the beginning, you play safe, and then you build some confidence. Once
    you know what you know, and you kind of have a feeling for what you don't know,
    then you maybe dare to ask one question and challenge what someone said. I mean,
    it's just a wonderful thing, because most people are actually open to get fresh
    perspectives on problems – and you have it.
  sec: 2271
  time: '37:51'
  who: Loris
- line: 'That''s the thing that we don''t see: the value of someone that attends a
    meeting from a completely different domain or department is that you don''t have
    priors. Your prior is a uniform distribution, to speak the language of the audience.
    You don’t have biases, you haven''t done the shaping yet you. Everything is equally
    important and potentially interesting, or potentially not – just in the same way.
    And that is a superpower. If you can sell that, people recognize it, and they
    open up, and they talk to you. Now you have friends – you have new connections.
    [chuckles]'
  sec: 2271
  time: '37:51'
  who: Loris
- line: Do you have a system for that? You have this database with people to remember
    their names – do you also have a system for taking notes after these business
    meetings? So then you can remember, you can map concepts, you can understand who
    cares about which topic, and what’s important for people?
  sec: 2471
  time: '41:11'
  who: Alexey
- header: 'Note Systems: Using Notion to Track Meetings and Key Activities'
- line: Yeah, absolutely – something that you can do on day one. So I come from… I’ve
    been working on Discovering Data for two years now and the whole system is built
    in Notion, so I knew the software really well. But I found that for the first
    four weeks, I couldn't possibly think about it. That's just all pure overwhelm.
    There's so much information coming to you that I think the only thing you need
    to do is just chill – do some yoga, long showers, sleep – because there's a lot
    going on.
  sec: 2493
  time: '41:33'
  who: Loris
- line: But after week four, you start seeing some patterns, and you’re like, “Okay,
    now I kind of know what the business drivers are. We want to do X. We want to
    do Y. The net sales value has to be above that number. The margins on our products
    have to be above that figure. Cool. Now, what are the key activities that I'm
    going to focus on, to try and sustain and support that business strategy?”
  sec: 2493
  time: '41:33'
  who: Loris
- line: And your line managers know that, because if you have a good line manager
    – even an average one – if they’ve been in the business longer than a year, they
    surely know the key activities that are more likely to support that strategy.
    So you start from those priors – you don't have to invent anything. They will
    tell you, “Okay. Two low hanging fruits are one and two. We're going to start
    from those, nice and simple.” So I built a system literally based on those two
    first key activities. I try to map my actions and map them to the activities.
    I have notes.
  sec: 2493
  time: '41:33'
  who: Loris
- line: Notion has things like templates, so every time I have a meeting, I have a
    button – that button creates a very simple, very bare bones template with who
    I’m meeting with, the date is automatically captured, the title of the meeting,
    and tags that tell you which key activity that those notes may one day support.
    And each key activity is a page – you open it and you have all the notes that
    refer to the key activities. You can do it on a notebook (pen and paper) as well
    as. I just use Notion because it's easier.
  sec: 2493
  time: '41:33'
  who: Loris
- header: 'Tooling & IP Considerations: Personal Knowledge vs Company Systems'
- line: I’m just wondering, do you use your private Notion account for that or do
    you use Notion at work? Is it a company account? The reason I'm asking this is
    because at my work, we don't use Notion. There is a different system called Conference.
    Some people hate it, some people love it, but this is what we use. I’m then wondering,
    if I want to implement this should I just use my Notion account? Or maybe I should
    use whatever the company has?
  sec: 2622
  time: '43:42'
  who: Alexey
- line: It's a wonderful question. I started out creating an account specifically
    for work and then I realized that Notion is literally my second brain. My ideas,
    my knowledge, the things that I develop are all there, so it made sense to continue
    doing that. In saying that, it could be tricky depending on… I don't want to offer
    legal advice, but do read your contract and intellectual property clauses of their
    contract, because you might be in breach. So the way that I resolve this is by
    creating different access roles and just segregating. I have databases that are
    within that same workspace but that are specific, so that there is no accidental
    sharing with other collaborators from my business and stuff like that. Just something
    to be careful about.
  sec: 2657
  time: '44:17'
  who: Loris
- line: Okay.
  sec: 2707
  time: '45:07'
  who: Alexey
- header: 'Prioritization: Choosing Projects by Stakeholder Impact'
- line: Yeah. We talked about prioritizing. Prioritizing is a big one. The question
    that's interesting to me is, once you reach a steady state and you start being
    productive, you're part of the business, you attend meetings. Now you are independent.
    You can decide and propose even a use case or a project to the business. How do
    you prioritize those use cases? That's where I think you really make the transition
    from onboarding to leaving your function or being on top of the work that you
    do. I'm curious to hear from the audience, if anyone has a go-to framework to
    prioritize. What do you focus on? How do you make that call? Is it a dollar value
    impact? Is it the impact on people and how they work? Is long-term thinking stuff,
    like data management, cleaning data? Is it transitioning to a data warehouse?
  sec: 2713
  time: '45:13'
  who: Loris
- line: The way I do it (maybe not the most scientific way) but it’s just by talking
    to people and understanding what they care about. What are their goals? What are
    the goals of their department? And they say, “Okay, this, this, and this is important
    to me.” And if I talk to multiple people and multiple people say that this item
    is important to them, then this means that this thing, this piece of work will
    make more people happy. It will contribute to whatever they are doing. And this
    is pretty simple, right? You don't think about money, which you probably should
    in the end, or some other impact, but instead it’s “How many stakeholders can
    this thing make happy?” I think this is a valid way of prioritizing too.
  sec: 2786
  time: '46:26'
  who: Alexey
- header: 'Opportunity Selection: Finding High-Connectivity Data Projects'
- line: Yeah. It makes me think of network and social media, when you find the nexus
    of a graph – it's a node that is highly connected. In this case, the nodes are
    data projects and the edges are how many people that data product essentially
    can touch. The difference is that those products don't exist yet. They're just
    in our head – in our imagination – so the job is to really understand where the
    business is going and find those opportunities.
  sec: 2830
  time: '47:10'
  who: Loris
- line: It's like marketing. When I title a podcast these days, I come up with like
    five or six different options for a title and I pick one – the other five or six
    are gone forever. That's where agility really comes in. It's not because we just
    learn about a particular algorithm and we find an opportunity to use it. A lot
    of people do that, to be honest. I've seen it over and over. Curriculum-driven
    development is a thing. People want to get better at specific things. They know
    that the average tenure in the industry is low. I’ve met people that were like,
    “Look, I'm just being realistic here. I'm not going to be in the job longer than
    a year and a half. So I'm just taking every opportunity I can to work on the stuff
    that I think is hot or is going to be hot – there's a big market for it – and
    then jump ship and negotiate a bigger salary.” That is one way of approaching
    the problem, right? I don't think that way.
  sec: 2830
  time: '47:10'
  who: Loris
- line: The community that I'm trying to build at Discovering Data (my podcast) is
    for people like that. Of course, I have a mortgage to pay. Of course, I want to
    negotiate a bigger salary. But what gets me out of bed in the morning is to see
    that I do work and that work has an impact on real people and I can put a dollar
    value figure on that. Look, I don't know if it's because it's nice to feel that
    someone comes in and says, “Hey, Loris. Good work!” I don't know, maybe I'm addicted
    to that feeling. Maybe I'm addicted to the brainstorming and the learnings.
  sec: 2830
  time: '47:10'
  who: Loris
- line: It's very human to get addicted to people saying good things about you. [chuckles]
  sec: 2956
  time: '49:16'
  who: Alexey
- line: Yeah. It's just nice. It makes you feel that you're consequential. That you're
    not just doing stuff for the sake of crunching numbers – you are actually having
    an impact on someone or some teams or maybe a whole domain in the organization.
    That makes me feel so much better. So for people like that.
  sec: 2963
  time: '49:23'
  who: Loris
- line: I just noticed that there is a comment from Alejandro that I wanted to acknowledge
    and read. He wrote “I have an MBA,” we talked about people with a business background
    starting in the data and he started from an individual contributor position again.
    “This shift is not easy, I'm still figuring out how to profit from that generalist
    business knowledge.” This is quite interesting. I wanted to ask you – I think
    most of the listeners are not coming from an MBA, but are coming from more of
    a quantitative background. How do we get this business knowledge? How do we start
    supporting business strategy?
  sec: 2986
  time: '49:46'
  who: Alexey
- line: One of the things we wanted to talk about is, “How can I sit with people who
    are making important decisions, strategic decisions? And how can I speak the same
    language?” So we already talked about stakeholder mapping, understanding what
    they care about, prioritizing things, and speaking the same language with them.
    Then what's next? How can I actually contribute my data knowledge to this model?
    How can I support these business decisions? How can I support the business strategy?
  sec: 2986
  time: '49:46'
  who: Alexey
- header: 'Pragmatism in Tools: Excel, Pivot Tables, and Rapid Experiments'
- line: I'm gonna give you an answer that is kind of intuitive. The answer is – that
    part is actually the easiest. [Alexey chuckles “Okay”] But! This is a huge “but”
    – it requires flexibility in the way we manage our identity. As data professionals,
    we identify ourselves with the depth and breadth of our technical knowledge. That
    is great, but it's also a barrier. The biggest transformation for me is to rethink
    who you are and decouple the identity – your identity as a professional – from
    the tools and the technologies that you use. The reality is that the 80/20 rule
    applies to anything (the Pareto principle). It applies to data projects as well.
    So there's the 20% that you can do that gets 80% of the value.
  sec: 3061
  time: '51:01'
  who: Loris
- line: Most of the time, for new case studies, these are things that are experimental
    – in Excel. And yet, we see on LinkedIn literal wars between people that sustain
    that Excel is bad and people that sustain that Excel is good. And I've been a
    victim of that. I took very sharp stances on that position and I said, “From a
    data management perspective, Excel is the enemy. It’s the reason why data is crap.”
    Yes, there's truth in that, but it's not one or the other. [cross-talk]
  sec: 3061
  time: '51:01'
  who: Loris
- line: That's definitely true. [laughs]
  sec: 3160
  time: '52:40'
  who: Alexey
- line: That's true, right? That’s true, but that doesn't mean that we need to go
    banning like, “I'm never touching Excel again. Give me a Python client or I'm
    outta here!” Because that blocks us from having those conversations.
  sec: 3162
  time: '52:42'
  who: Loris
- line: You can do a lot of nice things quickly with Excel without even starting your
    Jupyter Notebook. You just open the CSV file with Excel and play with the data.
    And then [cross-talk]
  sec: 3174
  time: '52:54'
  who: Alexey
- header: 'Conversation First: Description and Diagnostic Before ML'
- line: Pivot table. That's a superpower. To be honest, it's even better than Jupyter.
    How fast it is and how easily you can share it. We don't think about that, right?
    But the other side is, we're not dealing with monkeys, we're dealing with people
    that have brains. They want to understand what's happening and they even want
    to feel good about it. That collaboration – they just want to establish, or experiment,
    to see if it's worthwhile considering you as an ally, as a partner, to what they're
    trying to achieve. That's an experiment when you start. And you have to prove
    that it's worth it.
  sec: 3188
  time: '53:08'
  who: Loris
- line: What we don't think about is that we need to also worry about how these people
    feel. If I come to you with my Jupyter notebook and I showcase all my exploratory
    data analysis and that “package that does all those cool graphics!” Yeah, maybe
    there is a “Wow!” moment. But then the next thought, most of the time, is “Oh,
    jeez. He's so smart. That's a big brain and I'm behind. I don't even know how
    to launch a bloody Jupyter Notebook. I don't even know what it is.” And now all
    that work is inside your head, as a data professional. Instead of initiating a
    conversation, it becomes a monologue. That's the problem. It kills the conversation.
    And we want those conversations. The more conversations we have, the better we
    understand the domain and the higher the impact of the models that eventually
    will touch Python is going to be. We'll get there.
  sec: 3188
  time: '53:08'
  who: Loris
- line: We'll do predictive and prescriptive, but first we need to do description
    and we need to do diagnostic. We need to be able to answer the question “Why?”
    That is the most burning question for most businesses. People don't know why things
    happen. Yeah, Excel is not the only tool. You definitely can get to the description
    stage, and maybe with some use of your brain and your domain knowledge, you might
    even be able to do diagnostic without even touching machine learning. But are
    you going to be okay with that? That's why I said that it's going to be an identity
    clash. We need to let go of the fact that “You're cool if you use machine learning.
    You're boring if you use Excel.” That is nonsense. That is completely missing
    the point. The point for us is to support the business. If the business needs
    Excel at that moment, we need to be okay with that. We need to step up – grow
    up, essentially – and go like, “Okay. The tool doesn't identify me. I use whatever
    it takes to serve the business.” Are you ready to do that? That's the question.
    Not everybody is.
  sec: 3188
  time: '53:08'
  who: Loris
- line: '[technical difficulties]'
  sec: 3188
  time: '53:08'
  who: Loris
- header: 'Presenting Online: Podcasting, Pauses, and Audio Practices'
- line: Yeah, now it works. Thanks. We have a few questions and one interesting one
    from Raphael is “Your sound is very good. How does one learn to speak online?”
    [chuckles] Is it only trying and or did you do something else for that?
  sec: 3373
  time: '56:13'
  who: Alexey
- line: The sound as in the quality of the audio or the speaking?
  sec: 3392
  time: '56:32'
  who: Loris
- line: I think it’s both. A microphone is important, right? [Loris agrees] But that's
    not the whole thing. For example [cross-talk]
  sec: 3396
  time: '56:36'
  who: Alexey
- line: Well, I host a podcast [chuckles]
  sec: 3405
  time: '56:45'
  who: Loris
- line: '[laughs] Yeah. But how did you actually learn to speak online? Was it just
    practice? You thought, “Okay, let me host a podcast.” and then you just learn
    to speak online or you did something else for that?'
  sec: 3407
  time: '56:47'
  who: Alexey
- line: I did something that was atrocious. It was incredibly painful – listening
    to yourself after recording. It was one of the hardest things.
  sec: 3420
  time: '57:00'
  who: Loris
- line: Ooh. No, no. [laughs] That’s terrible.
  sec: 3432
  time: '57:12'
  who: Alexey
- line: I wanted to run away. Yeah. It's so weird. And people say “Yeah, you get used
    to it.” But yeah… I'm still working on it. I'm getting used to it. But when you
    edit your own podcasts, you realize how much you blather without really… You learn
    to speak in a way that is different, like varying the tone, taking the time to
    pause. A lot of us are actually afraid of silence. [cross-talk]
  sec: 3436
  time: '57:16'
  who: Loris
- line: You’re very good at this. I’ve noticed that in this episode. The pauses were
    really nice. It's like you practiced. You did practice, right?
  sec: 3471
  time: '57:51'
  who: Alexey
- line: No, I didn't. Well, I host a podcast. So after 55 interviews with people,
    you do find patterns in editing. I'm like, “Why…? I should breathe.” Sometimes
    that's what it comes from – from realizing how suffocating it is to just keep
    talking without breathing. From the listener perspective, when you take that pause…
  sec: 3481
  time: '58:01'
  who: Loris
- line: They can breathe too?
  sec: 3505
  time: '58:25'
  who: Alexey
- line: You allow them to breathe, yeah. It's so much easier to follow the podcast.
    I don't know if that works.
  sec: 3506
  time: '58:26'
  who: Loris
- header: 'Resources: Discovering Data Podcast for Business Skills'
- line: We should be wrapping up. So maybe the last question I will ask you is “Do
    you have any book recommendations or resource recommendations on the topic of
    today's interview? What kind of book can we read to learn more about business
    skills? Or maybe you can recommend your podcast for that and you don't need any
    books?
  sec: 3515
  time: '58:35'
  who: Alexey
- line: Yeah, it's a good question. To be honest, I have been looking for a book like
    that for a while. I’m kind of dreaming of writing one myself, because I couldn't
    find a book on the topic that is connected – that speaks the language of data
    professionals. There's plenty of books on businesses, but you read them and you're
    like, “This is not for me.” So no, I'm sorry. I'm not aware of any books. I do
    have a podcast that people that are interested in the topic of getting more impact
    out of the work they do – they can definitely check it out. It's called Discovering
    Data (DiscoveringData.com).
  sec: 3534
  time: '58:54'
  who: Loris
- line: We just launched a Discord server yesterday. Unlike DataTalks.Club, our community
    has myself and my podcast assistant at the moment on it. The server is open. [Alexey
    “Two people?”] Yeah, just two. So to whoever comes in, don't expect a polished
    system. [chuckles] But we've been running now for two years and we have so many
    people that reached out and said “It'd be nice to have a space to hang out and
    share thoughts – post episodes even before the episodes.” My vision for next year
    is to use that space to grow, to fill this gap that we all kind of know it's there.
    It's kind of like the Matrix, right? You’ve gotta take that red pill to follow
    the rabbit and see what there is. Because some people – most of us, really – don't
    even know that there is a gap.
  sec: 3534
  time: '58:54'
  who: Loris
- line: To join the Discord server, what do I need to do? Do I need to go to the Discovering
    Data website and scroll down?
  sec: 3626
  time: '1:00:26'
  who: Alexey
- header: 'Community Building: Joining the Discovering Data Discord'
- line: in the future, yes. At the moment, we are a business of one. It's way simpler
    than that. You go on wherever you listen to your podcasts, you follow Discovering
    Data, the last episode – the one with Stephen Shedletztky, the guy who worked
    10 years with Simon Sinek. He's an absolute authority on the space of psychological
    safety, leadership, that kind of stuff. We had a fantastic conversation. He's
    an incredible speaker. I absolutely recommend him, if you're looking for speakers
    for your podcast, by the way. In the show notes of that podcast, you'll find the
    link to the Discord server. So definitely join. Happy to see you there. Maybe
    we can bridge the gap together. It’s so much more fun.
  sec: 3633
  time: '1:00:33'
  who: Loris
- header: Episode Wrap-Up and Contact Links
- line: Thanks for the chat. It was amazing. Nice to talk to you. And thanks, everyone,
    for joining. I did not expect that so many people would join so early. So thanks,
    everyone. That was fun.
  sec: 3683
  time: '1:01:23'
  who: Alexey
- line: Thank you. Anytime. Hit me up on Discord or LinkedIn. Happy to connect with
    anyone in the audience.
  sec: 3696
  time: '1:01:36'
  who: Loris
- line: Yes. We'll include all the contact details, and you perhaps will also send
    us a link to your Discord server, which we’ll also include in the description.
  sec: 3702
  time: '1:01:42'
  who: Alexey
- line: I can definitely do that.
  sec: 3710
  time: '1:01:50'
  who: Loris
- line: Okay, nice talking to you and have a great weekend.
  sec: 3713
  time: '1:01:53'
  who: Alexey
- line: You too. Ciao.
  sec: 3717
  time: '1:01:57'
  who: Loris
---

Links:

* [Discovering Data Discord server](https://bit.ly/discovering-data-discord){:target="_blank"}
* [Loris' LinkedIn](https://www.linkedin.com/in/lorismarini/){:target="_blank"}
* [Loris' Twitter](https://twitter.com/LorisMarini){:target="_blank"}